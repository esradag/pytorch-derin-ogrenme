{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOxAXZYNlpg/AtUxlifHT3+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/esradag/pytorch-derin-ogrenme/blob/main/00_PytorchTemelleri.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 00. PyTorch Temelleri\n",
        "\n",
        "## PyTorch Nedir?\n",
        "\n",
        "[PyTorch](https://pytorch.org/), aÃ§Ä±k kaynaklÄ± bir makine Ã¶ÄŸrenimi ve derin Ã¶ÄŸrenme framework'Ã¼dÃ¼r.\n",
        "\n",
        "## PyTorch Ne Ä°Ã§in KullanÄ±lÄ±r?\n",
        "\n",
        "PyTorch, verileri iÅŸlemek ve Python kodu kullanarak makine Ã¶ÄŸrenimi algoritmalarÄ± yazmak iÃ§in kullanÄ±lÄ±r.\n",
        "\n",
        "## Kimler PyTorch KullanÄ±yor?\n",
        "\n",
        "DÃ¼nyanÄ±n en bÃ¼yÃ¼k teknoloji ÅŸirketlerinden [Meta (Facebook)](https://ai.facebook.com/blog/pytorch-builds-the-future-of-ai-and-machine-learning-at-facebook/), Tesla ve Microsoft gibi firmalar ile [OpenAI](https://openai.com/blog/openai-pytorch/) gibi yapay zeka araÅŸtÄ±rma ÅŸirketleri, araÅŸtÄ±rmalarÄ±nÄ± desteklemek ve makine Ã¶ÄŸrenimini Ã¼rÃ¼nlerine entegre etmek iÃ§in PyTorch kullanÄ±yor.\n",
        "\n",
        "![endÃ¼stri ve araÅŸtÄ±rmada kullanÄ±lan pytorch](https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/images/00-pytorch-being-used-across-research-and-industry.png)\n",
        "\n",
        "Ã–rneÄŸin, Tesla'nÄ±n yapay zeka baÅŸkanÄ± Andrej Karpathy, Tesla'nÄ±n otonom sÃ¼rÃ¼ÅŸ bilgisayarlÄ± gÃ¶rÃ¼ modellerini nasÄ±l PyTorch ile geliÅŸtirdiklerini [PyTorch DevCon 2019](https://youtu.be/oBklltKXtDE) ve [Tesla AI Day 2021](https://youtu.be/j0z4FweCy4M?t=2904) etkinliklerinde anlatmÄ±ÅŸtÄ±r.\n",
        "\n",
        "PyTorch, ayrÄ±ca tarÄ±m gibi farklÄ± sektÃ¶rlerde de [traktÃ¶rlerde bilgisayarlÄ± gÃ¶rÃ¼](https://medium.com/pytorch/ai-for-ag-production-machine-learning-for-agriculture-e8cfdb9849a1) uygulamalarÄ±nÄ± desteklemek iÃ§in kullanÄ±lÄ±yor.\n",
        "\n",
        "## Neden PyTorch KullanmalÄ±yÄ±z?\n",
        "\n",
        "Makine Ã¶ÄŸrenimi araÅŸtÄ±rmacÄ±larÄ± PyTorch kullanmayÄ± seviyor. Åubat 2022 itibarÄ±yla PyTorch, makine Ã¶ÄŸrenimi araÅŸtÄ±rma makalelerini ve kodlarÄ±nÄ± takip eden [Papers With Code](https://paperswithcode.com/trends) sitesinde en Ã§ok kullanÄ±lan derin Ã¶ÄŸrenme framework'Ã¼ olmuÅŸtur.\n",
        "\n",
        "PyTorch ayrÄ±ca GPU hÄ±zlandÄ±rma (kodunuzu daha hÄ±zlÄ± Ã§alÄ±ÅŸtÄ±rma) gibi birÃ§ok iÅŸlemi arka planda yÃ¶netir.\n",
        "\n",
        "Bu sayede veri iÅŸleme ve algoritma yazmaya odaklanabilir ve PyTorch kodunuzun hÄ±zlÄ± Ã§alÄ±ÅŸmasÄ±nÄ± saÄŸlar.\n",
        "\n",
        "Tesla ve Meta (Facebook) gibi ÅŸirketler yÃ¼zlerce uygulamayÄ± desteklemek, binlerce aracÄ± sÃ¼rmek ve milyarlarca insana iÃ§erik sunmak iÃ§in PyTorch kullanÄ±yorsa, geliÅŸtirme aÃ§Ä±sÄ±ndan oldukÃ§a gÃ¼Ã§lÃ¼ bir araÃ§ olduÄŸu aÃ§Ä±ktÄ±r.\n",
        "\n",
        "## Bu ModÃ¼lde Neler Ã–ÄŸreneceÄŸiz?\n",
        "\n",
        "Bu kurs farklÄ± bÃ¶lÃ¼mlere (notebook'lara) ayrÄ±lmÄ±ÅŸtÄ±r.\n",
        "\n",
        "Her notebook PyTorch iÃ§indeki Ã¶nemli fikirleri ve kavramlarÄ± kapsar.\n",
        "\n",
        "Sonraki notebook'lar Ã¶nceki bilgilerin Ã¼zerine inÅŸa edilir (numaralandÄ±rma 00'dan baÅŸlar, 01, 02 ÅŸeklinde devam eder).\n",
        "\n",
        "Bu notebook, makine Ã¶ÄŸrenimi ve derin Ã¶ÄŸrenmenin temel yapÄ± taÅŸÄ± olan tensÃ¶rleri ele alÄ±r.\n",
        "\n",
        "Ã–zellikle ÅŸu konularÄ± kapsayacaÄŸÄ±z:\n",
        "\n",
        "| **Konu** | **Ä°Ã§erik** |\n",
        "| ----- | ----- |\n",
        "| **TensÃ¶rlere GiriÅŸ** | TensÃ¶rler, makine Ã¶ÄŸrenimi ve derin Ã¶ÄŸrenmenin temel yapÄ± taÅŸlarÄ±dÄ±r. |\n",
        "| **TensÃ¶r OluÅŸturma** | TensÃ¶rler, gÃ¶rÃ¼ntÃ¼ler, kelimeler, sayÄ± tablolarÄ± gibi birÃ§ok veri tÃ¼rÃ¼nÃ¼ temsil edebilir. |\n",
        "| **TensÃ¶rlerden Bilgi Alma** | Bir tensÃ¶re bilgi koyabiliyorsanÄ±z, o bilgiyi Ã§Ä±karmak da isteyeceksiniz. |\n",
        "| **TensÃ¶rleri ManipÃ¼le Etme** | Makine Ã¶ÄŸrenimi algoritmalarÄ± (Ã¶rneÄŸin sinir aÄŸlarÄ±), tensÃ¶rleri toplama, Ã§arpma ve birleÅŸtirme gibi farklÄ± ÅŸekillerde manipÃ¼le etmeyi iÃ§erir. |\n",
        "| **TensÃ¶r Åekilleriyle Ã‡alÄ±ÅŸma** | Makine Ã¶ÄŸreniminde en sÄ±k karÅŸÄ±laÅŸÄ±lan sorunlardan biri, yanlÄ±ÅŸ ÅŸekilli tensÃ¶rleri birbiriyle karÄ±ÅŸtÄ±rmaktÄ±r. |\n",
        "| **TensÃ¶rlerde Ä°ndeksleme** | Python listesi veya NumPy dizisi Ã¼zerinde indeksleme yaptÄ±ysanÄ±z, tensÃ¶rlerde de benzer bir mantÄ±k vardÄ±r fakat Ã§ok daha fazla boyuta sahip olabilirler. |\n",
        "| **PyTorch TensÃ¶rleri ve NumPy KarÄ±ÅŸÄ±mÄ±** | PyTorch tensÃ¶rlerle ([`torch.Tensor`](https://pytorch.org/docs/stable/tensors.html)), NumPy ise dizilerle ([`np.ndarray`](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html)) Ã§alÄ±ÅŸÄ±r. Bazen bunlarÄ± birleÅŸtirmek isteyebilirsiniz. |\n",
        "| **Tekrarlanabilirlik (Reproducibility)** | Makine Ã¶ÄŸrenimi oldukÃ§a deneysel bir alandÄ±r ve Ã§alÄ±ÅŸmasÄ± iÃ§in Ã§ok fazla *rastgelelik* kullanÄ±r, bazen bu *rastgeleliÄŸin* o kadar rastgele olmamasÄ±nÄ± isteyebilirsiniz. |\n",
        "| **GPU Ãœzerinde TensÃ¶r Ã‡alÄ±ÅŸtÄ±rma** | GPU'lar (Grafik Ä°ÅŸlem Birimleri) kodunuzu hÄ±zlandÄ±rÄ±r, PyTorch ise kodunuzu GPU'da Ã§alÄ±ÅŸtÄ±rmayÄ± kolaylaÅŸtÄ±rÄ±r. |\n",
        "\n",
        "## Nereden YardÄ±m Alabilirsiniz?\n",
        "\n",
        "Bu kursun tÃ¼m materyallerine [GitHub Ã¼zerinden ulaÅŸabilirsiniz](https://github.com/mrdbourke/pytorch-deep-learning).\n",
        "\n",
        "Bir sorunla karÅŸÄ±laÅŸÄ±rsanÄ±z, [TartÄ±ÅŸmalar sayfasÄ±nda](https://github.com/mrdbourke/pytorch-deep-learning/discussions) soru sorabilirsiniz.\n",
        "\n",
        "AyrÄ±ca [PyTorch geliÅŸtirici forumlarÄ±](https://discuss.pytorch.org/) da PyTorch hakkÄ±nda her ÅŸey iÃ§in Ã§ok yardÄ±mcÄ± bir kaynaktÄ±r.\n"
      ],
      "metadata": {
        "id": "KP3SgER0ZsAM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#PyTorch'u Ä°Ã§e Aktarma\n",
        "> **Not:** Bu kodu Ã§alÄ±ÅŸtÄ±rmadan Ã¶nce, [PyTorch kurulum adÄ±mlarÄ±nÄ± ] (https://pytorch.org/get-started/locally/)  tamamlamÄ±ÅŸ olmanÄ±z gerekir.\n",
        "> Ancak, **Google Colab kullanÄ±yorsanÄ±z **herhangi bir ek kurulum yapmanÄ±za gerek yoktur Ã§Ã¼nkÃ¼ PyTorch ve diÄŸer gerekli kÃ¼tÃ¼phaneler Colab'de Ã¶nceden yÃ¼klÃ¼dÃ¼r.\n",
        "\n",
        "PyTorch'u iÃ§e aktararak ve kullanÄ±lan sÃ¼rÃ¼mÃ¼ kontrol ederek baÅŸlayalÄ±m:"
      ],
      "metadata": {
        "id": "-UfpAaulbMGo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "torch.__version__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "RX5glGB6Z148",
        "outputId": "bfce1057-b1ef-4c53-ff8a-aa6556dd2f20"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.5.1+cu121'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## TensÃ¶rlere GiriÅŸ\n",
        "\n",
        "ArtÄ±k PyTorch'u iÃ§e aktardÄ±ÄŸÄ±mÄ±za gÃ¶re, tensÃ¶rleri Ã¶ÄŸrenme zamanÄ±.\n",
        "\n",
        "TensÃ¶rler, makine Ã¶ÄŸreniminin temel yapÄ± taÅŸÄ±dÄ±r.\n",
        "\n",
        "GÃ¶revleri, verileri sayÄ±sal bir ÅŸekilde temsil etmektir.\n",
        "\n",
        "Ã–rneÄŸin, bir resmi `[3, 224, 224]` ÅŸeklinde bir tensÃ¶rle temsil edebilirsiniz. Bu, `[renk_kanallarÄ±, yÃ¼kseklik, geniÅŸlik]` anlamÄ±na gelir. Yani bu gÃ¶rÃ¼ntÃ¼de `3` renk kanalÄ± (kÄ±rmÄ±zÄ±, yeÅŸil, mavi), `224` piksel yÃ¼kseklik ve `224` piksel geniÅŸlik vardÄ±r.\n",
        "\n",
        "![girdi gÃ¶rÃ¼ntÃ¼sÃ¼nden tensÃ¶r temsilini gÃ¶steren Ã¶rnek, gÃ¶rÃ¼ntÃ¼ 3 renk kanalÄ±na ve yÃ¼kseklik ve geniÅŸliÄŸi temsil eden sayÄ±lara ayrÄ±lÄ±yor](https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/images/00-tensor-shape-example-of-image.png)\n",
        "\n",
        "TensÃ¶r dilinde (tensÃ¶rleri tanÄ±mlamak iÃ§in kullanÄ±lan dil), bu tensÃ¶r Ã¼Ã§ boyuta sahiptir: biri `renk_kanallarÄ±`, biri `yÃ¼kseklik` ve biri de `geniÅŸlik` iÃ§in.\n",
        "\n",
        "Ama kendimizi fazla ileriye taÅŸÄ±yoruz.\n",
        "\n",
        "Haydi, tensÃ¶rleri kodlayarak daha yakÄ±ndan Ã¶ÄŸrenelim.\n"
      ],
      "metadata": {
        "id": "oSTWM2_gcHT7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### TensÃ¶r OluÅŸturma\n",
        "\n",
        "PyTorch, tensÃ¶rleri Ã§ok sever. Ã–yle ki, [`torch.Tensor`](https://pytorch.org/docs/stable/tensors.html) sÄ±nÄ±fÄ±na Ã¶zel bir dÃ¶kÃ¼mantasyon sayfasÄ± bile var.\n",
        "\n",
        "Ä°lk Ã¶deviniz, [10 dakika boyunca `torch.Tensor` dÃ¶kÃ¼mantasyonunu okumak](https://pytorch.org/docs/stable/tensors.html). Ama bunu daha sonra da yapabilirsiniz.\n",
        "\n",
        "Haydi kod yazalÄ±m.\n",
        "\n",
        "Ä°lk oluÅŸturacaÄŸÄ±mÄ±z ÅŸey bir **skaler** olacak.\n",
        "\n",
        "Skaler, tek bir sayÄ±dÄ±r ve tensÃ¶r dilinde sÄ±fÄ±r boyutlu (0D) bir tensÃ¶rdÃ¼r.\n",
        "\n",
        "> **Not:** Bu kursta sÄ±kÃ§a karÅŸÄ±laÅŸacaÄŸÄ±nÄ±z bir yaklaÅŸÄ±m olacak. Spesifik kodlar yazmaya odaklanacaÄŸÄ±z. Ancak zaman zaman PyTorch dÃ¶kÃ¼mantasyonunu okuyup anlamanÄ±zÄ± gerektiren alÄ±ÅŸtÄ±rmalar vereceÄŸim. Ã‡Ã¼nkÃ¼ bu kursu bitirdiÄŸinizde daha fazlasÄ±nÄ± Ã¶ÄŸrenmek isteyeceÄŸinizden eminim. Ve dÃ¶kÃ¼mantasyon, sÄ±k sÄ±k baÅŸvuracaÄŸÄ±nÄ±z bir kaynak olacak.\n"
      ],
      "metadata": {
        "id": "SIafJg7kdU2o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Scalar\n",
        "scalar = torch.tensor(7)\n",
        "scalar"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i9fg_z8zdbH0",
        "outputId": "735d3ee3-d348-44f9-b6d5-609da9ed74fd"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(7)"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### TensÃ¶rlerin BoyutlarÄ±nÄ± Kontrol Etme\n",
        "\n",
        "YukarÄ±da ekrana **`tensor(7)`** Ã§Ä±ktÄ±sÄ±nÄ± gÃ¶rdÃ¼nÃ¼z mÃ¼?  \n",
        "\n",
        "Bu, **scalar** tek bir sayÄ± olmasÄ±na raÄŸmen, PyTorch'ta **`torch.Tensor`** tÃ¼rÃ¼nde olduÄŸunu gÃ¶sterir.\n",
        "\n",
        "Bir tensÃ¶rÃ¼n boyutunu kontrol etmek iÃ§in **`.ndim`** Ã¶zelliÄŸini kullanabiliriz.\n"
      ],
      "metadata": {
        "id": "eK1R_HX2cssS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scalar.ndim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CXmtxgftdw1G",
        "outputId": "c52e69c8-7254-44f5-a3be-fa35ec862354"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Peki, tensÃ¶rden bir sayÄ±yÄ± nasÄ±l alabiliriz?\n",
        "\n",
        "Yani, `torch.Tensor` tÃ¼rÃ¼nden bir Python tam sayÄ±sÄ±na nasÄ±l dÃ¶nÃ¼ÅŸtÃ¼rebiliriz?\n",
        "\n",
        "Bunu yapmak iÃ§in `item()` metodunu kullanabiliriz.\n"
      ],
      "metadata": {
        "id": "MGLpr8Auw9Eo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Bir tensÃ¶r iÃ§indeki Python sayÄ±sÄ±nÄ± al (sadece tek elemanlÄ± tensÃ¶rlerde Ã§alÄ±ÅŸÄ±r)\n",
        "scalar.item()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lCLVS6m4xCxu",
        "outputId": "fe2dfee4-b5dd-4fee-8747-7a000e9a0010"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tamam, ÅŸimdi bir **vektÃ¶r** gÃ¶relim.\n",
        "\n",
        "Bir vektÃ¶r, tek boyutlu bir tensÃ¶rdÃ¼r ancak birÃ§ok sayÄ± iÃ§erebilir.\n",
        "\n",
        "Ã–rneÄŸin, evinizdeki `[yatak odasÄ±, banyo]` bilgisini `[3, 2]` vektÃ¶rÃ¼yle tanÄ±mlayabilirsiniz. Veya `[yatak odasÄ±, banyo, otopark]` bilgisini `[3, 2, 2]` vektÃ¶rÃ¼yle ifade edebilirsiniz.\n",
        "\n",
        "Buradaki Ã¶nemli nokta, bir vektÃ¶rÃ¼n (ve tensÃ¶rlerin) neyi temsil edebileceÄŸi konusunda esnek olmasÄ±dÄ±r.\n"
      ],
      "metadata": {
        "id": "skTafv9Id6CL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Vector\n",
        "vector = torch.tensor([7, 7])\n",
        "vector"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l4xwrhkfd5kK",
        "outputId": "6f38633a-36a8-40aa-89ff-5d318bcfeda6"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([7, 7])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Harika, `vector` artÄ±k iki adet 7 iÃ§eriyor, en sevdiÄŸim sayÄ±.\n",
        "\n",
        "Peki, sence bu vektÃ¶r kaÃ§ boyutlu olacak?\n"
      ],
      "metadata": {
        "id": "iENHs35RebmC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# VektÃ¶rÃ¼n boyut sayÄ±sÄ±nÄ± kontrol et\n",
        "vector.ndim\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "La-K6U9cxwXU",
        "outputId": "1793bd32-a2a1-4a63-fbfc-f6751cbbacf0"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hmm, bu garip, `vector` iki sayÄ± iÃ§eriyor ama sadece tek bir boyuta sahip.\n",
        "\n",
        "Sana kÃ¼Ã§Ã¼k bir ipucu vereyim.\n",
        "\n",
        "PyTorch'ta bir tensÃ¶rÃ¼n kaÃ§ boyutu olduÄŸunu, dÄ±ÅŸÄ±ndaki kÃ¶ÅŸeli parantezlerin (`[`) sayÄ±sÄ±na bakarak anlayabilirsin ve sadece bir tarafÄ± sayman yeterlidir.\n",
        "\n",
        "`vector` kaÃ§ kÃ¶ÅŸeli paranteze sahip?\n",
        "\n",
        "TensÃ¶rler iÃ§in bir diÄŸer Ã¶nemli kavram ise `shape` (ÅŸekil) Ã¶zelliÄŸidir. Shape, tensÃ¶r iÃ§indeki elemanlarÄ±n nasÄ±l dÃ¼zenlendiÄŸini gÃ¶sterir.\n",
        "\n",
        "Åimdi `vector`'Ã¼n ÅŸeklini kontrol edelim.\n"
      ],
      "metadata": {
        "id": "jR_KpkzLx2r4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# VektÃ¶rÃ¼n ÅŸeklini kontrol etme\n",
        "vector.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ZWDUJzVee4g",
        "outputId": "ce2ff6fa-17f8-476d-805d-94f4be99443b"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "YukarÄ±daki Ã§Ä±ktÄ± `torch.Size([2])` dÃ¶ndÃ¼rÃ¼r, bu da vektÃ¶rÃ¼mÃ¼zÃ¼n `[2]` ÅŸeklinde olduÄŸunu gÃ¶sterir. Bunun nedeni, kÃ¶ÅŸeli parantezler iÃ§ine iki eleman yerleÅŸtirmiÅŸ olmamÄ±zdÄ±r (`[7, 7]`).\n",
        "\n",
        "Åimdi bir **matris** gÃ¶relim.\n"
      ],
      "metadata": {
        "id": "UIcWmbrSx98g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Matris (2D tensÃ¶r) oluÅŸturma\n",
        "MATRIX = torch.tensor([[7, 8],\n",
        "                       [9, 10]])\n",
        "\n",
        "MATRIX"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RmeTD2sKezbh",
        "outputId": "1571bf7f-a7ac-48b8-b38a-e57622f2af2b"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 7,  8],\n",
              "        [ 9, 10]])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vay canÄ±na! Daha fazla sayÄ±! Matrisler, vektÃ¶rler kadar esnektir ancak fazladan bir boyuta sahiptirler.\n"
      ],
      "metadata": {
        "id": "8rUgmvPwyTsP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Matrisin boyut sayÄ±sÄ±nÄ± kontrol etme\n",
        "MATRIX.ndim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kN9hA29yhvUZ",
        "outputId": "ca90ea26-0555-4ec7-c2a7-16bae5254afc"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "`MATRIX` iki boyuta sahip (Bir tarafÄ±ndaki dÄ±ÅŸ kÃ¶ÅŸeli parantezleri saydÄ±n mÄ±?).\n",
        "\n",
        "Sence `shape` (ÅŸekil) deÄŸeri ne olacak?\n"
      ],
      "metadata": {
        "id": "bPm_ag-xyl2v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Matrisin ÅŸeklini kontrol etme\n",
        "MATRIX.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6nXh8mgwh70U",
        "outputId": "6676b4c5-f2d4-4e71-cfd1-e502b769d908"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ã‡Ä±ktÄ± olarak `torch.Size([2, 2])` alÄ±yoruz Ã§Ã¼nkÃ¼ `MATRIX` iki eleman derinliÄŸinde ve iki eleman geniÅŸliÄŸinde.\n",
        "\n",
        "Åimdi bir **tensÃ¶r** oluÅŸturalÄ±m!\n"
      ],
      "metadata": {
        "id": "mqk4Y9tdzBdl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 3 boyutlu bir tensÃ¶r oluÅŸturma\n",
        "TENSOR = torch.tensor([[[1, 2, 3],\n",
        "                        [3, 6, 9],\n",
        "                        [2, 4, 5]]])\n",
        "\n",
        "# TensÃ¶rÃ¼ yazdÄ±rma\n",
        "print(TENSOR)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MADADlgfiVIh",
        "outputId": "7af2bf91-29ac-41fa-daa9-abd97b842250"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[1, 2, 3],\n",
            "         [3, 6, 9],\n",
            "         [2, 4, 5]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vay canÄ±na! Ne kadar gÃ¼zel bir tensÃ¶r.\n",
        "\n",
        "TensÃ¶rlerin neredeyse her ÅŸeyi temsil edebileceÄŸini vurgulamak istiyorum.\n",
        "\n",
        "Az Ã¶nce oluÅŸturduÄŸumuz tensÃ¶r, bir biftek ve badem ezmesi maÄŸazasÄ±nÄ±n satÄ±ÅŸ rakamlarÄ±nÄ± temsil edebilir (en sevdiÄŸim iki yiyecekten biri).\n",
        "\n",
        "![Google Sheets'te haftanÄ±n gÃ¼nleri, biftek satÄ±ÅŸlarÄ± ve badem ezmesi satÄ±ÅŸlarÄ±nÄ± gÃ¶steren basit bir tensÃ¶r](https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/images/00_simple_tensor.png)\n",
        "\n",
        "Sence bu tensÃ¶r kaÃ§ boyutludur? (ipucu: kÃ¶ÅŸeli parantez sayma yÃ¶ntemini kullan)\n"
      ],
      "metadata": {
        "id": "GN6nU9nBiio5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TENSOR deÄŸiÅŸkeninin boyut sayÄ±sÄ±nÄ± kontrol etme\n",
        "TENSOR.ndim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DiJqLXQFijoL",
        "outputId": "ae4da2e7-bcaa-42f2-ee65-22b9e159901f"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Peki ya tensÃ¶rÃ¼n ÅŸekli (shape) nasÄ±l?"
      ],
      "metadata": {
        "id": "BxUjWQDazPQK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TENSOR deÄŸiÅŸkeninin ÅŸeklini (boyutlarÄ±nÄ±n dÃ¼zenini) kontrol etme\n",
        "TENSOR.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WjkmKhCbhl-s",
        "outputId": "c2226375-7ee1-4f0c-9064-714f248446c2"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 3, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tamam, Ã§Ä±ktÄ± olarak `torch.Size([1, 3, 3])` alÄ±yoruz.\n",
        "\n",
        "Boyutlar dÄ±ÅŸtan iÃ§e doÄŸru sÄ±ralanÄ±r.\n",
        "\n",
        "Bu, 3x3'lÃ¼k 1 adet boyut olduÄŸu anlamÄ±na gelir.\n",
        "\n",
        "![FarklÄ± tensÃ¶r boyutlarÄ±na Ã¶rnek](https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/images/00-pytorch-different-tensor-dimensions.png)\n",
        "\n",
        "> **Not:** `scalar` ve `vector` iÃ§in kÃ¼Ã§Ã¼k harf, `MATRIX` ve `TENSOR` iÃ§in bÃ¼yÃ¼k harf kullandÄ±ÄŸÄ±mÄ± fark etmiÅŸ olabilirsiniz. Bu bilinÃ§li bir tercih. Pratikte, skalerler ve vektÃ¶rler genellikle kÃ¼Ã§Ã¼k harflerle (`y`, `a`) gÃ¶sterilir. Matrisler ve tensÃ¶rler ise bÃ¼yÃ¼k harflerle (`X`, `W`) gÃ¶sterilir.\n",
        ">\n",
        "> AyrÄ±ca matris ve tensÃ¶r terimlerinin bazen birbirinin yerine kullanÄ±ldÄ±ÄŸÄ±nÄ± da gÃ¶rebilirsiniz. Bu oldukÃ§a yaygÄ±ndÄ±r. PyTorch'ta Ã§oÄŸunlukla `torch.Tensor` ile Ã§alÄ±ÅŸtÄ±ÄŸÄ±nÄ±z iÃ§in tensÃ¶r terimi kullanÄ±lÄ±r, ancak iÃ§eriÄŸin ÅŸekli ve boyutlarÄ± ne olduÄŸunu belirler.\n",
        "\n",
        "### Ã–zetleyelim\n",
        "\n",
        "| **AdÄ±**   | **Nedir?**                                    | **Boyut SayÄ±sÄ±**              | **Genellikle KullanÄ±mÄ± (Ã–rnek)** |\n",
        "|-----------|-----------------------------------------------|------------------------------|----------------------------------|\n",
        "| **scalar** | Tek bir sayÄ±                                  | 0                            | KÃ¼Ã§Ã¼k harf (`a`)                 |\n",
        "| **vector** | YÃ¶nÃ¼ olan bir sayÄ± (Ã¶rneÄŸin rÃ¼zgar hÄ±zÄ±) veya birden fazla sayÄ± | 1                            | KÃ¼Ã§Ã¼k harf (`y`)                 |\n",
        "| **matrix** | 2 boyutlu sayÄ± dizisi                        | 2                            | BÃ¼yÃ¼k harf (`Q`)                 |\n",
        "| **tensor** | n-boyutlu sayÄ± dizisi                        | Herhangi bir boyut (0: skaler, 1: vektÃ¶r) | BÃ¼yÃ¼k harf (`X`)                 |\n",
        "\n",
        "![Skaler, vektÃ¶r, matris ve tensÃ¶r Ã¶rnekleri](https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/images/00-scalar-vector-matrix-tensor.png)\n"
      ],
      "metadata": {
        "id": "5UBaoJHsjCDB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ğŸ² Rastgele TensÃ¶rler (Random Tensors)\n",
        "\n",
        "Daha Ã¶nce tensÃ¶rlerin verileri temsil ettiÄŸini Ã¶ÄŸrendik.  \n",
        "Makine Ã¶ÄŸrenimi modelleri (Ã¶zellikle **sinir aÄŸlarÄ±**) bu tensÃ¶rleri iÅŸleyerek iÃ§indeki kalÄ±plarÄ± ve iliÅŸkileri keÅŸfeder.\n",
        "\n",
        "Ancak, PyTorch ile makine Ã¶ÄŸrenimi modeli geliÅŸtirirken, tensÃ¶rleri elle oluÅŸturmak (ÅŸu ana kadar yaptÄ±ÄŸÄ±mÄ±z gibi) oldukÃ§a nadir bir durumdur.\n",
        "\n",
        "---\n",
        "\n",
        "### ğŸ”„ **Makine Ã–ÄŸreniminde Rastgele TensÃ¶rlerin Ã–nemi**\n",
        "\n",
        "Makine Ã¶ÄŸrenimi modelleri genellikle baÅŸlangÄ±Ã§ta rastgele sayÄ±larla doldurulmuÅŸ bÃ¼yÃ¼k tensÃ¶rlerle baÅŸlar.  \n",
        "Model, bu rastgele sayÄ±larÄ± veriyi iÅŸlerken gÃ¼nceller ve daha iyi tahminler yapmayÄ± Ã¶ÄŸrenir.\n",
        "\n",
        "Bu sÃ¼reci ÅŸu ÅŸekilde Ã¶zetleyebiliriz:\n",
        "\n",
        "`Rastgele sayÄ±larla baÅŸla â†’ Veriye bak â†’ SayÄ±larÄ± gÃ¼ncelle â†’ Veriye tekrar bak â†’ SayÄ±larÄ± gÃ¼ncelle...`\n",
        "\n",
        "ğŸ“Œ **Veri bilimcisi** olarak, modelin:  \n",
        "- **BaÅŸlangÄ±Ã§ deÄŸerlerini (initialization)** nasÄ±l belirleyeceÄŸini,  \n",
        "- **Veriyi (representation)** nasÄ±l iÅŸleyeceÄŸini ve  \n",
        "- **SayÄ±larÄ± (optimization)** nasÄ±l gÃ¼ncelleyeceÄŸini kontrol edebilirsiniz.\n",
        "\n",
        "Bu adÄ±mlarÄ± ilerleyen bÃ¶lÃ¼mlerde uygulamalÄ± olarak inceleyeceÄŸiz.  \n",
        "Åimdilik, rastgele sayÄ± iÃ§eren tensÃ¶rleri nasÄ±l oluÅŸturacaÄŸÄ±mÄ±za bakalÄ±m.\n",
        "\n",
        "---\n",
        "\n",
        "### ğŸ“ **Rastgele TensÃ¶r OluÅŸturma**\n",
        "\n",
        "Rastgele sayÄ± iÃ§eren tensÃ¶rleri oluÅŸturmak iÃ§in [`torch.rand()`](https://pytorch.org/docs/stable/generated/torch.rand.html) fonksiyonunu kullanabiliriz.  \n",
        "Bu fonksiyon, **0 ile 1** arasÄ±nda rastgele sayÄ± Ã¼reten bir tensÃ¶r oluÅŸturur.\n",
        "\n"
      ],
      "metadata": {
        "id": "IPXQkS5PjYTX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# (3, 4) boyutunda rastgele sayÄ± iÃ§eren bir tensÃ¶r oluÅŸturma\n",
        "random_tensor = torch.rand(size=(3, 4))\n",
        "\n",
        "# TensÃ¶rÃ¼ ve veri tipini yazdÄ±rma\n",
        "random_tensor, random_tensor.dtype"
      ],
      "metadata": {
        "id": "QnGv0yrIi0uY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5813cf62-bc50-4a7e-aa78-ec20258cb8a5"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[0.5246, 0.4837, 0.5311, 0.3527],\n",
              "         [0.5622, 0.5908, 0.8572, 0.4340],\n",
              "         [0.4462, 0.6054, 0.7701, 0.0760]]),\n",
              " torch.float32)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "`torch.rand()` fonksiyonunun esnekliÄŸi, `size` parametresini istediÄŸimiz gibi ayarlayabilmemizdir.\n",
        "\n",
        "Ã–rneÄŸin, yaygÄ±n bir gÃ¶rÃ¼ntÃ¼ boyutu olan `[224, 224, 3]` ÅŸeklinde ( `[yÃ¼kseklik, geniÅŸlik, renk_kanallarÄ±]` ) rastgele bir tensÃ¶r oluÅŸturmak istersek:\n"
      ],
      "metadata": {
        "id": "oUQQfwHXzxVd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# (224, 224, 3) boyutunda rastgele sayÄ± iÃ§eren bir tensÃ¶r oluÅŸturma\n",
        "random_image_size_tensor = torch.rand(size=(224, 224, 3))\n",
        "\n",
        "# TensÃ¶rÃ¼n ÅŸeklini (shape) ve boyut sayÄ±sÄ±nÄ± (ndim) kontrol etme\n",
        "random_image_size_tensor.shape, random_image_size_tensor.ndim\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fDLLZ_lQjydO",
        "outputId": "68b3afab-ccc7-4cdf-dc36-1f8819f1763a"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([224, 224, 3]), 3)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### SÄ±fÄ±rlar ve Birler(Zeros and ones)\n",
        "\n",
        "Bazen tensÃ¶rleri sadece sÄ±fÄ±r veya birlerle doldurmak isteyebilirsin.\n",
        "\n",
        "Bu durum genellikle maskeleme iÅŸlemlerinde kullanÄ±lÄ±r (bir tensÃ¶rdeki bazÄ± deÄŸerleri sÄ±fÄ±rlarla maskeleyerek modelin o deÄŸerleri Ã¶ÄŸrenmemesini saÄŸlamak gibi).\n",
        "\n",
        "Åimdi, [`torch.zeros()`](https://pytorch.org/docs/stable/generated/torch.zeros.html) kullanarak sÄ±fÄ±rlarla dolu bir tensÃ¶r oluÅŸturalÄ±m.\n",
        "\n",
        "Yine, burada `size` parametresi Ã¶nem kazanÄ±yor.\n"
      ],
      "metadata": {
        "id": "RCiwWXtRjwZ4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# (3, 4) boyutunda sÄ±fÄ±rlardan oluÅŸan bir tensÃ¶r oluÅŸturma\n",
        "zeros = torch.zeros(size=(3, 4))\n",
        "\n",
        "# TensÃ¶rÃ¼ ve veri tipini yazdÄ±rma\n",
        "zeros, zeros.dtype"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SFL-sPjhjppl",
        "outputId": "a6531da7-70fc-44f5-9bf5-9755a0706d09"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0.]]),\n",
              " torch.float32)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "AynÄ± ÅŸekilde, tÃ¼m elemanlarÄ± bir olan bir tensÃ¶r oluÅŸturmak iÃ§in [`torch.ones()`](https://pytorch.org/docs/stable/generated/torch.ones.html) fonksiyonunu kullanabiliriz.\n"
      ],
      "metadata": {
        "id": "v_AaxC8WkUEm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# (3, 4) boyutunda birlerden oluÅŸan bir tensÃ¶r oluÅŸturma\n",
        "ones = torch.ones(size=(3, 4))\n",
        "\n",
        "# TensÃ¶rÃ¼ ve veri tipini yazdÄ±rma\n",
        "ones, ones.dtype"
      ],
      "metadata": {
        "id": "lTdN5pTckYFs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cb5df86e-0e75-4279-b523-4d739a5ea9fa"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[1., 1., 1., 1.],\n",
              "         [1., 1., 1., 1.],\n",
              "         [1., 1., 1., 1.]]),\n",
              " torch.float32)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### AralÄ±k ve Benzer TensÃ¶rler OluÅŸturma\n",
        "\n",
        "Bazen 1'den 10'a veya 0'dan 100'e kadar bir sayÄ± aralÄ±ÄŸÄ± oluÅŸturmak isteyebilirsin.\n",
        "\n",
        "Bunu yapmak iÃ§in `torch.arange(start, end, step)` fonksiyonunu kullanabilirsin.\n",
        "\n",
        "Burada:\n",
        "* `start` = aralÄ±ÄŸÄ±n baÅŸlangÄ±Ã§ deÄŸeri (Ã¶rn. 0)  \n",
        "* `end` = aralÄ±ÄŸÄ±n bitiÅŸ deÄŸeri (Ã¶rn. 10)  \n",
        "* `step` = her deÄŸerin arasÄ±ndaki adÄ±m sayÄ±sÄ± (Ã¶rn. 1)  \n",
        "\n",
        "> **Not:** Python'da bir aralÄ±k oluÅŸturmak iÃ§in `range()` fonksiyonunu kullanabilirsin. Ancak PyTorch'ta `torch.range()` artÄ±k kullanÄ±lmÄ±yor ve gelecekte hata verebilir.\n"
      ],
      "metadata": {
        "id": "MLRepZ440ag0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# âš ï¸ Dikkat: torch.range() kullanÄ±mdan kaldÄ±rÄ±lmÄ±ÅŸtÄ±r (deprecated)\n",
        "zero_to_ten_deprecated = torch.range(0, 10)  # Bu kullanÄ±m gelecekte hata verebilir!\n",
        "\n",
        "# âœ… DoÄŸru kullanÄ±m: torch.arange() ile 0'dan 10'a kadar bir tensÃ¶r oluÅŸturma\n",
        "zero_to_ten = torch.arange(start=0, end=10, step=1)\n",
        "\n",
        "# TensÃ¶rÃ¼ yazdÄ±rma\n",
        "zero_to_ten"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AjNX3QXlkf7Z",
        "outputId": "2adffefc-80d1-4320-dae4-2e1479143b5f"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-18-4ec072aa6a03>:2: UserWarning: torch.range is deprecated and will be removed in a future release because its behavior is inconsistent with Python's range builtin. Instead, use torch.arange, which produces values in [start, end).\n",
            "  zero_to_ten_deprecated = torch.range(0, 10)  # Bu kullanÄ±m gelecekte hata verebilir!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bazen baÅŸka bir tensÃ¶rle aynÄ± ÅŸekle sahip bir tensÃ¶r oluÅŸturmak isteyebilirsiniz.\n",
        "\n",
        "Ã–rneÄŸin, Ã¶nceki bir tensÃ¶rle aynÄ± ÅŸekle sahip, sadece sÄ±fÄ±rlardan oluÅŸan bir tensÃ¶r.\n",
        "\n",
        "Bunu yapmak iÃ§in [`torch.zeros_like(input)`](https://pytorch.org/docs/stable/generated/torch.zeros_like.html) veya [`torch.ones_like(input)`](https://pytorch.org/docs/1.9.1/generated/torch.ones_like.html) fonksiyonlarÄ±nÄ± kullanabilirsiniz. Bu fonksiyonlar sÄ±rasÄ±yla `input` tensÃ¶rÃ¼nÃ¼n aynÄ± ÅŸekline sahip, sÄ±fÄ±rlarla veya birlerle dolu bir tensÃ¶r dÃ¶ndÃ¼rÃ¼r.\n"
      ],
      "metadata": {
        "id": "aAe8jjsPlEOR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mevcut bir tensÃ¶rle aynÄ± boyutta sÄ±fÄ±rlardan oluÅŸan bir tensÃ¶r oluÅŸturma\n",
        "ten_zeros = torch.zeros_like(input=zero_to_ten)  # zero_to_ten ile aynÄ± boyutta\n",
        "\n",
        "# OluÅŸturulan tensÃ¶rÃ¼ yazdÄ±rma\n",
        "ten_zeros"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bc9jS0O2lE-_",
        "outputId": "e3a6c8ef-60c5-409c-8344-5cb1ef23a73e"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### TensÃ¶r Veri TÃ¼rleri\n",
        "\n",
        "PyTorch'ta kullanÄ±labilir birÃ§ok farklÄ± [tensÃ¶r veri tÃ¼rÃ¼](https://pytorch.org/docs/stable/tensors.html#data-types) vardÄ±r.\n",
        "\n",
        "BazÄ±larÄ± CPU iÃ§in Ã¶zel olup, bazÄ±larÄ± ise GPU iÃ§in daha uygundur.\n",
        "\n",
        "Hangi veri tÃ¼rÃ¼nÃ¼n kullanÄ±lacaÄŸÄ±nÄ± Ã¶ÄŸrenmek zaman alabilir.\n",
        "\n",
        "Genellikle `torch.cuda` gÃ¶rdÃ¼ÄŸÃ¼nÃ¼zde, tensÃ¶rÃ¼n GPU iÃ§in kullanÄ±ldÄ±ÄŸÄ±nÄ± anlayabilirsiniz (Ã§Ã¼nkÃ¼ Nvidia GPU'larÄ± CUDA adÄ± verilen bir hesaplama araÃ§ setini kullanÄ±r).\n",
        "\n",
        "En yaygÄ±n tÃ¼r (ve genellikle varsayÄ±lan) `torch.float32` veya `torch.float`'tÄ±r.\n",
        "\n",
        "Bu, \"32-bit kayan nokta\" olarak adlandÄ±rÄ±lÄ±r.\n",
        "\n",
        "Ancak, 16-bit kayan nokta (`torch.float16` veya `torch.half`) ve 64-bit kayan nokta (`torch.float64` veya `torch.double`) da vardÄ±r.\n",
        "\n",
        "Ve iÅŸler daha da karÄ±ÅŸsÄ±n diye, ayrÄ±ca 8-bit, 16-bit, 32-bit ve 64-bit tam sayÄ±lar da vardÄ±r.\n",
        "\n",
        "DahasÄ± var!\n",
        "\n",
        "> **Not:** Bir tam sayÄ± dÃ¼z bir yuvarlak sayÄ±dÄ±r, Ã¶rneÄŸin `7` iken bir kayan nokta sayÄ±sÄ± ondalÄ±klÄ± bir deÄŸere sahiptir, Ã¶rneÄŸin `7.0`.\n",
        "\n",
        "BunlarÄ±n hepsinin nedeni **hesaplama hassasiyeti** ile ilgilidir.\n",
        "\n",
        "Hassasiyet, bir sayÄ±yÄ± tanÄ±mlamak iÃ§in kullanÄ±lan detay miktarÄ±dÄ±r.\n",
        "\n",
        "Hassasiyet deÄŸeri ne kadar yÃ¼ksekse (8, 16, 32), sayÄ±yÄ± ifade etmek iÃ§in kullanÄ±lan veri miktarÄ± ve detay da o kadar artar.\n",
        "\n",
        "Bu, derin Ã¶ÄŸrenme ve sayÄ±sal hesaplama iÃ§in Ã¶nemlidir Ã§Ã¼nkÃ¼ Ã§ok sayÄ±da iÅŸlem yapÄ±yorsunuz ve Ã¼zerinde hesaplama yapacaÄŸÄ±nÄ±z daha fazla detay olduÄŸunda, kullanmanÄ±z gereken hesaplama gÃ¼cÃ¼ de artar.\n",
        "\n",
        "Yani, dÃ¼ÅŸÃ¼k hassasiyetli veri tÃ¼rleri genellikle daha hÄ±zlÄ± hesaplanabilir ancak doÄŸruluk gibi deÄŸerlendirme Ã¶lÃ§Ã¼tlerinde performans kaybÄ±na yol aÃ§abilir (daha hÄ±zlÄ± hesaplanabilir ama daha az doÄŸru).\n",
        "\n",
        "> **Kaynaklar:**  \n",
        "  * TÃ¼m mevcut tensÃ¶r veri tÃ¼rlerinin bir listesini gÃ¶rmek iÃ§in [PyTorch belgesine gÃ¶z atÄ±n](https://pytorch.org/docs/stable/tensors.html#data-types).\n",
        "  * Hesaplamada hassasiyetin ne olduÄŸunu Ã¶ÄŸrenmek iÃ§in [Wikipedia sayfasÄ±nÄ± okuyun](https://en.wikipedia.org/wiki/Precision_(computer_science)).\n",
        "\n",
        "Åimdi belirli veri tÃ¼rlerine sahip tensÃ¶rler nasÄ±l oluÅŸturulacaÄŸÄ±nÄ± gÃ¶relim. Bunu `dtype` parametresini kullanarak yapabiliriz.\n"
      ],
      "metadata": {
        "id": "urBksgNaljOv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Belirli Veri Tipleriyle TensÃ¶r OluÅŸturma\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# 32-bit float tensÃ¶r (varsayÄ±lan)\n",
        "float32_tensor = torch.tensor([1.0, 2.0, 3.0], dtype=torch.float32)\n",
        "\n",
        "# 16-bit float tensÃ¶r\n",
        "float16_tensor = torch.tensor([1.0, 2.0, 3.0], dtype=torch.float16)\n",
        "\n",
        "# 64-bit float tensÃ¶r\n",
        "float64_tensor = torch.tensor([1.0, 2.0, 3.0], dtype=torch.float64)\n",
        "\n",
        "# 32-bit integer tensÃ¶r\n",
        "int32_tensor = torch.tensor([1, 2, 3], dtype=torch.int32)\n",
        "\n",
        "# TensÃ¶rleri yazdÄ±rma\n",
        "print(\"32-bit Float Tensor:\", float32_tensor)\n",
        "print(\"16-bit Float Tensor:\", float16_tensor)\n",
        "print(\"64-bit Float Tensor:\", float64_tensor)\n",
        "print(\"32-bit Integer Tensor:\", int32_tensor)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NNilqe53liTg",
        "outputId": "db3f4e52-ea98-4b4a-b93f-df470a00a255"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "32-bit Float Tensor: tensor([1., 2., 3.])\n",
            "16-bit Float Tensor: tensor([1., 2., 3.], dtype=torch.float16)\n",
            "64-bit Float Tensor: tensor([1., 2., 3.], dtype=torch.float64)\n",
            "32-bit Integer Tensor: tensor([1, 2, 3], dtype=torch.int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Åekil sorunlarÄ±nÄ±n (tensÃ¶r ÅŸekilleri uyumsuz olduÄŸunda) dÄ±ÅŸÄ±nda, PyTorch'ta karÅŸÄ±laÅŸacaÄŸÄ±nÄ±z diÄŸer yaygÄ±n iki sorun veri tÃ¼rÃ¼ ve cihaz sorunlarÄ±dÄ±r.\n",
        "\n",
        "Ã–rneÄŸin, bir tensÃ¶r `torch.float32` iken, diÄŸeri `torch.float16` olabilir (PyTorch, genellikle tensÃ¶rlerin aynÄ± formatta olmasÄ±nÄ± tercih eder).\n",
        "\n",
        "Ya da bir tensÃ¶rÃ¼nÃ¼z CPU'da, diÄŸer tensÃ¶rÃ¼nÃ¼z ise GPU'da olabilir (PyTorch, tensÃ¶rler arasÄ±ndaki hesaplamalarÄ±n aynÄ± cihazda yapÄ±lmasÄ±nÄ± tercih eder).\n",
        "\n",
        "Cihaz konuÅŸmasÄ±nÄ± daha sonra daha ayrÄ±ntÄ±lÄ± olarak gÃ¶receÄŸiz.\n",
        "\n",
        "Åimdi, `dtype=torch.float16` olan bir tensÃ¶r oluÅŸturalÄ±m.\n"
      ],
      "metadata": {
        "id": "5LAvuf450yJH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# VarsayÄ±lan olarak float32 tipinde bir tensÃ¶r oluÅŸturma\n",
        "float_32_tensor = torch.tensor([3.0, 6.0, 9.0],\n",
        "                               dtype=None,         # Belirtilmezse varsayÄ±lan olarak torch.float32 olur\n",
        "                               device=None,        # Belirtilmezse CPU kullanÄ±lÄ±r\n",
        "                               requires_grad=False)  # False olduÄŸu iÃ§in gradyan hesaplanmaz\n",
        "\n",
        "# TensÃ¶rÃ¼n ÅŸekli, veri tipi ve cihaz bilgisi\n",
        "float_32_tensor.shape, float_32_tensor.dtype, float_32_tensor.device\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dJ117geslupG",
        "outputId": "f5112499-f92a-49a3-fcc7-3c536eae35ce"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([3]), torch.float32, device(type='cpu'))"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## TensÃ¶rlerden Bilgi Alma\n",
        "\n",
        "Bir kez tensÃ¶rler oluÅŸturduÄŸunuzda (ya da baÅŸkasÄ± veya bir PyTorch modÃ¼lÃ¼ sizin iÃ§in oluÅŸturduÄŸunda), onlardan bazÄ± bilgiler almak isteyebilirsiniz.\n",
        "\n",
        "BunlarÄ± daha Ã¶nce gÃ¶rdÃ¼k ama tensÃ¶rler hakkÄ±nda Ã¶ÄŸrenmek isteyeceÄŸiniz Ã¼Ã§ yaygÄ±n Ã¶zellik ÅŸunlardÄ±r:\n",
        "* `shape` - TensÃ¶rÃ¼n ÅŸekli nedir? (bazÄ± iÅŸlemler belirli ÅŸekil kurallarÄ±na ihtiyaÃ§ duyar)\n",
        "* `dtype` - TensÃ¶r iÃ§inde yer alan elemanlarÄ±n veri tÃ¼rÃ¼ nedir?\n",
        "* `device` - TensÃ¶r hangi cihazda depolanÄ±yor? (genellikle GPU veya CPU)\n",
        "\n",
        "Åimdi rastgele bir tensÃ¶r oluÅŸturalÄ±m ve bununla ilgili detaylarÄ± Ã¶ÄŸrenelim.\n"
      ],
      "metadata": {
        "id": "X1Izbba5mEM6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 16-bit kayan noktalÄ± (float16) tensÃ¶r oluÅŸturma\n",
        "float_16_tensor = torch.tensor([3.0, 6.0, 9.0],\n",
        "                               dtype=torch.float16)  # torch.half da kullanÄ±labilir\n",
        "\n",
        "# TensÃ¶rÃ¼n veri tipini kontrol etme\n",
        "float_16_tensor.dtype"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0S8-IvdbmEBX",
        "outputId": "6b4a6aff-7b64-4974-d3b2-d11659e622c6"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.float16"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## â„¹ï¸ TensÃ¶rlerden Bilgi Alma\n",
        "\n",
        "TensÃ¶rler oluÅŸturduktan sonra (ister kendiniz, ister bir PyTorch modÃ¼lÃ¼ tarafÄ±ndan oluÅŸturulmuÅŸ olsun), onlarla ilgili bazÄ± bilgilere ihtiyaÃ§ duyabilirsiniz.\n",
        "\n",
        "Daha Ã¶nce de gÃ¶rdÃ¼ÄŸÃ¼mÃ¼z gibi, tensÃ¶rlerle ilgili en yaygÄ±n kullanÄ±lan Ã¼Ã§ Ã¶zellik ÅŸunlardÄ±r:\n",
        "\n",
        "- **`shape`** â†’ TensÃ¶rÃ¼n ÅŸekli nedir?  \n",
        "  (*BazÄ± iÅŸlemler belirli ÅŸekil kurallarÄ±nÄ± gerektirir.*)  \n",
        "- **`dtype`** â†’ TensÃ¶rdeki elemanlar hangi veri tÃ¼rÃ¼nde saklanÄ±yor?  \n",
        "- **`device`** â†’ TensÃ¶r hangi cihazda saklanÄ±yor? (**CPU** veya **GPU**)\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "bbyrWAvamR_W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ğŸ”¢ 3x4 boyutunda rastgele bir tensÃ¶r oluÅŸturma\n",
        "some_tensor = torch.rand(3, 4)\n",
        "\n",
        "# â„¹ï¸ TensÃ¶rÃ¼n detaylarÄ±nÄ± yazdÄ±rma\n",
        "print(\"TensÃ¶r:\\n\", some_tensor)\n",
        "print(f\"TensÃ¶rÃ¼n Åekli (Shape): {some_tensor.shape}\")\n",
        "print(f\"TensÃ¶rÃ¼n Veri Tipi (Datatype): {some_tensor.dtype}\")\n",
        "print(f\"TensÃ¶rÃ¼n CihazÄ± (Device): {some_tensor.device}\")  # VarsayÄ±lan olarak CPU'da tutulur\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZW0lYl99mSrm",
        "outputId": "26b508ea-ae88-43a0-9c3b-78bea0467f59"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensÃ¶r:\n",
            " tensor([[0.8086, 0.3897, 0.0087, 0.4006],\n",
            "        [0.3816, 0.2700, 0.0922, 0.0510],\n",
            "        [0.5456, 0.2015, 0.1747, 0.8109]])\n",
            "TensÃ¶rÃ¼n Åekli (Shape): torch.Size([3, 4])\n",
            "TensÃ¶rÃ¼n Veri Tipi (Datatype): torch.float32\n",
            "TensÃ¶rÃ¼n CihazÄ± (Device): cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> **Not:** PyTorch'ta sorunlarla karÅŸÄ±laÅŸtÄ±ÄŸÄ±nÄ±zda, genellikle yukarÄ±daki Ã¼Ã§ Ã¶zellikten biriyle ilgili bir problemle karÅŸÄ±laÅŸÄ±rsÄ±nÄ±z. Bu yÃ¼zden hata mesajlarÄ± gÃ¶rÃ¼ndÃ¼ÄŸÃ¼nde, kendinize kÃ¼Ã§Ã¼k bir ÅŸarkÄ± sÃ¶yleyin: \"what, what, where\":\n",
        "  * \"*TensÃ¶rlerimin ÅŸekli ne? Veri tÃ¼rÃ¼ ne ve nerede depolanÄ±yor? Hangi ÅŸekil, hangi veri tÃ¼rÃ¼, nerede nerede nerede*\"\n"
      ],
      "metadata": {
        "id": "zTfOogXHmptT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## TensÃ¶rleri ManipÃ¼le Etme (TensÃ¶r Operations)\n",
        "\n",
        "Derin Ã¶ÄŸrenmede, veriler (gÃ¶rÃ¼ntÃ¼ler, metinler, videolar, sesler, protein yapÄ±larÄ± vb.) tensÃ¶rler olarak temsil edilir.\n",
        "\n",
        "Bir model, bu tensÃ¶rleri inceleyerek ve tensÃ¶rler Ã¼zerinde bir dizi iÅŸlem yaparak (1.000.000'larca iÅŸlem olabilir) giriÅŸ verilerindeki desenlerin bir temsilini oluÅŸturur.\n",
        "\n",
        "Bu iÅŸlemler genellikle ÅŸu temel iÅŸlemler arasÄ±nda harika bir dans gibidir:\n",
        "* Toplama\n",
        "* Ã‡Ä±karma\n",
        "* Ã‡arpma (eleman bazÄ±nda)\n",
        "* BÃ¶lme\n",
        "* Matris Ã§arpÄ±mÄ±\n",
        "\n",
        "Ve hepsi bu kadar. Tabii ki burada ve orada birkaÃ§ ekstra iÅŸlem olabilir ama bunlar sinir aÄŸlarÄ±nÄ±n temel yapÄ± taÅŸlarÄ±dÄ±r.\n",
        "\n",
        "Bu yapÄ± taÅŸlarÄ±nÄ± doÄŸru ÅŸekilde Ã¼st Ã¼ste koyarak, en sofistike sinir aÄŸlarÄ±nÄ± oluÅŸturabilirsiniz (tÄ±pkÄ± lego gibi!).\n"
      ],
      "metadata": {
        "id": "GmgthCbYnkYO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Temel Ä°ÅŸlemler\n",
        "\n",
        "BaÅŸlangÄ±Ã§ olarak, birkaÃ§ temel iÅŸlemle baÅŸlayalÄ±m: toplama (`+`), Ã§Ä±karma (`-`), Ã§arpma (`*`).\n",
        "\n",
        "Bu iÅŸlemler, dÃ¼ÅŸÃ¼ndÃ¼ÄŸÃ¼nÃ¼z gibi Ã§alÄ±ÅŸÄ±r.\n"
      ],
      "metadata": {
        "id": "YOjjRU3unvPJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ğŸ”¢ TensÃ¶r oluÅŸturma\n",
        "tensor = torch.tensor([1, 2, 3])\n",
        "\n",
        "# â• TensÃ¶re 10 ekleme (eleman bazlÄ±)\n",
        "tensor + 10"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zY5hHpqEnz4T",
        "outputId": "ea6a0eb2-7056-4b3d-8178-91b1df359d09"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([11, 12, 13])"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# âœ–ï¸ TensÃ¶rÃ¼ 10 ile Ã§arpma (eleman bazlÄ±)\n",
        "tensor * 10"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F-1Kgg4rnv7S",
        "outputId": "b90e367a-aaaa-41b6-b061-02a6aec3a550"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([10, 20, 30])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "YukarÄ±daki tensÃ¶r deÄŸerlerinin `tensor([110, 120, 130])` ÅŸeklinde olmadÄ±ÄŸÄ±nÄ± fark ettiniz mi? Bunun nedeni, tensÃ¶rdeki deÄŸerlerin yalnÄ±zca yeniden atanmadÄ±kÃ§a deÄŸiÅŸmemesidir.\n"
      ],
      "metadata": {
        "id": "bViynErXoj7W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TensÃ¶rler yeniden atanmadÄ±kÃ§a deÄŸiÅŸmez\n",
        "tensor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aner-aWwnnKV",
        "outputId": "be92b2a7-3c4c-460d-a60e-5885a6ee0659"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 2, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Åimdi bir sayÄ±yÄ± Ã§Ä±karalÄ±m ve bu sefer `tensor` deÄŸiÅŸkenini yeniden atayalÄ±m.\n"
      ],
      "metadata": {
        "id": "kNs1MShwo48c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ã‡Ä±karma iÅŸlemi ve yeniden atama\n",
        "tensor = tensor - 10\n",
        "\n",
        "# GÃ¼ncellenmiÅŸ tensÃ¶rÃ¼ yazdÄ±rma\n",
        "print(tensor)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JWFcoNPno6KK",
        "outputId": "8ab395d4-c53f-4a44-e079-001a03d9a943"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([-9, -8, -7])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Toplama iÅŸlemi ve yeniden atama\n",
        "tensor = tensor + 10\n",
        "\n",
        "# GÃ¼ncellenmiÅŸ tensÃ¶rÃ¼ yazdÄ±rma\n",
        "print(tensor)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BuIVGv9_mE7u",
        "outputId": "113c83a1-abc6-4991-df92-7089f34be277"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1, 2, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "PyTorch ayrÄ±ca temel iÅŸlemleri gerÃ§ekleÅŸtirmek iÃ§in [`torch.mul()`](https://pytorch.org/docs/stable/generated/torch.mul.html#torch.mul) (Ã§arpma kÄ±saltmasÄ±) ve [`torch.add()`](https://pytorch.org/docs/stable/generated/torch.add.html) gibi birÃ§ok yerleÅŸik fonksiyona sahiptir.\n"
      ],
      "metadata": {
        "id": "KvuSDE7TprLl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# PyTorch fonksiyonlarÄ±nÄ± da kullanabilirsiniz\n",
        "torch.multiply(tensor, 10)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dD1q0G25pq00",
        "outputId": "0c3165ca-8122-402c-dacf-c73025ec420f"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([10, 20, 30])"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Orijinal tensÃ¶r hÃ¢lÃ¢ deÄŸiÅŸmedi\n",
        "tensor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tOtVT5j4p-7p",
        "outputId": "0bb6f749-009e-48e1-c58f-9f86b776da2f"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 2, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ancak, daha yaygÄ±n olarak `torch.mul()` yerine `*` gibi operator sembollerini kullanmak tercih edilir.\n"
      ],
      "metadata": {
        "id": "YHVL2nAJqQE0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ğŸ”¢ Eleman BazlÄ± Ã‡arpma (Her eleman aynÄ± indeksdeki elemanla Ã§arpÄ±lÄ±r: 0->0, 1->1, 2->2)\n",
        "print(tensor, \"*\", tensor)\n",
        "print(\"SonuÃ§:\", tensor * tensor)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LchV9GuxqQ18",
        "outputId": "c3f87112-2aeb-4ca0-fa9d-055345645959"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1, 2, 3]) * tensor([1, 2, 3])\n",
            "SonuÃ§: tensor([1, 4, 9])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Matris Ã‡arpÄ±mÄ± (Ä°htiyacÄ±nÄ±z Olan Her Åey)\n",
        "\n",
        "Makine Ã¶ÄŸrenimi ve derin Ã¶ÄŸrenme algoritmalarÄ±nda (sinir aÄŸlarÄ± gibi) en yaygÄ±n iÅŸlemlerden biri [matris Ã§arpÄ±mÄ±](https://www.mathsisfun.com/algebra/matrix-multiplying.html)'dÄ±r.\n",
        "\n",
        "PyTorch, matris Ã§arpÄ±mÄ± iÅŸlevselliÄŸini [`torch.matmul()`](https://pytorch.org/docs/stable/generated/torch.matmul.html) metodunda saÄŸlar.\n",
        "\n",
        "Matris Ã§arpÄ±mÄ±yla ilgili hatÄ±rlamanÄ±z gereken iki ana kural ÅŸunlardÄ±r:\n",
        "\n",
        "1. **Ä°Ã§ boyutlar** uyumlu olmalÄ±dÄ±r:\n",
        "  * `(3, 2) @ (3, 2)` Ã§alÄ±ÅŸmaz\n",
        "  * `(2, 3) @ (3, 2)` Ã§alÄ±ÅŸÄ±r\n",
        "  * `(3, 2) @ (2, 3)` Ã§alÄ±ÅŸÄ±r\n",
        "2. SonuÃ§ matrisi **dÄ±ÅŸ boyutlar**a sahip olur:\n",
        " * `(2, 3) @ (3, 2)` -> `(2, 2)`\n",
        " * `(3, 2) @ (2, 3)` -> `(3, 3)`\n",
        "\n",
        "> **Not:** Python'da \"`@`\" sembolÃ¼ matris Ã§arpÄ±mÄ±nÄ± temsil eder.\n",
        "\n",
        "> **Kaynak:** `torch.matmul()` ile matris Ã§arpÄ±mÄ±nÄ±n tÃ¼m kurallarÄ±nÄ± [PyTorch belgesinde](https://pytorch.org/docs/stable/generated/torch.matmul.html) gÃ¶rebilirsiniz.\n",
        "\n",
        "Åimdi bir tensÃ¶r oluÅŸturalÄ±m ve Ã¼zerinde eleman bazÄ±nda Ã§arpma ve matris Ã§arpÄ±mÄ± iÅŸlemleri yapalÄ±m.\n"
      ],
      "metadata": {
        "id": "EPFpO80bqiDl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "tensor = torch.tensor([1, 2, 3])\n",
        "tensor.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qtl3wk1jqjfr",
        "outputId": "f607c5eb-577f-48d2-ca2b-838874643cc0"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3])"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Eleman bazÄ±nda Ã§arpma ile matris Ã§arpÄ±mÄ± arasÄ±ndaki fark, deÄŸerlerin eklenmesidir.\n",
        "\n",
        "`tensor` deÄŸiÅŸkenimiz iÃ§in `[1, 2, 3]` deÄŸerleriyle:\n",
        "\n",
        "| Ä°ÅŸlem | Hesaplama | Kod |\n",
        "| ----- | ----- | ----- |\n",
        "| **Eleman bazÄ±nda Ã§arpma** | `[1*1, 2*2, 3*3]` = `[1, 4, 9]` | `tensor * tensor` |\n",
        "| **Matris Ã§arpÄ±mÄ±** | `[1*1 + 2*2 + 3*3]` = `[14]` | `tensor.matmul(tensor)` |\n"
      ],
      "metadata": {
        "id": "IkVJdXydqwUc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# â— Eleman BazlÄ± Ã‡arpma (Element-wise Multiplication)\n",
        "tensor * tensor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GW85IddGqxS1",
        "outputId": "95b9244c-20d5-4e23-cb79-5ea74b329e8c"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 4, 9])"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#matris Ã§arpÄ±mÄ± (matrix multiplication)\n",
        "torch.matmul(tensor, tensor)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "32l6g82qq7I8",
        "outputId": "0e37d3dc-7d59-4865-cf87-41583bad579f"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(14)"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Matris Ã§arpÄ±mÄ± iÃ§in \"@\" sembolÃ¼ de kullanÄ±labilir, ancak Ã¶nerilmez.\n",
        "tensor @ tensor\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7_3rWam8rGvj",
        "outputId": "34fba771-a78d-4764-dd48-984d5e7ab0d6"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(14)"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Matris Ã§arpÄ±mÄ±nÄ± elle yapabilirsiniz, ancak bu Ã¶nerilmez.\n",
        "\n",
        "YerleÅŸik `torch.matmul()` metodu daha hÄ±zlÄ±dÄ±r.\n"
      ],
      "metadata": {
        "id": "EADDMNLXrK6H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "# ğŸŸ° Elle Matris Ã‡arpÄ±mÄ± (Manuel Hesaplama)\n",
        "# â— For dÃ¶ngÃ¼leriyle iÅŸlem yapmaktan kaÃ§Ä±nÄ±n, Ã§Ã¼nkÃ¼ hesaplama maliyeti yÃ¼ksektir!\n",
        "\n",
        "value = 0\n",
        "for i in range(len(tensor)):\n",
        "    value += tensor[i] * tensor[i]\n",
        "\n",
        "# Sonucu yazdÄ±rma\n",
        "value"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4udTBTTLrLxk",
        "outputId": "9ae28312-02f6-4fc0-95de-f62ab5d7e3b1"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 2.99 ms, sys: 9 Âµs, total: 3 ms\n",
            "Wall time: 6.92 ms\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(14)"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "# ğŸŸ° Matris Ã‡arpÄ±mÄ± - PyTorch YerleÅŸik Fonksiyonu ile\n",
        "torch.matmul(tensor, tensor)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vt0gZJWwrZZR",
        "outputId": "fc4518dd-125d-4df9-938d-9bf66de73b44"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 70 Âµs, sys: 20 Âµs, total: 90 Âµs\n",
            "Wall time: 94.2 Âµs\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(14)"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Derin Ã–ÄŸrenmedeki En YaygÄ±n Hatalardan Biri (Åekil HatalarÄ±)\n",
        "\n",
        "Ã‡Ã¼nkÃ¼ derin Ã¶ÄŸrenmenin Ã§oÄŸu, matrisler Ã¼zerinde Ã§arpma ve iÅŸlemler yapmaktan ibarettir ve matrislerin, hangi ÅŸekil ve boyutlarÄ±n birleÅŸtirilebileceÄŸi konusunda sÄ±kÄ± kurallarÄ± vardÄ±r, derin Ã¶ÄŸrenmede karÅŸÄ±laÅŸabileceÄŸiniz en yaygÄ±n hatalardan biri ÅŸekil uyumsuzluklarÄ±dÄ±r.\n"
      ],
      "metadata": {
        "id": "m-miMQuorZIx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ğŸ”¢ Ä°ki tensÃ¶r oluÅŸturuluyor\n",
        "tensor_A = torch.tensor([[1, 2],\n",
        "                         [3, 4],\n",
        "                         [5, 6]], dtype=torch.float32)\n",
        "\n",
        "tensor_B = torch.tensor([[7, 10],\n",
        "                         [8, 11],\n",
        "                         [9, 12]], dtype=torch.float32)\n",
        "\n",
        "# ğŸŸ° Matris Ã§arpÄ±mÄ± (Bu iÅŸlem hata verecek!)\n",
        "torch.matmul(tensor_A, tensor_B)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "id": "4TpXvTlCr5OC",
        "outputId": "2c7d2287-1eda-4d0f-beb7-1ce8d7fe1116"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "mat1 and mat2 shapes cannot be multiplied (3x2 and 3x2)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-38-6839c54cdfcb>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# ğŸŸ° Matris Ã§arpÄ±mÄ± (Bu iÅŸlem hata verecek!)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor_A\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_B\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (3x2 and 3x2)"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "`tensor_A` ve `tensor_B` arasÄ±ndaki matris Ã§arpÄ±mÄ±nÄ± iÃ§ boyutlarÄ±nÄ± eÅŸleÅŸtirerek Ã§alÄ±ÅŸtÄ±rabiliriz.\n",
        "\n",
        "Bunu yapmanÄ±n yollarÄ±ndan biri, **transpoz** iÅŸlemidir (verilen bir tensÃ¶rÃ¼n boyutlarÄ±nÄ± deÄŸiÅŸtirmek).\n",
        "\n",
        "PyTorch'ta transpoz iÅŸlemini ÅŸu ÅŸekilde gerÃ§ekleÅŸtirebilirsiniz:\n",
        "* `torch.transpose(input, dim0, dim1)` - burada `input` transpoze edilecek tensÃ¶rdÃ¼r ve `dim0` ve `dim1` deÄŸiÅŸtirilmesi gereken boyutlardÄ±r.\n",
        "* `tensor.T` - burada `tensor` transpoze edilecek tensÃ¶rdÃ¼r.\n",
        "\n",
        "Åimdi ikincisini deneyelim.\n"
      ],
      "metadata": {
        "id": "iMJImG1n2lyo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# tensor_A ve tensor_B'yi gÃ¶rÃ¼ntÃ¼le\n",
        "print(tensor_A)\n",
        "print(tensor_B)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WoTIHTeQsXMp",
        "outputId": "4d8b76b8-c495-41bf-d754-f0f753e1f006"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 2.],\n",
            "        [3., 4.],\n",
            "        [5., 6.]])\n",
            "tensor([[ 7., 10.],\n",
            "        [ 8., 11.],\n",
            "        [ 9., 12.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# tensor_A ve tensor_B.T'yi gÃ¶rÃ¼ntÃ¼le\n",
        "print(tensor_A)\n",
        "print(tensor_B.T)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a3tbwyIKsb8T",
        "outputId": "39fb1d90-620f-43ce-9f3d-dca03a2f0703"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 2.],\n",
            "        [3., 4.],\n",
            "        [5., 6.]])\n",
            "tensor([[ 7.,  8.,  9.],\n",
            "        [10., 11., 12.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# tensor_B transpozu alÄ±ndÄ±ÄŸÄ±nda iÅŸlem Ã§alÄ±ÅŸÄ±r\n",
        "print(f\"Original shapes: tensor_A = {tensor_A.shape}, tensor_B = {tensor_B.shape}\\n\")\n",
        "print(f\"New shapes: tensor_A = {tensor_A.shape} (same as above), tensor_B.T = {tensor_B.T.shape}\\n\")\n",
        "print(f\"Multiplying: {tensor_A.shape} * {tensor_B.T.shape} <- inner dimensions match\\n\")\n",
        "print(\"Output:\\n\")\n",
        "\n",
        "# Matris Ã§arpÄ±mÄ±nÄ± yap\n",
        "output = torch.matmul(tensor_A, tensor_B.T)\n",
        "print(output)\n",
        "print(f\"\\nOutput shape: {output.shape}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "upDoZfRrsirc",
        "outputId": "25c9db22-60a7-4e14-f57b-ff9762b8a8f0"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original shapes: tensor_A = torch.Size([3, 2]), tensor_B = torch.Size([3, 2])\n",
            "\n",
            "New shapes: tensor_A = torch.Size([3, 2]) (same as above), tensor_B.T = torch.Size([2, 3])\n",
            "\n",
            "Multiplying: torch.Size([3, 2]) * torch.Size([2, 3]) <- inner dimensions match\n",
            "\n",
            "Output:\n",
            "\n",
            "tensor([[ 27.,  30.,  33.],\n",
            "        [ 61.,  68.,  75.],\n",
            "        [ 95., 106., 117.]])\n",
            "\n",
            "Output shape: torch.Size([3, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "AyrÄ±ca `torch.mm()` fonksiyonunu da kullanabilirsiniz, bu fonksiyon `torch.matmul()`'Ä±n kÄ±saltmasÄ±dÄ±r.\n"
      ],
      "metadata": {
        "id": "5TGWnw0IsqM2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# torch.mm, matmul iÃ§in bir kÄ±saltmadÄ±r\n",
        "torch.mm(tensor_A, tensor_B.T)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "57DvtpxNsrlw",
        "outputId": "4269bf58-4d2e-4421-cc58-ff7cde548543"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 27.,  30.,  33.],\n",
              "        [ 61.,  68.,  75.],\n",
              "        [ 95., 106., 117.]])"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Transpoz iÅŸlemi yapÄ±lmadan, matris Ã§arpÄ±mÄ± kurallarÄ± yerine getirilmediÄŸi iÃ§in yukarÄ±daki gibi bir hata alÄ±rÄ±z.\n",
        "\n",
        "Peki ya bir gÃ¶rsel?\n",
        "\n",
        "![Matris Ã§arpÄ±mÄ±nÄ±n gÃ¶rsel demosu](https://github.com/mrdbourke/pytorch-deep-learning/raw/main/images/00-matrix-multiply-crop.gif)\n",
        "\n",
        "Kendi matris Ã§arpÄ±mÄ± gÃ¶rsellerinizi ÅŸu adreste oluÅŸturabilirsiniz: [http://matrixmultiplication.xyz/](http://matrixmultiplication.xyz/).\n",
        "\n",
        "> **Not:** Bu tÃ¼r bir matris Ã§arpÄ±mÄ±, iki matrisin [**nokta Ã§arpÄ±mÄ±**](https://www.mathsisfun.com/algebra/vectors-dot-product.html) olarak da adlandÄ±rÄ±lÄ±r.\n"
      ],
      "metadata": {
        "id": "VfaQf7fSsbrn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sinir aÄŸlarÄ±, matris Ã§arpÄ±mlarÄ± ve nokta Ã§arpÄ±mlarÄ± ile doludur.\n",
        "\n",
        "[`torch.nn.Linear()`](https://pytorch.org/docs/1.9.1/generated/torch.nn.Linear.html) modÃ¼lÃ¼ (bunu daha sonra pratikte gÃ¶receÄŸiz), aynÄ± zamanda bir ileri besleme katmanÄ± veya tam baÄŸlÄ± katman olarak bilinir, bir giriÅŸ `x` ile bir aÄŸÄ±rlÄ±k matrisi `A` arasÄ±nda matris Ã§arpÄ±mÄ± uygular.\n",
        "\n",
        "$$\n",
        "y = x\\cdot{A^T} + b\n",
        "$$\n",
        "\n",
        "Burada:\n",
        "* `x` katmanÄ±n giriÅŸi (derin Ã¶ÄŸrenme, `torch.nn.Linear()` gibi katmanlarÄ±n birbirinin Ã¼zerine yÄ±ÄŸÄ±ldÄ±ÄŸÄ± bir yapÄ±dÄ±r).\n",
        "* `A` katman tarafÄ±ndan oluÅŸturulan aÄŸÄ±rlÄ±k matrisidir, baÅŸlangÄ±Ã§ta rastgele sayÄ±larla baÅŸlar ve bir sinir aÄŸÄ±, verilerdeki desenleri daha iyi temsil edecek ÅŸekilde bunlarÄ± ayarladÄ±kÃ§a deÄŸiÅŸtirilir (buradaki \"`T`\", Ã§Ã¼nkÃ¼ aÄŸÄ±rlÄ±k matrisi transpoze edilir).\n",
        "  * **Not:** AÄŸÄ±rlÄ±k matrisini gÃ¶stermek iÃ§in genellikle `W` veya `X` gibi baÅŸka harfler de kullanÄ±lÄ±r.\n",
        "* `b` aÄŸÄ±rlÄ±klarÄ± ve giriÅŸleri biraz kaydÄ±rmak iÃ§in kullanÄ±lan bias terimidir.\n",
        "* `y` Ã§Ä±ktÄ±dÄ±r (giriÅŸin bir manipÃ¼lasyonu, bununla verilerdeki desenleri keÅŸfetmeye Ã§alÄ±ÅŸÄ±lÄ±r).\n",
        "\n",
        "Bu, bir doÄŸrusal fonksiyondur (lisede veya baÅŸka bir yerde $y = mx+b$ gibi bir ÅŸey gÃ¶rmÃ¼ÅŸ olabilirsiniz), ve bir doÄŸru Ã§izmeyi saÄŸlar!\n",
        "\n",
        "Åimdi doÄŸrusal bir katman ile oynayalÄ±m.\n",
        "\n",
        "AÅŸaÄŸÄ±daki `in_features` ve `out_features` deÄŸerlerini deÄŸiÅŸtirin ve ne olduÄŸunu gÃ¶rÃ¼n.\n",
        "\n",
        "Åekillerle ilgili bir ÅŸey fark ettiniz mi?\n"
      ],
      "metadata": {
        "id": "zCPC4Kf1tCGL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ğŸ”¢ Rasgele aÄŸÄ±rlÄ±klar matrisinin tekrarlanabilir olmasÄ±nÄ± saÄŸlamak iÃ§in manuel tohum belirleme\n",
        "torch.manual_seed(42)\n",
        "\n",
        "# ğŸŸ° DoÄŸrusal katmanÄ± oluÅŸturma\n",
        "linear = torch.nn.Linear(in_features=2,  # in_features = giriÅŸin iÃ§ boyutuyla uyumlu\n",
        "                         out_features=6)  # out_features = dÄ±ÅŸ boyutunu tanÄ±mlar\n",
        "\n",
        "# ğŸ§‘â€ğŸ’» GiriÅŸ tensÃ¶rÃ¼nÃ¼ tanÄ±mlama\n",
        "x = tensor_A\n",
        "\n",
        "# ğŸ”„ Ã‡Ä±kÄ±ÅŸÄ± hesaplama\n",
        "output = linear(x)\n",
        "\n",
        "# SonuÃ§larÄ± yazdÄ±rma\n",
        "print(f\"GiriÅŸ ÅŸekli: {x.shape}\\n\")\n",
        "print(f\"Ã‡Ä±ktÄ±:\\n{output}\\n\\nÃ‡Ä±ktÄ± ÅŸekli: {output.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Q3ZnTQRs_rm",
        "outputId": "bfdf88cb-020b-4d90-f4fc-90d1ac615687"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GiriÅŸ ÅŸekli: torch.Size([3, 2])\n",
            "\n",
            "Ã‡Ä±ktÄ±:\n",
            "tensor([[2.2368, 1.2292, 0.4714, 0.3864, 0.1309, 0.9838],\n",
            "        [4.4919, 2.1970, 0.4469, 0.5285, 0.3401, 2.4777],\n",
            "        [6.7469, 3.1648, 0.4224, 0.6705, 0.5493, 3.9716]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "\n",
            "Ã‡Ä±ktÄ± ÅŸekli: torch.Size([3, 6])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> **Soru:** YukarÄ±da `in_features` deÄŸerini 2'den 3'e deÄŸiÅŸtirirseniz ne olur? Bir hata alÄ±r mÄ±sÄ±nÄ±z? GiriÅŸi (`x`) hataya uyacak ÅŸekilde nasÄ±l deÄŸiÅŸtirebilirsiniz? Ä°pucu: YukarÄ±da `tensor_B` ile ne yapmamÄ±z gerektiÄŸini hatÄ±rlayÄ±n.\n"
      ],
      "metadata": {
        "id": "-eSn9Pj9ti3x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "EÄŸer daha Ã¶nce yapmadÄ±ysanÄ±z, matris Ã§arpÄ±mÄ± baÅŸlangÄ±Ã§ta kafa karÄ±ÅŸtÄ±rÄ±cÄ± bir konu olabilir.\n",
        "\n",
        "Ama birkaÃ§ kez Ã¼zerinde oynayÄ±p, hatta bazÄ± sinir aÄŸlarÄ±nÄ± aÃ§Ä±p inceledikten sonra, her yerde olduÄŸunu fark edeceksiniz.\n",
        "\n",
        "UnutmayÄ±n, matris Ã§arpÄ±mÄ± tek ihtiyacÄ±nÄ±z olan ÅŸey.\n",
        "\n",
        "![Matris Ã§arpÄ±mÄ± tek ihtiyacÄ±nÄ±z olan ÅŸey](https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/images/00_matrix_multiplication_is_all_you_need.jpeg)\n",
        "\n",
        "*Sinir aÄŸÄ± katmanlarÄ±na girmeye baÅŸladÄ±ÄŸÄ±nÄ±zda ve kendi katmanlarÄ±nÄ±zÄ± inÅŸa ettiÄŸinizde, matris Ã§arpÄ±mlarÄ±nÄ± her yerde bulacaksÄ±nÄ±z. **Kaynak:** https://marksaroufim.substack.com/p/working-class-deep-learner*\n"
      ],
      "metadata": {
        "id": "c3SB56yPtkfx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Min, max, mean, sum gibi iÅŸlemlerle toplama (aggregation)\n",
        "\n",
        "Åimdi tensÃ¶rleri nasÄ±l manipÃ¼le edebileceÄŸimizi gÃ¶rdÃ¼k, ÅŸimdi de bunlarÄ± **toplayarak** (daha fazla deÄŸerden daha az deÄŸere) nasÄ±l iÅŸlem yapabileceÄŸimizi gÃ¶relim.\n",
        "\n",
        "Ã–nce bir tensÃ¶r oluÅŸturacaÄŸÄ±z ve ardÄ±ndan bu tensÃ¶rÃ¼n **max**, **min**, **mean** ve **sum** gibi deÄŸerlerini bulacaÄŸÄ±z.\n",
        "\n"
      ],
      "metadata": {
        "id": "zb7i2MHxtwt4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ğŸ”¢ Bir tensÃ¶r oluÅŸturma\n",
        "x = torch.arange(0, 100, 10)\n",
        "print(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lSE8auantx2q",
        "outputId": "f73100c6-9d05-4740-ee7e-6693d2c334db"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 0, 10, 20, 30, 40, 50, 60, 70, 80, 90])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's perform some aggregation."
      ],
      "metadata": {
        "id": "P4zW97oSt8ct"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Minimum deÄŸeri yazdÄ±rma\n",
        "print(f\"Minimum: {x.min()}\")\n",
        "\n",
        "# Maksimum deÄŸeri yazdÄ±rma\n",
        "print(f\"Maximum: {x.max()}\")\n",
        "\n",
        "# OrtalamayÄ± yazdÄ±rma (Hata alÄ±r Ã§Ã¼nkÃ¼ integer tensÃ¶rde mean kullanÄ±lamaz)\n",
        "# print(f\"Mean: {x.mean()}\") # Bu hata verir\n",
        "\n",
        "# OrtalamayÄ± doÄŸru ÅŸekilde yazdÄ±rma (float32 veri tipi ile)\n",
        "print(f\"Mean: {x.type(torch.float32).mean()}\") # float32 veri tipi ile Ã§alÄ±ÅŸÄ±r\n",
        "\n",
        "# Toplam deÄŸeri yazdÄ±rma\n",
        "print(f\"Sum: {x.sum()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i3EmMTbst9C1",
        "outputId": "b8e4803f-9866-4d28-eb2a-122647d26ca2"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Minimum: 0\n",
            "Maximum: 90\n",
            "Mean: 45.0\n",
            "Sum: 450\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> **Not:**  \n",
        "> BazÄ± yÃ¶ntemlerin, Ã¶rneÄŸin **`torch.mean()`**, tensÃ¶rlerin **`torch.float32`** (en yaygÄ±n) veya baÅŸka bir Ã¶zel veri tipinde olmasÄ±nÄ± gerektirdiÄŸini gÃ¶rebilirsiniz, aksi takdirde iÅŸlem baÅŸarÄ±sÄ±z olur.\n",
        "\n",
        "AÅŸaÄŸÄ±da yapmÄ±ÅŸ olduÄŸumuz iÅŸlemi **`torch`** yÃ¶ntemleriyle de gerÃ§ekleÅŸtirebilirsiniz.\n"
      ],
      "metadata": {
        "id": "TzqcSufIujOw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.max(x), torch.min(x), torch.mean(x.type(torch.float32)), torch.sum(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZBdB3deKuj4K",
        "outputId": "e49354c9-5918-40d3-d29e-017165ebda1e"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(90), tensor(0), tensor(45.), tensor(450))"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Pozisyonel Min/Max**\n",
        "\n",
        "Bir tensÃ¶rde maksimum veya minimum deÄŸerin bulunduÄŸu **indeksi** bulmak iÃ§in sÄ±rasÄ±yla **`torch.argmax()`** ve **`torch.argmin()`** fonksiyonlarÄ±nÄ± kullanabilirsiniz.\n",
        "\n",
        "Bu, **en yÃ¼ksek (veya en dÃ¼ÅŸÃ¼k) deÄŸerin** pozisyonunu bilmek istediÄŸinizde faydalÄ±dÄ±r, ancak **deÄŸerin kendisini** deÄŸil. (Bunu, [softmax aktivasyon fonksiyonunu](https://pytorch.org/docs/stable/generated/torch.nn.Softmax.html) kullandÄ±ÄŸÄ±mÄ±z ilerleyen bÃ¶lÃ¼mlerde gÃ¶receÄŸiz).\n"
      ],
      "metadata": {
        "id": "hUYhsUrCuvn3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ğŸ”¢ TensÃ¶r oluÅŸturma\n",
        "tensor = torch.arange(10, 100, 10)\n",
        "print(f\"TensÃ¶r: {tensor}\")\n",
        "\n",
        "# Maksimum ve minimum deÄŸerlerin indekslerini dÃ¶ndÃ¼rme\n",
        "print(f\"Max deÄŸerin bulunduÄŸu indeks: {tensor.argmax()}\")\n",
        "print(f\"Min deÄŸerin bulunduÄŸu indeks: {tensor.argmin()}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aEcJ39qlu0V3",
        "outputId": "2ea86a5a-2e9c-46a0-ceee-9f13c75083bb"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensÃ¶r: tensor([10, 20, 30, 40, 50, 60, 70, 80, 90])\n",
            "Max deÄŸerin bulunduÄŸu indeks: 8\n",
            "Min deÄŸerin bulunduÄŸu indeks: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### TensÃ¶r Veri TÃ¼rÃ¼nÃ¼ DeÄŸiÅŸtirme\n",
        "\n",
        "Daha Ã¶nce belirtildiÄŸi gibi, derin Ã¶ÄŸrenme iÅŸlemleriyle ilgili yaygÄ±n bir sorun, tensÃ¶rlerin farklÄ± veri tÃ¼rlerinde olmasÄ±dÄ±r.\n",
        "\n",
        "Bir tensÃ¶r `torch.float64` tÃ¼rÃ¼nde, diÄŸer tensÃ¶r ise `torch.float32` tÃ¼rÃ¼nde olduÄŸunda bazÄ± hatalarla karÅŸÄ±laÅŸabilirsiniz.\n",
        "\n",
        "Ama bunun bir Ã§Ã¶zÃ¼mÃ¼ var.\n",
        "\n",
        "TensÃ¶rlerin veri tÃ¼rlerini, [`torch.Tensor.type(dtype=None)`](https://pytorch.org/docs/stable/generated/torch.Tensor.type.html) fonksiyonu ile deÄŸiÅŸtirebilirsiniz. Burada `dtype` parametresi, kullanmak istediÄŸiniz veri tÃ¼rÃ¼dÃ¼r.\n",
        "\n",
        "Ä°lk olarak bir tensÃ¶r oluÅŸturacaÄŸÄ±z ve veri tÃ¼rÃ¼nÃ¼ kontrol edeceÄŸiz (varsayÄ±lan `torch.float32`'dir).\n"
      ],
      "metadata": {
        "id": "kuxaVo3yvC5x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ğŸ”¢ TensÃ¶r oluÅŸturma ve veri tipini kontrol etme\n",
        "tensor = torch.arange(10., 100., 10.)\n",
        "print(tensor.dtype)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ii-GL0u4vChl",
        "outputId": "a7b2b7c0-68f5-4cc7-b03c-beedcb3938b7"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.float32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Åimdi, daha Ã¶nce oluÅŸturduÄŸumuz gibi baÅŸka bir tensÃ¶r oluÅŸturacaÄŸÄ±z ama bu sefer veri tÃ¼rÃ¼nÃ¼ `torch.float16` olarak deÄŸiÅŸtireceÄŸiz.\n"
      ],
      "metadata": {
        "id": "gvH5fe_vvOPM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ğŸ”¢ float16 veri tipiyle bir tensÃ¶r oluÅŸturma\n",
        "tensor_float16 = tensor.type(torch.float16)\n",
        "print(tensor_float16)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nTTsfJB4vOv1",
        "outputId": "3b244d81-4c02-4347-bb3c-8f994a45263c"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([10., 20., 30., 40., 50., 60., 70., 80., 90.], dtype=torch.float16)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ve benzer ÅŸekilde, bir **`torch.int8`** tensÃ¶rÃ¼ oluÅŸturmak iÃ§in aynÄ± iÅŸlemi yapabiliriz.\n"
      ],
      "metadata": {
        "id": "A2xPbEG0vY5j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ğŸ”¢ int8 veri tipiyle bir tensÃ¶r oluÅŸturma\n",
        "tensor_int8 = tensor.type(torch.int8)\n",
        "print(tensor_int8)\n"
      ],
      "metadata": {
        "id": "FhdgZJJwvZvi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ec9ab15-7def-4def-c103-723553cb8883"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([10, 20, 30, 40, 50, 60, 70, 80, 90], dtype=torch.int8)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> **Not:** FarklÄ± veri tÃ¼rleri baÅŸlangÄ±Ã§ta kafa karÄ±ÅŸtÄ±rÄ±cÄ± olabilir. Ama ÅŸÃ¶yle dÃ¼ÅŸÃ¼nÃ¼n, sayÄ±nÄ±n deÄŸeri ne kadar kÃ¼Ã§Ã¼kse (Ã¶rneÄŸin 32, 16, 8), bilgisayar o deÄŸeri o kadar az hassasiyetle depolar. Ve daha az depolama ile bu genellikle daha hÄ±zlÄ± hesaplamalar ve daha kÃ¼Ã§Ã¼k bir modelle sonuÃ§lanÄ±r. Mobil tabanlÄ± sinir aÄŸlarÄ± genellikle 8-bit tam sayÄ±larla Ã§alÄ±ÅŸÄ±r, daha kÃ¼Ã§Ã¼k ve daha hÄ±zlÄ± Ã§alÄ±ÅŸtÄ±rÄ±lÄ±rlar ancak float32 karÅŸÄ±lÄ±klarÄ±na gÃ¶re daha az doÄŸrudur. Bununla ilgili daha fazla bilgi iÃ§in [hesaplama hassasiyeti](https://en.wikipedia.org/wiki/Precision_(computer_science)) hakkÄ±nda okuyabilirsiniz.\n",
        "\n",
        "> **Egzersiz:** Åu ana kadar bir dizi tensÃ¶r metodunu inceledik, ancak [`torch.Tensor` belgesinde](https://pytorch.org/docs/stable/tensors.html) daha bir sÃ¼rÃ¼ metod bulunuyor. 10 dakika boyunca belgenin iÃ§inde gezinip ilgini Ã§ekenleri incelemeni tavsiye ederim. Onlara tÄ±klayarak ve kodla kendin yazÄ±p ne olduÄŸunu gÃ¶rmek oldukÃ§a Ã¶ÄŸretici olacaktÄ±r.\n"
      ],
      "metadata": {
        "id": "PhcIxnQZvimz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Yeniden Åekillendirme, YÄ±ÄŸÄ±nlama, SÄ±kÄ±ÅŸtÄ±rma ve UnsÄ±kÄ±ÅŸtÄ±rma\n",
        "\n",
        "Ã‡oÄŸu zaman, tensÃ¶rlerin iÃ§inde deÄŸerleri deÄŸiÅŸtirmeden yalnÄ±zca boyutlarÄ±nÄ± deÄŸiÅŸtirmek istersiniz.\n",
        "\n",
        "Bunu yapmak iÃ§in bazÄ± popÃ¼ler yÃ¶ntemler ÅŸunlardÄ±r:\n",
        "\n",
        "| YÃ¶ntem | KÄ±sa aÃ§Ä±klama |\n",
        "| ----- | ----- |\n",
        "| [`torch.reshape(input, shape)`](https://pytorch.org/docs/stable/generated/torch.reshape.html#torch.reshape) | `input`'Ä± uyumluysa `shape`'a yeniden ÅŸekillendirir, `torch.Tensor.reshape()` da kullanÄ±labilir. |\n",
        "| [`Tensor.view(shape)`](https://pytorch.org/docs/stable/generated/torch.Tensor.view.html) | Orijinal tensÃ¶rÃ¼n yeni bir `shape`'te gÃ¶rÃ¼nÃ¼mÃ¼nÃ¼ dÃ¶ndÃ¼rÃ¼r ancak orijinal tensÃ¶rle aynÄ± veriyi paylaÅŸÄ±r. |\n",
        "| [`torch.stack(tensors, dim=0)`](https://pytorch.org/docs/1.9.1/generated/torch.stack.html) | Bir dizi `tensors`'Ä± yeni bir boyut (`dim`) boyunca birleÅŸtirir, tÃ¼m `tensors` aynÄ± boyutta olmalÄ±dÄ±r. |\n",
        "| [`torch.squeeze(input)`](https://pytorch.org/docs/stable/generated/torch.squeeze.html) | `input`'Ä± sÄ±kÄ±ÅŸtÄ±rarak deÄŸeri `1` olan tÃ¼m boyutlarÄ± kaldÄ±rÄ±r. |\n",
        "| [`torch.unsqueeze(input, dim)`](https://pytorch.org/docs/1.9.1/generated/torch.unsqueeze.html) | `input`'Ä±, `dim` boyutunda deÄŸeri `1` olan bir boyut ekleyerek dÃ¶ndÃ¼rÃ¼r. |\n",
        "| [`torch.permute(input, dims)`](https://pytorch.org/docs/stable/generated/torch.permute.html) | Orijinal `input`'Ä±n bir *gÃ¶rÃ¼nÃ¼mÃ¼nÃ¼* dÃ¶ndÃ¼rÃ¼r, boyutlarÄ± `dims`'e gÃ¶re dÃ¼zenlenmiÅŸtir. |\n",
        "\n",
        "Peki neden bunlarÄ± yapalÄ±m?\n",
        "\n",
        "Ã‡Ã¼nkÃ¼ derin Ã¶ÄŸrenme modelleri (sinir aÄŸlarÄ±) her yÃ¶nÃ¼yle tensÃ¶rleri manipÃ¼le etmekle ilgilidir. Ve matris Ã§arpÄ±mÄ± kurallarÄ± nedeniyle, eÄŸer ÅŸekil uyumsuzluklarÄ± varsa, hatalarla karÅŸÄ±laÅŸÄ±rsÄ±nÄ±z. Bu yÃ¶ntemler, tensÃ¶rlerinizin doÄŸru elemanlarÄ±nÄ±n, diÄŸer tensÃ¶rlerle doÄŸru elemanlarla karÄ±ÅŸmasÄ±nÄ± saÄŸlamanÄ±za yardÄ±mcÄ± olur.\n",
        "\n",
        "Åimdi bunlarÄ± deneyelim.\n",
        "\n",
        "Ä°lk olarak bir tensÃ¶r oluÅŸturalÄ±m.\n"
      ],
      "metadata": {
        "id": "T6K8WWVmvwBU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TensÃ¶r OluÅŸturma\n",
        "import torch\n",
        "x = torch.arange(1., 8.)\n",
        "x, x.shape\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZBhQT02gvjpf",
        "outputId": "afe33d36-3b3c-4965-a04e-9f502978e932"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([1., 2., 3., 4., 5., 6., 7.]), torch.Size([7]))"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Åimdi **`torch.reshape()`** ile ekstra bir boyut ekleyelim.\n"
      ],
      "metadata": {
        "id": "BNyV67IOwAaD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ekstra bir boyut ekleme\n",
        "x_reshaped = x.reshape(1, 7)\n",
        "x_reshaped, x_reshaped.shape\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tbBhfHfYwBZ_",
        "outputId": "f624000f-3210-4623-feea-4dd65bea3939"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[1., 2., 3., 4., 5., 6., 7.]]), torch.Size([1, 7]))"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "AyrÄ±ca gÃ¶rÃ¼nÃ¼mÃ¼ **`torch.view()`** ile deÄŸiÅŸtirebiliriz.\n"
      ],
      "metadata": {
        "id": "ocWzkKMpwSsQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# GÃ¶rÃ¼nÃ¼mÃ¼ deÄŸiÅŸtir (aynÄ± veriyi korur ancak gÃ¶rÃ¼nÃ¼mÃ¼ deÄŸiÅŸtirir)\n",
        "# Daha fazla bilgi: https://stackoverflow.com/a/54507446/7900723\n",
        "z = x.view(1, 7)\n",
        "z, z.shape\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m6PUtz_bwTnv",
        "outputId": "559a0e90-998c-42ed-f9bc-fd3f1ad07de1"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[1., 2., 3., 4., 5., 6., 7.]]), torch.Size([1, 7]))"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ancak unutmayÄ±n, **`torch.view()`** ile bir tensÃ¶rÃ¼n gÃ¶rÃ¼nÃ¼mÃ¼nÃ¼ deÄŸiÅŸtirmek, aslÄ±nda **aynÄ±** tensÃ¶rÃ¼n yeni bir gÃ¶rÃ¼nÃ¼mÃ¼nÃ¼ oluÅŸturur.\n",
        "\n",
        "Yani gÃ¶rÃ¼nÃ¼mÃ¼ deÄŸiÅŸtirmek, orijinal tensÃ¶rÃ¼ de deÄŸiÅŸtirir.\n"
      ],
      "metadata": {
        "id": "w2SiGS8rwYlU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# z'yi deÄŸiÅŸtirmek x'i de deÄŸiÅŸtirir\n",
        "z[:, 0] = 5\n",
        "z, x\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vO3W1BmowdrG",
        "outputId": "e91659c1-2411-4129-f9ea-c8394f9100e5"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[5., 2., 3., 4., 5., 6., 7.]]), tensor([5., 2., 3., 4., 5., 6., 7.]))"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "EÄŸer yeni tensÃ¶rÃ¼mÃ¼zÃ¼ kendisinin Ã¼zerine beÅŸ kez yÄ±ÄŸmak istersek, bunu **`torch.stack()`** ile yapabiliriz.\n"
      ],
      "metadata": {
        "id": "Hz8iFuB7wtQn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TensÃ¶rleri Ã¼st Ã¼ste yÄ±ÄŸma\n",
        "x_stacked = torch.stack([x, x, x, x], dim=0) # dim'i dim=1 olarak deÄŸiÅŸtirip ne olduÄŸunu gÃ¶rÃ¼n\n",
        "x_stacked\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k1MQI6Wvwt6E",
        "outputId": "e36d15e5-664b-4b82-99d6-0976102b7b1f"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[5., 2., 3., 4., 5., 6., 7.],\n",
              "        [5., 2., 3., 4., 5., 6., 7.],\n",
              "        [5., 2., 3., 4., 5., 6., 7.],\n",
              "        [5., 2., 3., 4., 5., 6., 7.]])"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ya bir tensÃ¶rden tÃ¼m tek boyutlarÄ± (single dimensions) kaldÄ±rmak istersek?\n",
        "\n",
        "Bunu yapmak iÃ§in **`torch.squeeze()`** kullanabilirsiniz (ben bunu, tensÃ¶rÃ¼ sadece 1'den bÃ¼yÃ¼k boyutlara sahip olacak ÅŸekilde **sÄ±kÄ±ÅŸtÄ±rmak** olarak hatÄ±rlÄ±yorum).\n"
      ],
      "metadata": {
        "id": "-d41TZh1w9w1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Ã–nceki tensÃ¶r: {x_reshaped}\")\n",
        "print(f\"Ã–nceki ÅŸekil: {x_reshaped.shape}\")\n",
        "\n",
        "# x_reshaped'ten ekstra boyutu kaldÄ±rma\n",
        "x_squeezed = x_reshaped.squeeze()\n",
        "print(f\"\\nYeni tensÃ¶r: {x_squeezed}\")\n",
        "print(f\"Yeni ÅŸekil: {x_squeezed.shape}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OfKb1E75w-Xk",
        "outputId": "ab91ccbb-05fc-42fc-872a-f8c092041484"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ã–nceki tensÃ¶r: tensor([[5., 2., 3., 4., 5., 6., 7.]])\n",
            "Ã–nceki ÅŸekil: torch.Size([1, 7])\n",
            "\n",
            "Yeni tensÃ¶r: tensor([5., 2., 3., 4., 5., 6., 7.])\n",
            "Yeni ÅŸekil: torch.Size([7])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ve **`torch.squeeze()`**'in tersini yapmak iÃ§in, belirli bir indekste **1** deÄŸeri eklemek iÃ§in **`torch.unsqueeze()`** kullanabilirsiniz.\n"
      ],
      "metadata": {
        "id": "1ZJ25JS2xG-p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Ã–nceki tensÃ¶r: {x_squeezed}\")\n",
        "print(f\"Ã–nceki ÅŸekil: {x_squeezed.shape}\")\n",
        "\n",
        "## unsqueeze ile ekstra bir boyut ekleyin\n",
        "x_unsqueezed = x_squeezed.unsqueeze(dim=0)\n",
        "print(f\"\\nYeni tensÃ¶r: {x_unsqueezed}\")\n",
        "print(f\"Yeni ÅŸekil: {x_unsqueezed.shape}\")\n"
      ],
      "metadata": {
        "id": "qq3LbsW4xHk5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a4b4b762-e23c-4522-84a9-321e097bfc69"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ã–nceki tensÃ¶r: tensor([5., 2., 3., 4., 5., 6., 7.])\n",
            "Ã–nceki ÅŸekil: torch.Size([7])\n",
            "\n",
            "Yeni tensÃ¶r: tensor([[5., 2., 3., 4., 5., 6., 7.]])\n",
            "Yeni ÅŸekil: torch.Size([1, 7])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "AyrÄ±ca **`torch.permute(input, dims)`** ile eksen deÄŸerlerinin sÄ±rasÄ±nÄ± yeniden dÃ¼zenleyebilirsiniz; burada **`input`**, yeni **`dims`** ile bir *gÃ¶rÃ¼nÃ¼m* haline gelir.\n"
      ],
      "metadata": {
        "id": "IMBoef0axRTk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Belirli bir ÅŸekle sahip tensÃ¶r oluÅŸturma\n",
        "x_original = torch.rand(size=(224, 224, 3))\n",
        "\n",
        "# Orijinal tensÃ¶rÃ¼ eksen sÄ±rasÄ±nÄ± yeniden dÃ¼zenlemek iÃ§in permute etme\n",
        "x_permuted = x_original.permute(2, 0, 1) # eksenleri 0->1, 1->2, 2->0 ÅŸeklinde kaydÄ±rÄ±r\n",
        "\n",
        "print(f\"Ã–nceki ÅŸekil: {x_original.shape}\")\n",
        "print(f\"Yeni ÅŸekil: {x_permuted.shape}\")\n"
      ],
      "metadata": {
        "id": "Zk9WYjFtxSCy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b9475a0-cc16-47e2-aaf5-96558d6cb6d9"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ã–nceki ÅŸekil: torch.Size([224, 224, 3])\n",
            "Yeni ÅŸekil: torch.Size([3, 224, 224])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> **Not:**  \n",
        "> Ã‡Ã¼nkÃ¼ **`permute()`** bir *gÃ¶rÃ¼nÃ¼m* dÃ¶ndÃ¼rÃ¼r (orijinal ile aynÄ± veriyi paylaÅŸÄ±r), permÃ¼telenmiÅŸ tensÃ¶rdeki deÄŸerler, orijinal tensÃ¶rle aynÄ± olacaktÄ±r ve eÄŸer gÃ¶rÃ¼nÃ¼mdeki deÄŸerleri deÄŸiÅŸtirirseniz, bu orijinal tensÃ¶rÃ¼n deÄŸerlerini de deÄŸiÅŸtirir.\n"
      ],
      "metadata": {
        "id": "33UNUvajxaOb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ä°ndeksleme (TensÃ¶rlerden veri seÃ§me)\n",
        "\n",
        "Bazen tensÃ¶rlerden belirli verileri seÃ§mek isteyebilirsiniz (Ã¶rneÄŸin, sadece ilk sÃ¼tun veya ikinci satÄ±r gibi).\n",
        "\n",
        "Bunu yapmak iÃ§in indeksleme kullanabilirsiniz.\n",
        "\n",
        "EÄŸer Python listelerinde veya NumPy dizilerinde indeksleme yaptÄ±ysanÄ±z, PyTorch'ta tensÃ¶rlerle indeksleme yapmak oldukÃ§a benzer.\n"
      ],
      "metadata": {
        "id": "4pquuNWDxe_2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TensÃ¶r oluÅŸturma\n",
        "import torch\n",
        "x = torch.arange(1, 10).reshape(1, 3, 3)\n",
        "x, x.shape\n"
      ],
      "metadata": {
        "id": "LJN2guVyxf96",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "65af92f0-5692-4fb4-9811-2b742fac5264"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[[1, 2, 3],\n",
              "          [4, 5, 6],\n",
              "          [7, 8, 9]]]),\n",
              " torch.Size([1, 3, 3]))"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ä°ndeksleme iÅŸlemi dÄ±ÅŸ boyuttan iÃ§ boyuta doÄŸru yapÄ±lÄ±r (kare parantezlere gÃ¶z atÄ±n).\n"
      ],
      "metadata": {
        "id": "_tDKNCaExxrE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Hadi, parantez parantez indeksleyelim\n",
        "print(f\"Ä°lk kare parantez:\\n{x[0]}\")\n",
        "print(f\"Ä°kinci kare parantez: {x[0][0]}\")\n",
        "print(f\"ÃœÃ§Ã¼ncÃ¼ kare parantez: {x[0][0][0]}\")\n"
      ],
      "metadata": {
        "id": "WUDQjSA9xydt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc1e2644-0c3e-472c-fbcd-e17cea72a468"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ä°lk kare parantez:\n",
            "tensor([[1, 2, 3],\n",
            "        [4, 5, 6],\n",
            "        [7, 8, 9]])\n",
            "Ä°kinci kare parantez: tensor([1, 2, 3])\n",
            "ÃœÃ§Ã¼ncÃ¼ kare parantez: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "AyrÄ±ca **`:`** kullanarak \"bu boyuttaki tÃ¼m deÄŸerleri\" belirtebilir ve ardÄ±ndan bir virgÃ¼l (**`,`**) kullanarak baÅŸka bir boyut ekleyebilirsiniz.\n"
      ],
      "metadata": {
        "id": "HHSGjMY5x7zO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 0. boyuttaki tÃ¼m deÄŸerleri ve 1. boyuttaki 0. indeksi almak\n",
        "x[:, 0]\n"
      ],
      "metadata": {
        "id": "etjqcRH7yAjx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bfc637cc-fd24-46cc-ebe5-c9081b367599"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1, 2, 3]])"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 0. ve 1. boyuttaki tÃ¼m deÄŸerleri, ancak yalnÄ±zca 2. boyuttaki 1. indeksi almak\n",
        "x[:, :, 1]\n"
      ],
      "metadata": {
        "id": "E5OVlfwFyE0b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7670eacb-bab1-4175-f421-e168531bb548"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[2, 5, 8]])"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 0. ve 1. boyutlarÄ±n 0. indeksini almak ve 2. boyuttaki tÃ¼m deÄŸerleri almak\n",
        "x[0, 0, :] # x[0][0] ile aynÄ±\n"
      ],
      "metadata": {
        "id": "MjaOVh54yJ3d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6ea7bf18-517b-4c0f-d133-d6b7482d338f"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 2, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ä°ndeksleme baÅŸta oldukÃ§a kafa karÄ±ÅŸtÄ±rÄ±cÄ± olabilir, Ã¶zellikle daha bÃ¼yÃ¼k tensÃ¶rlerle Ã§alÄ±ÅŸÄ±rken (ben hÃ¢lÃ¢ doÄŸru yapmak iÃ§in birkaÃ§ kez indeksleme yapmam gerekiyor). Ama biraz pratik yaparak ve veri kaÅŸiflerinin mottosunu takip ederek (***gÃ¶rselleÅŸtir, gÃ¶rselleÅŸtir, gÃ¶rselleÅŸtir***), zamanla alÄ±ÅŸmaya baÅŸlayacaksÄ±nÄ±z.\n"
      ],
      "metadata": {
        "id": "jjPT0sl1yNzu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PyTorch TensÃ¶rleri ve NumPy\n",
        "\n",
        "NumPy, popÃ¼ler bir Python sayÄ±sal hesaplama kÃ¼tÃ¼phanesi olduÄŸundan, PyTorch'un NumPy ile dÃ¼zgÃ¼n bir ÅŸekilde etkileÅŸim kurma iÅŸlevselliÄŸi vardÄ±r.\n",
        "\n",
        "NumPy ile PyTorch arasÄ±nda (ve geriye) kullanmak isteyeceÄŸiniz iki ana yÃ¶ntem ÅŸunlardÄ±r:\n",
        "* [`torch.from_numpy(ndarray)`](https://pytorch.org/docs/stable/generated/torch.from_numpy.html) - NumPy dizisi -> PyTorch tensÃ¶rÃ¼.\n",
        "* [`torch.Tensor.numpy()`](https://pytorch.org/docs/stable/generated/torch.Tensor.numpy.html) - PyTorch tensÃ¶rÃ¼ -> NumPy dizisi.\n",
        "\n",
        "Åimdi bunlarÄ± deneyelim.\n"
      ],
      "metadata": {
        "id": "o20M5CwhyUir"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# NumPy dizisini tensÃ¶re Ã§evirme\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "array = np.arange(1.0, 8.0)\n",
        "tensor = torch.from_numpy(array)\n",
        "array, tensor\n"
      ],
      "metadata": {
        "id": "sDB_iIqHyXTG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9f9dad9a-9c7d-4d98-f623-0e5db9ee1415"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([1., 2., 3., 4., 5., 6., 7.]),\n",
              " tensor([1., 2., 3., 4., 5., 6., 7.], dtype=torch.float64))"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> **Not:**  \n",
        "> VarsayÄ±lan olarak, NumPy dizileri **`float64`** veri tipiyle oluÅŸturulur ve PyTorch tensÃ¶rÃ¼ne dÃ¶nÃ¼ÅŸtÃ¼rdÃ¼ÄŸÃ¼nÃ¼zde aynÄ± veri tipi korunur (yukarÄ±daki gibi).  \n",
        ">  \n",
        "> Ancak, birÃ§ok PyTorch hesaplamasÄ± varsayÄ±lan olarak **`float32`** kullanÄ±r.  \n",
        ">  \n",
        "> Yani, NumPy dizinizi (**`float64`**) -> PyTorch tensÃ¶rÃ¼ (**`float64`**) -> PyTorch tensÃ¶rÃ¼ (**`float32`**) olarak dÃ¶nÃ¼ÅŸtÃ¼rmek istiyorsanÄ±z, **`tensor = torch.from_numpy(array).type(torch.float32)`** kullanabilirsiniz.  \n",
        ">  \n",
        "> YukarÄ±da **`tensor`**'u yeniden atadÄ±ÄŸÄ±mÄ±z iÃ§in, tensÃ¶rÃ¼ deÄŸiÅŸtirdiÄŸinizde dizi aynÄ± kalÄ±r.\n"
      ],
      "metadata": {
        "id": "-1c4THo2ydr1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Diziyi deÄŸiÅŸtir, tensÃ¶rÃ¼ aynÄ± tut\n",
        "array = array + 1\n",
        "array, tensor\n"
      ],
      "metadata": {
        "id": "H3bOiO4myOg6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e02d079d-b371-450a-c1a4-40f69cae03e1"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([2., 3., 4., 5., 6., 7., 8.]),\n",
              " tensor([1., 2., 3., 4., 5., 6., 7.], dtype=torch.float64))"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ve eÄŸer PyTorch tensÃ¶rÃ¼nden NumPy dizisine geÃ§mek isterseniz, **`tensor.numpy()`** fonksiyonunu Ã§aÄŸÄ±rabilirsiniz.\n"
      ],
      "metadata": {
        "id": "5e2K5bPNymkm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TensÃ¶rden NumPy dizisine\n",
        "tensor = torch.ones(7) # float32 veri tipiyle bir tensÃ¶r oluÅŸturma\n",
        "numpy_tensor = tensor.numpy() # dtype=float32 olacak, eÄŸer deÄŸiÅŸtirilmezse\n",
        "tensor, numpy_tensor\n"
      ],
      "metadata": {
        "id": "N9aI-6JEynRs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "785f45c0-926d-4a88-ab4e-f1867be79c35"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([1., 1., 1., 1., 1., 1., 1.]),\n",
              " array([1., 1., 1., 1., 1., 1., 1.], dtype=float32))"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ve yukarÄ±daki kural aynen geÃ§erlidir; eÄŸer orijinal **`tensor`**'Ä± deÄŸiÅŸtirirseniz, yeni **`numpy_tensor`** aynÄ± kalÄ±r.\n"
      ],
      "metadata": {
        "id": "TvLFP0jtyru4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TensÃ¶rÃ¼ deÄŸiÅŸtir, diziyi aynÄ± tut\n",
        "tensor = tensor + 1\n",
        "tensor, numpy_tensor\n"
      ],
      "metadata": {
        "id": "fq7yUezxyz_5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f7136402-4b7f-4380-9fe0-f29b55427674"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([2., 2., 2., 2., 2., 2., 2.]),\n",
              " array([1., 1., 1., 1., 1., 1., 1.], dtype=float32))"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tekrarlanabilirlik (RastgeleliÄŸi Rastgelelikten Ã‡Ä±karmaya Ã‡alÄ±ÅŸmak)\n",
        "\n",
        "Sinir aÄŸlarÄ± ve makine Ã¶ÄŸrenimi hakkÄ±nda daha fazla ÅŸey Ã¶ÄŸrendikÃ§e, rastgeleliÄŸin ne kadar Ã¶nemli bir rol oynadÄ±ÄŸÄ±nÄ± keÅŸfedeceksiniz.\n",
        "\n",
        "AslÄ±nda bu, **sahte rastgelelik**. Ã‡Ã¼nkÃ¼ sonuÃ§ta, tasarlandÄ±klarÄ± gibi bir bilgisayar temelde **deterministiktir** (her adÄ±m tahmin edilebilir), bu yÃ¼zden yarattÄ±klarÄ± rastgelelikler, simÃ¼le edilmiÅŸ rastgeleliklerdir (bununla ilgili de tartÄ±ÅŸmalar olsa da, ben bir bilgisayar bilimci olmadÄ±ÄŸÄ±m iÃ§in bunu kendiniz keÅŸfetmenize bÄ±rakÄ±yorum).\n",
        "\n",
        "Peki bu, sinir aÄŸlarÄ± ve derin Ã¶ÄŸrenme ile nasÄ±l iliÅŸkilidir?\n",
        "\n",
        "Sinir aÄŸlarÄ±nÄ±n, verilerdeki kalÄ±plarÄ± tanÄ±mlamak iÃ§in rastgele sayÄ±larla baÅŸladÄ±ÄŸÄ±nÄ± ve bu sayÄ±larÄ± tensÃ¶r iÅŸlemleri (ve henÃ¼z tartÄ±ÅŸmadÄ±ÄŸÄ±mÄ±z birkaÃ§ baÅŸka ÅŸey) kullanarak iyileÅŸtirmeye Ã§alÄ±ÅŸtÄ±ÄŸÄ±nÄ± konuÅŸtuk. Bu sayÄ±lar baÅŸlangÄ±Ã§ta kÃ¶tÃ¼ tanÄ±mlamalardÄ±r ve verilerdeki kalÄ±plarÄ± daha iyi tanÄ±mlamak iÃ§in bu rastgele sayÄ±lar iyileÅŸtirilmeye Ã§alÄ±ÅŸÄ±lÄ±r.\n",
        "\n",
        "KÄ±sacasÄ±:\n",
        "\n",
        "``rastgele sayÄ±larla baÅŸla -> tensÃ¶r iÅŸlemleri -> daha iyi hale getirmeye Ã§alÄ±ÅŸ (defalarca ve tekrar)``\n",
        "\n",
        "Rastgelelik gÃ¼zel ve gÃ¼Ã§lÃ¼ olsa da, bazen biraz daha az rastgelelik istersiniz.\n",
        "\n",
        "Neden?\n",
        "\n",
        "Ã‡Ã¼nkÃ¼ tekrarlanabilir deneyler yapabilmek istersiniz.\n",
        "\n",
        "Ã–rneÄŸin, X performansÄ±nÄ± elde edebilen bir algoritma oluÅŸturursunuz.\n",
        "\n",
        "Ve sonra arkadaÅŸÄ±nÄ±z bunu deneyerek sizin deli olmadÄ±ÄŸÄ±nÄ±zÄ± doÄŸrulamak ister.\n",
        "\n",
        "Bunu nasÄ±l yapabilirler?\n",
        "\n",
        "Ä°ÅŸte burada **tekrarlanabilirlik** devreye giriyor.\n",
        "\n",
        "BaÅŸka bir deyiÅŸle, aynÄ± kodu Ã§alÄ±ÅŸtÄ±ran bilgisayarÄ±mda aldÄ±ÄŸÄ±m aynÄ± (veya Ã§ok benzer) sonuÃ§larÄ±, sizin bilgisayarÄ±nÄ±zda alabilir misiniz?\n",
        "\n",
        "Hadi PyTorch'ta tekrarlanabilirliÄŸe kÄ±sa bir Ã¶rnek bakalÄ±m.\n",
        "\n",
        "Ä°ki rastgele tensÃ¶r oluÅŸturacaÄŸÄ±z. Ã‡Ã¼nkÃ¼ rastgele olduklarÄ±ndan, farklÄ± olmalarÄ±nÄ± beklersiniz, deÄŸil mi?\n"
      ],
      "metadata": {
        "id": "sa47pSZny3V_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Ä°ki rastgele tensÃ¶r oluÅŸturma\n",
        "random_tensor_A = torch.rand(3, 4)\n",
        "random_tensor_B = torch.rand(3, 4)\n",
        "\n",
        "print(f\"TensÃ¶r A:\\n{random_tensor_A}\\n\")\n",
        "print(f\"TensÃ¶r B:\\n{random_tensor_B}\\n\")\n",
        "print(f\"TensÃ¶r A, TensÃ¶r B'ye eÅŸit mi? (herhangi bir yerde)\")\n",
        "random_tensor_A == random_tensor_B\n"
      ],
      "metadata": {
        "id": "FVX4eoFUy86n",
        "outputId": "7b8560b8-b217-4416-a782-7d1341174f74",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensÃ¶r A:\n",
            "tensor([[0.8016, 0.3649, 0.6286, 0.9663],\n",
            "        [0.7687, 0.4566, 0.5745, 0.9200],\n",
            "        [0.3230, 0.8613, 0.0919, 0.3102]])\n",
            "\n",
            "TensÃ¶r B:\n",
            "tensor([[0.9536, 0.6002, 0.0351, 0.6826],\n",
            "        [0.3743, 0.5220, 0.1336, 0.9666],\n",
            "        [0.9754, 0.8474, 0.8988, 0.1105]])\n",
            "\n",
            "TensÃ¶r A, TensÃ¶r B'ye eÅŸit mi? (herhangi bir yerde)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[False, False, False, False],\n",
              "        [False, False, False, False],\n",
              "        [False, False, False, False]])"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "BeklediÄŸiniz gibi, tensÃ¶rler farklÄ± deÄŸerlerle Ã§Ä±ktÄ±.\n",
        "\n",
        "Ama ya iki rastgele tensÃ¶rÃ¼n *aynÄ±* deÄŸerlere sahip olmasÄ±nÄ± isteseydiniz?\n",
        "\n",
        "Yani tensÃ¶rler hala rastgele deÄŸerlere sahip olacak ama aynÄ± \"lezzette\" olacaklardÄ±.\n",
        "\n",
        "Ä°ÅŸte burada **`torch.manual_seed(seed)`** devreye giriyor; burada **`seed`** bir tam sayÄ±dÄ±r (mesela **`42`** olabilir ama baÅŸka bir ÅŸey de olabilir) ve rastgeleliÄŸi **lezzetlendiren** bir deÄŸerdir.\n",
        "\n",
        "Hadi bunu deneyelim ve daha fazla *lezzetlendirilmiÅŸ* rastgele tensÃ¶rler oluÅŸturalÄ±m.\n"
      ],
      "metadata": {
        "id": "uIjm-ILtzLhB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import random\n",
        "\n",
        "# Rastgele tohum deÄŸerini ayarla\n",
        "RANDOM_SEED = 42 # Bunu farklÄ± deÄŸerlere deÄŸiÅŸtirerek aÅŸaÄŸÄ±daki sayÄ±larda ne olduÄŸunu gÃ¶rebilirsiniz\n",
        "torch.manual_seed(seed=RANDOM_SEED)\n",
        "random_tensor_C = torch.rand(3, 4)\n",
        "\n",
        "# Her yeni rand() Ã§aÄŸrÄ±ldÄ±ÄŸÄ±nda tohumun sÄ±fÄ±rlanmasÄ± gerekir\n",
        "# Bunu yapmazsanÄ±z, tensor_D, tensor_C'ye farklÄ± olurdu\n",
        "torch.random.manual_seed(seed=RANDOM_SEED) # Bu satÄ±rÄ± yorum satÄ±rÄ±na almayÄ± deneyin ve ne olacaÄŸÄ±nÄ± gÃ¶rÃ¼n\n",
        "random_tensor_D = torch.rand(3, 4)\n",
        "\n",
        "print(f\"TensÃ¶r C:\\n{random_tensor_C}\\n\")\n",
        "print(f\"TensÃ¶r D:\\n{random_tensor_D}\\n\")\n",
        "print(f\"TensÃ¶r C, TensÃ¶r D'ye eÅŸit mi? (herhangi bir yerde)\")\n",
        "random_tensor_C == random_tensor_D\n"
      ],
      "metadata": {
        "id": "QhdIoDPGzOan",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d06ced55-ef9e-4a23-a5e2-2c0838290d75"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensÃ¶r C:\n",
            "tensor([[0.8823, 0.9150, 0.3829, 0.9593],\n",
            "        [0.3904, 0.6009, 0.2566, 0.7936],\n",
            "        [0.9408, 0.1332, 0.9346, 0.5936]])\n",
            "\n",
            "TensÃ¶r D:\n",
            "tensor([[0.8823, 0.9150, 0.3829, 0.9593],\n",
            "        [0.3904, 0.6009, 0.2566, 0.7936],\n",
            "        [0.9408, 0.1332, 0.9346, 0.5936]])\n",
            "\n",
            "TensÃ¶r C, TensÃ¶r D'ye eÅŸit mi? (herhangi bir yerde)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[True, True, True, True],\n",
              "        [True, True, True, True],\n",
              "        [True, True, True, True]])"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Harika!\n",
        "\n",
        "GÃ¶rÃ¼nÃ¼ÅŸe gÃ¶re tohum ayarlamak iÅŸe yaramÄ±ÅŸ.\n",
        "\n",
        "> **Kaynak:** Åu ana kadar ele aldÄ±klarÄ±mÄ±z, PyTorch'ta tekrarlanabilirlik konusunda yalnÄ±zca yÃ¼zeyi Ã§iziyor. Genel olarak tekrarlanabilirlik ve rastgele tohumlar hakkÄ±nda daha fazla bilgi iÃ§in ÅŸunlarÄ± incelemenizi Ã¶neririm:\n",
        "> * [PyTorch tekrarlanabilirlik dokÃ¼mantasyonu](https://pytorch.org/docs/stable/notes/randomness.html) (iyi bir alÄ±ÅŸtÄ±rma, bunu 10 dakika boyunca okuyup anlamasanÄ±z da, buna aÅŸina olmak Ã¶nemlidir).\n",
        "> * [Wikipedia rastgele tohum sayfasÄ±](https://en.wikipedia.org/wiki/Random_seed) (bu, rastgele tohumlar ve genel olarak sahte rastgelelik hakkÄ±nda iyi bir genel bakÄ±ÅŸ saÄŸlar).\n"
      ],
      "metadata": {
        "id": "xgKOtuWpzVAE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## TensÃ¶rleri GPU'larda Ã‡alÄ±ÅŸtÄ±rma (ve Daha HÄ±zlÄ± Hesaplamalar Yapma)\n",
        "\n",
        "Derin Ã¶ÄŸrenme algoritmalarÄ± Ã§ok fazla sayÄ±sal iÅŸlem gerektirir.\n",
        "\n",
        "Ve varsayÄ±lan olarak bu iÅŸlemler Ã§oÄŸunlukla bir CPU'da (iÅŸlemci) yapÄ±lÄ±r.\n",
        "\n",
        "Ancak, bir GPU (grafik iÅŸleme birimi) adÄ±nda baÅŸka bir yaygÄ±n donanÄ±m tÃ¼rÃ¼ vardÄ±r, bu donanÄ±m genellikle sinir aÄŸlarÄ±nÄ±n ihtiyaÃ§ duyduÄŸu belirli tÃ¼rdeki iÅŸlemleri (matris Ã§arpÄ±mlarÄ±) CPU'lardan Ã§ok daha hÄ±zlÄ± bir ÅŸekilde gerÃ§ekleÅŸtirebilir.\n",
        "\n",
        "BilgisayarÄ±nÄ±zda bir tane olabilir.\n",
        "\n",
        "EÄŸer Ã¶yleyse, sinir aÄŸlarÄ±nÄ± eÄŸitmek iÃ§in her fÄ±rsatta kullanmaya Ã§alÄ±ÅŸmalÄ±sÄ±nÄ±z Ã§Ã¼nkÃ¼ bÃ¼yÃ¼k ihtimalle eÄŸitim sÃ¼resini dramatik ÅŸekilde hÄ±zlandÄ±racaktÄ±r.\n",
        "\n",
        "GPU'ya eriÅŸmenin ve PyTorch'u GPU kullanacak ÅŸekilde yapÄ±landÄ±rmanÄ±n birkaÃ§ yolu vardÄ±r.\n",
        "\n",
        "> **Not:** Bu kurs boyunca \"GPU\"dan bahsederken, [CUDA etkinleÅŸtirilmiÅŸ bir Nvidia GPU'yu](https://developer.nvidia.com/cuda-gpus) kast ediyorum (CUDA, GPU'larÄ±n yalnÄ±zca grafik deÄŸil, genel amaÃ§lÄ± hesaplama iÃ§in de kullanÄ±lmasÄ±nÄ± saÄŸlayan bir hesaplama platformu ve API'sidir) aksi belirtilmedikÃ§e.\n"
      ],
      "metadata": {
        "id": "D4xB2AVnzgEp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. GPU'ya EriÅŸim\n",
        "\n",
        "GPU dediÄŸimde ne olduÄŸunu zaten biliyor olabilirsiniz. Ancak bilmiyorsanÄ±z, birine eriÅŸim saÄŸlamak iÃ§in birkaÃ§ yol vardÄ±r.\n",
        "\n",
        "| **YÃ¶ntem** | **Kurulum ZorluÄŸu** | **Avantajlar** | **Dezavantajlar** | **NasÄ±l Kurulur** |\n",
        "| ----- | ----- | ----- | ----- | ----- |\n",
        "| Google Colab | Kolay | Ãœcretsiz, neredeyse sÄ±fÄ±r kurulum gerektirir, Ã§alÄ±ÅŸmalarÄ± baÅŸkalarÄ±yla bir baÄŸlantÄ± kadar kolay paylaÅŸabilirsiniz | Verilerinizi kaydetmez, sÄ±nÄ±rlÄ± hesaplama gÃ¼cÃ¼, zaman aÅŸÄ±mÄ±na uÄŸrayabilir | [Google Colab KÄ±lavuzunu Takip Edin](https://colab.research.google.com/notebooks/gpu.ipynb) |\n",
        "| Kendi bilgisayarÄ±nÄ±zÄ± kullanma | Orta | Her ÅŸeyi yerel olarak kendi bilgisayarÄ±nÄ±zda Ã§alÄ±ÅŸtÄ±rabilirsiniz | GPU'lar Ã¼cretsiz deÄŸil, Ã¶nceden maliyet gerektirir | [PyTorch kurulum yÃ¶nergelerini takip edin](https://pytorch.org/get-started/locally/) |\n",
        "| Bulut biliÅŸim (AWS, GCP, Azure) | Orta-Zor | KÃ¼Ã§Ã¼k Ã¶n maliyet, neredeyse sonsuz hesaplama eriÅŸimi | SÃ¼rekli Ã§alÄ±ÅŸtÄ±rÄ±rsanÄ±z pahalÄ± olabilir, doÄŸru ÅŸekilde kurmak zaman alabilir | [PyTorch bulut kurulum kÄ±lavuzunu takip edin](https://pytorch.org/get-started/cloud-partners/) |\n",
        "\n",
        "GPU'larÄ± kullanmak iÃ§in daha fazla seÃ§enek vardÄ±r ancak yukarÄ±daki Ã¼Ã§ seÃ§enek ÅŸimdilik yeterli olacaktÄ±r.\n",
        "\n",
        "KiÅŸisel olarak, kÃ¼Ã§Ã¼k Ã¶lÃ§ekli deneyler (ve bu kursu oluÅŸturma) iÃ§in Google Colab ve kendi bilgisayarÄ±mÄ±n bir kombinasyonunu kullanÄ±yorum ve daha fazla hesaplama gÃ¼cÃ¼ne ihtiyaÃ§ duyduÄŸumda bulut kaynaklarÄ±na baÅŸvuruyorum.\n",
        "\n",
        "> **Kaynak:** Kendi GPU'nuzu satÄ±n almayÄ± dÃ¼ÅŸÃ¼nÃ¼yorsanÄ±z ancak ne alacaÄŸÄ±nÄ±zÄ± bilmiyorsanÄ±z, [Tim Dettmers'Ä±n harika bir kÄ±lavuzu var](https://timdettmers.com/2020/09/07/which-gpu-for-deep-learning/).\n",
        "\n",
        "Bir Nvidia GPU'nuzun olup olmadÄ±ÄŸÄ±nÄ± kontrol etmek iÃ§in, `!nvidia-smi` komutunu Ã§alÄ±ÅŸtÄ±rabilirsiniz, burada `!` (aynÄ± zamanda bang olarak da bilinir) \"bunu komut satÄ±rÄ±nda Ã§alÄ±ÅŸtÄ±r\" anlamÄ±na gelir.\n"
      ],
      "metadata": {
        "id": "rwemFJIkzq2c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "DgB0QZWrzjEp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "78dc30a4-b89f-4d8c-cc25-e114429695aa"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: nvidia-smi: command not found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "EÄŸer eriÅŸebileceÄŸiniz bir Nvidia GPU'nuz yoksa, yukarÄ±daki Ã§Ä±ktÄ± ÅŸu ÅŸekilde gÃ¶rÃ¼necektir:\n",
        "\n"
      ],
      "metadata": {
        "id": "wJglSGizz6GB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. PyTorch'u GPU Ã¼zerinde Ã§alÄ±ÅŸtÄ±rma\n",
        "\n",
        "Bir GPU'ya eriÅŸim saÄŸladÄ±ktan sonra, bir sonraki adÄ±m, PyTorch'u verileri (tensÃ¶rleri) depolamak ve veriler Ã¼zerinde hesaplamalar yapmak (tensÃ¶rler Ã¼zerinde iÅŸlemler gerÃ§ekleÅŸtirmek) iÃ§in kullanmaktÄ±r.\n",
        "\n",
        "Bunu yapmak iÃ§in **`torch.cuda`** paketini kullanabilirsiniz.\n",
        "\n",
        "Bundan bahsetmek yerine, bunu deneyelim.\n",
        "\n",
        "PyTorch'un bir GPU'ya eriÅŸimi olup olmadÄ±ÄŸÄ±nÄ±, **[`torch.cuda.is_available()`](https://pytorch.org/docs/stable/generated/torch.cuda.is_available.html#torch.cuda.is_available)** fonksiyonunu kullanarak test edebilirsiniz.\n"
      ],
      "metadata": {
        "id": "Khx-VYnoz_SE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# GPU'yu kontrol etme\n",
        "import torch\n",
        "torch.cuda.is_available()\n"
      ],
      "metadata": {
        "id": "iMwPP5g8z_59",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df9ea002-994a-4b0d-8801-dffa274623bc"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "EÄŸer yukarÄ±daki Ã§Ä±ktÄ± **`True`** ise, PyTorch GPU'yu gÃ¶rebilir ve kullanabilir, eÄŸer **`False`** Ã§Ä±karsa, GPU'yu gÃ¶remez ve bu durumda kurulum adÄ±mlarÄ±nÄ± tekrar gÃ¶zden geÃ§irmeniz gerekecek.\n",
        "\n",
        "Åimdi, kodunuzu CPU *veya* mevcutsa GPU Ã¼zerinde Ã§alÄ±ÅŸacak ÅŸekilde ayarlamak istediÄŸinizi varsayalÄ±m.\n",
        "\n",
        "Bu ÅŸekilde, siz veya birisi kodunuzu Ã§alÄ±ÅŸtÄ±rmaya karar verdiÄŸinde, kullandÄ±klarÄ± hesaplama cihazÄ±na bakÄ±lmaksÄ±zÄ±n Ã§alÄ±ÅŸacaktÄ±r.\n",
        "\n",
        "Bir `device` deÄŸiÅŸkeni oluÅŸturalÄ±m ve hangi tÃ¼r cihazÄ±n mevcut olduÄŸunu saklayalÄ±m.\n"
      ],
      "metadata": {
        "id": "Ipf9zbYY0K-w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cihaz tÃ¼rÃ¼nÃ¼ ayarlama\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "device\n"
      ],
      "metadata": {
        "id": "nqgwd7fe0M6M",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "e74bdfed-ebaa-4bae-bdf4-9604b018016d"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cpu'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "YukarÄ±daki Ã§Ä±ktÄ± **`\"cuda\"`** ise, tÃ¼m PyTorch kodumuzu mevcut CUDA cihazÄ±nÄ± (GPU) kullanacak ÅŸekilde ayarlayabileceÄŸimiz anlamÄ±na gelir ve eÄŸer **`\"cpu\"`** Ã§Ä±karsa, PyTorch kodumuz CPU Ã¼zerinde Ã§alÄ±ÅŸacaktÄ±r.\n",
        "\n",
        "> **Not:** PyTorch'ta, [**cihazdan baÄŸÄ±msÄ±z kod**](https://pytorch.org/docs/master/notes/cuda.html#device-agnostic-code) yazmak en iyi uygulamadÄ±r. Bu, CPU'da (her zaman mevcut) veya GPU'da (mevcutsa) Ã§alÄ±ÅŸacak kod anlamÄ±na gelir.\n",
        "\n",
        "Daha hÄ±zlÄ± hesaplamalar yapmak istiyorsanÄ±z, bir GPU kullanabilirsiniz, ancak *Ã§ok* daha hÄ±zlÄ± hesaplamalar yapmak istiyorsanÄ±z, birden fazla GPU kullanabilirsiniz.\n",
        "\n",
        "PyTorch'un eriÅŸebileceÄŸi GPU sayÄ±sÄ±nÄ±, **[`torch.cuda.device_count()`](https://pytorch.org/docs/stable/generated/torch.cuda.device_count.html#torch.cuda.device_count)** fonksiyonunu kullanarak Ã¶ÄŸrenebilirsiniz.\n"
      ],
      "metadata": {
        "id": "XA1sKRPg0URk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cihaz sayÄ±sÄ±nÄ± sayma\n",
        "torch.cuda.device_count()\n"
      ],
      "metadata": {
        "id": "dQMUzFRB0YPm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fc2ce727-3bf4-43a7-f3fc-281862ae4d6e"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "PyTorch'un eriÅŸebileceÄŸi GPU sayÄ±sÄ±nÄ± bilmek, bir iÅŸlemi bir GPU'da ve baÅŸka bir iÅŸlemi diÄŸer GPU'da Ã§alÄ±ÅŸtÄ±rmak isterseniz faydalÄ±dÄ±r (PyTorch ayrÄ±ca bir iÅŸlemi *tÃ¼m* GPU'lar Ã¼zerinde Ã§alÄ±ÅŸtÄ±rmanÄ±za olanak tanÄ±yan Ã¶zelliklere sahiptir).\n"
      ],
      "metadata": {
        "id": "TpIixDo-0d2l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.1 PyTorch'u Apple Silicon'da Ã‡alÄ±ÅŸtÄ±rma\n",
        "\n",
        "Apple'Ä±n M1/M2/M3 GPU'larÄ±nda PyTorch Ã§alÄ±ÅŸtÄ±rmak iÃ§in **[`torch.backends.mps`](https://pytorch.org/docs/stable/notes/mps.html)** modÃ¼lÃ¼nÃ¼ kullanabilirsiniz.\n",
        "\n",
        "macOS ve PyTorch sÃ¼rÃ¼mlerinin gÃ¼ncel olduÄŸundan emin olun.\n",
        "\n",
        "PyTorch'un bir GPU'ya eriÅŸimi olup olmadÄ±ÄŸÄ±nÄ± **`torch.backends.mps.is_available()`** ile test edebilirsiniz.\n"
      ],
      "metadata": {
        "id": "uIB79nEG0jU9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Apple Silicon GPU'yu kontrol etme\n",
        "import torch\n",
        "torch.backends.mps.is_available() # Not: Bu, bir Mac'te Ã§alÄ±ÅŸmÄ±yorsanÄ±z false dÃ¶ndÃ¼recektir\n"
      ],
      "metadata": {
        "id": "HqCas6Gs0kH-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3e6b9495-eb01-4b65-b42e-23b16fc41f50"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cihaz tÃ¼rÃ¼nÃ¼ ayarlama\n",
        "device = \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
        "device\n"
      ],
      "metadata": {
        "id": "mwA66ygc0oP3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "f96a14c9-7c1f-4e96-b3d4-82df438bff40"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cpu'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "YukarÄ±daki Ã§Ä±ktÄ± **`\"mps\"`** ise, tÃ¼m PyTorch kodumuzu mevcut Apple Silicon GPU'sunu kullanacak ÅŸekilde ayarlayabileceÄŸimiz anlamÄ±na gelir.\n"
      ],
      "metadata": {
        "id": "vEgOhEOt0s-E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if torch.cuda.is_available():\n",
        "    device = \"cuda\"  # NVIDIA GPU'yu kullan (eÄŸer mevcutsa)\n",
        "elif torch.backends.mps.is_available():\n",
        "    device = \"mps\"  # Apple Silicon GPU'yu kullan (eÄŸer mevcutsa)\n",
        "else:\n",
        "    device = \"cpu\"  # GPU yoksa varsayÄ±lan olarak CPU kullan\n"
      ],
      "metadata": {
        "id": "R7-M6VxR0x1t"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. TensÃ¶rleri (ve modelleri) GPU'ya koyma\n",
        "\n",
        "TensÃ¶rleri (ve modelleri, bunu daha sonra gÃ¶receÄŸiz) belirli bir cihaza koymak iÃ§in onlara **`to(device)`** fonksiyonunu Ã§aÄŸÄ±rabilirsiniz. Burada **`device`**, tensÃ¶rÃ¼n (veya modelin) gitmesini istediÄŸiniz hedef cihazdÄ±r.\n",
        "\n",
        "Bunu neden yapmalÄ±sÄ±nÄ±z?\n",
        "\n",
        "GPU'lar, CPU'lardan Ã§ok daha hÄ±zlÄ± sayÄ±sal hesaplamalar yapar ve eÄŸer bir GPU mevcut deÄŸilse, **cihazdan baÄŸÄ±msÄ±z kodumuz** (yukarÄ±ya bakÄ±n) sayesinde kod CPU Ã¼zerinde Ã§alÄ±ÅŸacaktÄ±r.\n",
        "\n",
        "> **Not:** **`to(device)`** kullanarak bir tensÃ¶rÃ¼ GPU'ya koymak (Ã¶rneÄŸin **`some_tensor.to(device)`**) o tensÃ¶rÃ¼n bir kopyasÄ±nÄ± dÃ¶ndÃ¼rÃ¼r; Ã¶rneÄŸin, aynÄ± tensÃ¶r hem CPU'da hem de GPU'da olacaktÄ±r. TensÃ¶rleri Ã¼zerine yazmak iÃ§in onlarÄ± yeniden atayÄ±n:\n",
        ">\n",
        "> `some_tensor = some_tensor.to(device)`\n",
        "\n",
        "Hadi, bir tensÃ¶r oluÅŸturalÄ±m ve onu GPU'ya koyalÄ±m (eÄŸer mevcutsa).\n"
      ],
      "metadata": {
        "id": "lUppzg1l06wL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TensÃ¶r oluÅŸturma (varsayÄ±lan olarak CPU Ã¼zerinde)\n",
        "tensor = torch.tensor([1, 2, 3])\n",
        "\n",
        "# TensÃ¶r GPU'da deÄŸil\n",
        "print(tensor, tensor.device)\n",
        "\n",
        "# TensÃ¶rÃ¼ GPU'ya taÅŸÄ±ma (eÄŸer mevcutsa)\n",
        "tensor_on_gpu = tensor.to(device)\n",
        "tensor_on_gpu\n"
      ],
      "metadata": {
        "id": "JevoqGA-08kQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c957c0b9-1d18-4160-a703-ca55efc7a8a6"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1, 2, 3]) cpu\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 2, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "EÄŸer bir GPU'nuz mevcutsa, yukarÄ±daki kod ÅŸu ÅŸekilde bir Ã§Ä±ktÄ± verecektir:\n",
        "\n",
        "```\n",
        "tensor([1, 2, 3]) cpu\n",
        "tensor([1, 2, 3], device='cuda:0')\n",
        "```\n",
        "\n",
        "Ä°kinci tensÃ¶rÃ¼n **`device='cuda:0'`** olduÄŸunu fark edin, bu, tensÃ¶rÃ¼n mevcut 0. GPU'da depolandÄ±ÄŸÄ±nÄ± gÃ¶sterir (GPU'lar 0'dan baÅŸlar, eÄŸer iki GPU mevcutsa, sÄ±rasÄ±yla `'cuda:0'` ve `'cuda:1'` olur, bu ÅŸekilde `'cuda:n'`'e kadar devam eder).\n"
      ],
      "metadata": {
        "id": "OuJIlGiN1HcU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. TensÃ¶rleri CPU'ya geri taÅŸÄ±ma\n",
        "\n",
        "Ya tensÃ¶rÃ¼ geri CPU'ya taÅŸÄ±mak istersek?\n",
        "\n",
        "Ã–rneÄŸin, tensÃ¶rlerinizle NumPy ile etkileÅŸimde bulunmak isterseniz bunu yapmak isteyebilirsiniz (NumPy, GPU'yu kullanmaz).\n",
        "\n",
        "Hadi, **`torch.Tensor.numpy()`** metodunu **`tensor_on_gpu`** Ã¼zerinde deneyelim.\n"
      ],
      "metadata": {
        "id": "YbKaIdQ81K8n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# EÄŸer tensÃ¶r GPU'daysa, NumPy'ye dÃ¶nÃ¼ÅŸtÃ¼rÃ¼lemez (bu hata verecektir)\n",
        "tensor_on_gpu.numpy()\n"
      ],
      "metadata": {
        "id": "dh6y1zUr1RTw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d4e28cdb-c43f-4e48-ed95-b56c4e3fcbe1"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 2, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bunun yerine, bir tensÃ¶rÃ¼ CPU'ya geri almak ve NumPy ile kullanÄ±labilir hale getirmek iÃ§in **[`Tensor.cpu()`](https://pytorch.org/docs/stable/generated/torch.Tensor.cpu.html)** kullanabiliriz.\n",
        "\n",
        "Bu, tensÃ¶rÃ¼ CPU belleÄŸine kopyalar, bÃ¶ylece CPU'lar ile kullanÄ±labilir hale gelir.\n"
      ],
      "metadata": {
        "id": "re4L2_YZ1adh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Bunun yerine, tensÃ¶rÃ¼ geri CPU'ya kopyala\n",
        "tensor_back_on_cpu = tensor_on_gpu.cpu().numpy()\n",
        "tensor_back_on_cpu\n"
      ],
      "metadata": {
        "id": "LPIKXGxN1fdT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "94fef295-f2d6-427c-a116-a0de24be25cf"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 2, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "YukarÄ±daki iÅŸlem, GPU tensÃ¶rÃ¼nÃ¼n bir kopyasÄ±nÄ± CPU belleÄŸine dÃ¶ndÃ¼rÃ¼r, bÃ¶ylece orijinal tensÃ¶r hala GPU Ã¼zerinde kalÄ±r.\n"
      ],
      "metadata": {
        "id": "bc36Ve3J1jp0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tensor_on_gpu"
      ],
      "metadata": {
        "id": "JRHDFVEy1m7u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1fb90ba7-8420-4db5-a2ab-faf5cfa8c740"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 2, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "-l9dVpGIfJxF"
      }
    }
  ]
}