{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPYfJSrMZHjDCO/L+tfsNii",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/esradag/pytorch-derin-ogrenme/blob/main/PytorchTemelleri.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#PyTorch Nedir?\n",
        "PyTorch, aÃ§Ä±k kaynaklÄ± bir makine Ã¶ÄŸrenimi ve derin Ã¶ÄŸrenme frameworkâ€™Ã¼dÃ¼r.\n",
        "\n",
        "#PyTorch Ne Ä°Ã§in KullanÄ±lÄ±r?\n",
        "PyTorch, Python kodu kullanarak veri iÅŸleme ve makine Ã¶ÄŸrenimi algoritmalarÄ± yazmayÄ± saÄŸlar."
      ],
      "metadata": {
        "id": "KP3SgER0ZsAM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#PyTorch Temel KonularÄ±\n",
        "\n",
        "##TensÃ¶rlere GiriÅŸ:\n",
        "TensÃ¶rler, makine Ã¶ÄŸrenimi ve derin Ã¶ÄŸrenme modellerinin temel yapÄ± taÅŸlarÄ±dÄ±r. TÃ¼m veri iÅŸlemleri ve hesaplamalar tensÃ¶rler Ã¼zerinden gerÃ§ekleÅŸtirilir.\n",
        "\n",
        "##TensÃ¶r OluÅŸturma:\n",
        "TensÃ¶rler; gÃ¶rÃ¼ntÃ¼ler, metinler ve sayÄ± tablolarÄ± gibi farklÄ± veri tÃ¼rlerini temsil edebilir. PyTorch, farklÄ± boyut ve tÃ¼rde tensÃ¶rler oluÅŸturmayÄ± kolaylaÅŸtÄ±rÄ±r.\n",
        "\n",
        "##TensÃ¶rlerden Bilgi Alma:\n",
        "TensÃ¶rlerde depolanan verilere eriÅŸmek ve bu bilgileri analiz etmek iÃ§in Ã§eÅŸitli yÃ¶ntemler sunar.\n",
        "\n",
        "##TensÃ¶rleri ManipÃ¼le Etme:\n",
        "TensÃ¶rler Ã¼zerinde toplama, Ã§arpma ve birleÅŸtirme gibi matematiksel ve yapÄ±sal iÅŸlemler kolaylÄ±kla yapÄ±labilir.\n",
        "\n",
        "##TensÃ¶r Åekilleriyle Ã‡alÄ±ÅŸma:\n",
        "Makine Ã¶ÄŸreniminde sÄ±kÃ§a karÅŸÄ±laÅŸÄ±lan yanlÄ±ÅŸ ÅŸekilli tensÃ¶rlerin yÃ¶netimi iÃ§in ÅŸekil dÃ¶nÃ¼ÅŸtÃ¼rme ve uyumlu hale getirme iÅŸlemleri uygulanÄ±r.\n",
        "\n",
        "##TensÃ¶rlerde Ä°ndeksleme:\n",
        "Python listeleri veya NumPy dizileriyle benzer ÅŸekilde, tensÃ¶rlerde de Ã§ok boyutlu indeksleme yapÄ±labilir. Bu sayede veriye kolay eriÅŸim saÄŸlanÄ±r.\n",
        "\n",
        "##PyTorch ve NumPy KarÄ±ÅŸÄ±mÄ±:\n",
        "PyTorch tensÃ¶rleri (torch.Tensor) ve NumPy dizileri (np.ndarray) arasÄ±nda veri dÃ¶nÃ¼ÅŸÃ¼mleri kolaylÄ±kla yapÄ±labilir. BÃ¶ylece her iki kÃ¼tÃ¼phanenin avantajlarÄ±ndan yararlanÄ±lÄ±r.\n",
        "\n",
        "##Yeniden Ãœretilebilirlik:\n",
        "Makine Ã¶ÄŸreniminde deneylerin tutarlÄ±lÄ±ÄŸÄ± iÃ§in rastgeleliÄŸin kontrol edilmesi Ã¶nemlidir. PyTorch, belirli bir rastgelelik seviyesini sabitleyerek sonuÃ§larÄ±n tekrarlanabilir olmasÄ±nÄ± saÄŸlar.\n",
        "\n",
        "##TensÃ¶rleri GPUâ€™da Ã‡alÄ±ÅŸtÄ±rma:\n",
        "PyTorch, GPU (Grafik Ä°ÅŸleme Birimi) desteÄŸiyle bÃ¼yÃ¼k veri ve karmaÅŸÄ±k hesaplamalarÄ± hÄ±zlÄ± bir ÅŸekilde gerÃ§ekleÅŸtirir. Bu sayede model eÄŸitimi ve tahmin sÃ¼reÃ§leri hÄ±z kazanÄ±r."
      ],
      "metadata": {
        "id": "BabWWlYWayYo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#PyTorch'u Ä°Ã§e Aktarma\n",
        "> **Not:** Bu kodu Ã§alÄ±ÅŸtÄ±rmadan Ã¶nce, [PyTorch kurulum adÄ±mlarÄ±nÄ± ] (https://pytorch.org/get-started/locally/)  tamamlamÄ±ÅŸ olmanÄ±z gerekir.\n",
        "> Ancak, **Google Colab kullanÄ±yorsanÄ±z **herhangi bir ek kurulum yapmanÄ±za gerek yoktur Ã§Ã¼nkÃ¼ PyTorch ve diÄŸer gerekli kÃ¼tÃ¼phaneler Colab'de Ã¶nceden yÃ¼klÃ¼dÃ¼r.\n",
        "\n",
        "PyTorch'u iÃ§e aktararak ve kullanÄ±lan sÃ¼rÃ¼mÃ¼ kontrol ederek baÅŸlayalÄ±m:"
      ],
      "metadata": {
        "id": "-UfpAaulbMGo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "torch.__version__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "RX5glGB6Z148",
        "outputId": "028ac83d-009c-461a-fa84-ccbae66b0211"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.5.1+cu121'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## TensÃ¶rlere GiriÅŸ\n",
        "\n",
        "TensÃ¶rler, makine Ã¶ÄŸreniminin temel yapÄ± taÅŸÄ±dÄ±r.  \n",
        "GÃ¶revleri, verileri sayÄ±sal bir ÅŸekilde temsil etmektir.\n",
        "\n",
        "Ã–rneÄŸin, bir resmi **`[3, 224, 224]`** ÅŸeklinde bir tensÃ¶r olarak temsil edebiliriz. Bu ÅŸu anlama gelir:\n",
        "\n",
        "- **3** renk kanalÄ± (**kÄ±rmÄ±zÄ±**, **yeÅŸil**, **mavi**)  \n",
        "- **224** piksel **yÃ¼kseklik**  \n",
        "- **224** piksel **geniÅŸlik**  \n",
        "\n",
        "TensÃ¶r dilinde bu, **Ã¼Ã§ boyutlu** bir tensÃ¶rdÃ¼r:  \n",
        "\n",
        "1. **Renk kanallarÄ±** (`colour_channels`)  \n",
        "2. **YÃ¼kseklik** (`height`)  \n",
        "3. **GeniÅŸlik** (`width`)  \n"
      ],
      "metadata": {
        "id": "oSTWM2_gcHT7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### TensÃ¶r OluÅŸturma\n",
        "\n",
        "PyTorch, tensÃ¶rler Ã¼zerine kurulmuÅŸ gÃ¼Ã§lÃ¼ bir kÃ¼tÃ¼phanedir. Hatta [`torch.Tensor`](https://pytorch.org/docs/stable/tensors.html) sÄ±nÄ±fÄ±na Ã¶zel bir dokÃ¼mantasyon sayfasÄ± da bulunmaktadÄ±r.\n",
        "\n",
        "\n",
        "Ä°lk oluÅŸturulacak veri tÃ¼rÃ¼ bir **skaler**dir.\n",
        "\n",
        "**Skaler** nedir?  \n",
        "- Tek bir sayÄ±dan oluÅŸan en basit veri tÃ¼rÃ¼dÃ¼r.  \n",
        "- TensÃ¶r terminolojisinde **sÄ±fÄ±r boyutlu (0D)** bir tensÃ¶r olarak adlandÄ±rÄ±lÄ±r.  \n"
      ],
      "metadata": {
        "id": "SIafJg7kdU2o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Scalar\n",
        "scalar = torch.tensor(7)\n",
        "scalar"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i9fg_z8zdbH0",
        "outputId": "c51021fa-1256-452d-a6ab-9128494514cf"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(7)"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### TensÃ¶rlerin BoyutlarÄ±nÄ± Kontrol Etme\n",
        "\n",
        "YukarÄ±da ekrana **`tensor(7)`** Ã§Ä±ktÄ±sÄ±nÄ± gÃ¶rdÃ¼nÃ¼z mÃ¼?  \n",
        "\n",
        "Bu, **scalar** tek bir sayÄ± olmasÄ±na raÄŸmen, PyTorch'ta **`torch.Tensor`** tÃ¼rÃ¼nde olduÄŸunu gÃ¶sterir.\n",
        "\n",
        "Bir tensÃ¶rÃ¼n boyutunu kontrol etmek iÃ§in **`.ndim`** Ã¶zelliÄŸini kullanabiliriz.\n"
      ],
      "metadata": {
        "id": "eK1R_HX2cssS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scalar.ndim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CXmtxgftdw1G",
        "outputId": "1de5a276-90d1-4e81-e832-03e8abddc2e0"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### VektÃ¶r (Vector) Nedir?\n",
        "\n",
        "Åimdi de **vektÃ¶r** kavramÄ±nÄ± inceleyelim.  \n",
        "\n",
        "Bir **vektÃ¶r**, tek boyutlu (**1D**) bir tensÃ¶rdÃ¼r ancak birden fazla sayÄ± iÃ§erebilir.\n",
        "\n",
        "Ã–rneÄŸin, evinizdeki oda bilgilerini temsil etmek iÃ§in bir vektÃ¶r kullanabilirsiniz:  \n",
        "- `[3, 2]` â†’ **3** yatak odasÄ± ve **2** banyo  \n",
        "- `[3, 2, 2]` â†’ **3** yatak odasÄ±, **2** banyo ve **2** otopark alanÄ±  \n",
        "\n",
        "Burada dikkat edilmesi gereken Ã¶nemli nokta, bir **vektÃ¶rÃ¼n** (ve tensÃ¶rlerin) neyi temsil edeceÄŸi konusunda esnek olmasÄ±dÄ±r.\n",
        "\n"
      ],
      "metadata": {
        "id": "skTafv9Id6CL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Vector\n",
        "vector = torch.tensor([7, 7])\n",
        "vector"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l4xwrhkfd5kK",
        "outputId": "a0afe6ed-0a66-4085-c765-6b656beb5136"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([7, 7])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### VektÃ¶rÃ¼n Boyutunu ve Åeklini Anlama\n",
        "\n",
        "Ä°lginÃ§ deÄŸil mi? **`vector`** iki sayÄ± iÃ§eriyor ancak yalnÄ±zca **tek bir boyuta** sahip.  \n",
        "\n",
        "Bu durumu daha iyi anlamanÄ±z iÃ§in size kÃ¼Ã§Ã¼k bir ipucu vereyim:  \n",
        "\n",
        "**Bir tensÃ¶rÃ¼n kaÃ§ boyutlu olduÄŸunu, kÃ¶ÅŸeli parantez sayÄ±sÄ±ndan anlayabilirsiniz (`[`).**  \n",
        "Ve yalnÄ±zca **bir tarafÄ±** saymanÄ±z yeterlidir.\n",
        "\n",
        "Ã–rneÄŸin:  \n",
        "- **`[1, 2, 3]`** â†’ **1 boyutlu** tensÃ¶r (**vektÃ¶r**)  \n",
        "- **`[[1, 2, 3], [4, 5, 6]]`** â†’ **2 boyutlu** tensÃ¶r (**matris**)  \n",
        "- **`[[[1], [2]], [[3], [4]]]`** â†’ **3 boyutlu** tensÃ¶r  \n",
        "\n",
        "Peki, **`vector`** kaÃ§ kÃ¶ÅŸeli parantez iÃ§eriyor?  \n",
        "\n",
        "---\n",
        "\n",
        "TensÃ¶rlerle ilgili Ã¶nemli bir diÄŸer kavram ise **`shape`** (ÅŸekil) Ã¶zelliÄŸidir.  \n",
        "**`shape`**, tensÃ¶r iÃ§indeki elemanlarÄ±n nasÄ±l dÃ¼zenlendiÄŸini gÃ¶sterir.\n"
      ],
      "metadata": {
        "id": "iENHs35RebmC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# VektÃ¶rÃ¼n ÅŸeklini kontrol etme\n",
        "vector.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ZWDUJzVee4g",
        "outputId": "9fd63772-735d-4add-ef41-2d0b0daf1940"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Matris (Matrix) Nedir?\n",
        "\n",
        "Bir Ã¶nceki iÅŸlemde elde ettiÄŸimiz sonuÃ§ **`torch.Size([2])`** oldu. Bu, vektÃ¶rÃ¼mÃ¼zÃ¼n **[2]** ÅŸeklinde olduÄŸunu gÃ¶sterir.  \n",
        "Bunun nedeni, kÃ¶ÅŸeli parantezler iÃ§ine **iki eleman** yerleÅŸtirmiÅŸ olmamÄ±zdÄ±r (`[7, 7]`).\n",
        "\n",
        "Åimdi bir **matris** oluÅŸturalÄ±m.\n",
        "\n",
        "**Matris**, **iki boyutlu (2D)** bir tensÃ¶rdÃ¼r.  \n",
        "Ã–rneÄŸin, aÅŸaÄŸÄ±daki gibi bir yapÄ± matristir:\n",
        "\n"
      ],
      "metadata": {
        "id": "YtCcmUWzert_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Matris (2D tensÃ¶r) oluÅŸturma\n",
        "MATRIX = torch.tensor([[7, 8],\n",
        "                       [9, 10]])\n",
        "\n",
        "MATRIX"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RmeTD2sKezbh",
        "outputId": "3a653c15-33aa-48d5-fab9-bfa74b5c8963"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 7,  8],\n",
              "        [ 9, 10]])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Matrisler (Matrix) â€“ Ã‡ok Boyutlu Veri Temsili\n",
        "\n",
        "**VektÃ¶rler** tek boyutlu tensÃ¶rlerken, **matrisler** ekstra bir boyut ekleyerek verileri daha esnek ve karmaÅŸÄ±k bir ÅŸekilde temsil eder.  \n",
        "Matrisler, **satÄ±r (row)** ve **sÃ¼tun (column)** yapÄ±sÄ±ndan oluÅŸur ve genellikle **2 boyutlu (2D)** tensÃ¶rler olarak adlandÄ±rÄ±lÄ±r.\n"
      ],
      "metadata": {
        "id": "CIwn4nvZhlLL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### ğŸ“ Matrisin Boyut SayÄ±sÄ±nÄ± Kontrol Etme\n",
        "\n",
        "Bir tensÃ¶rÃ¼n kaÃ§ boyutlu olduÄŸunu Ã¶ÄŸrenmek iÃ§in **`.ndim`** Ã¶zelliÄŸini kullanabiliriz.  \n",
        "Bu Ã¶zellik, tensÃ¶rÃ¼n boyut (dimension) sayÄ±sÄ±nÄ± dÃ¶ndÃ¼rÃ¼r."
      ],
      "metadata": {
        "id": "oa8sTRQVhtVD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Matrisin boyut sayÄ±sÄ±nÄ± kontrol etme\n",
        "MATRIX.ndim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kN9hA29yhvUZ",
        "outputId": "8e365ea5-2ed7-48b0-88b1-43281e106e1c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### ğŸ“ Matrisin Åekli (Shape) Ne Olacak?\n",
        "\n",
        "**`MATRIX`** tensÃ¶rÃ¼nÃ¼n **2 boyutlu (2D)** olduÄŸunu Ã¶ÄŸrendik.  \n",
        "(Bunu, dÄ±ÅŸtaki kÃ¶ÅŸeli parantezleri sayarak da anlayabiliriz! ğŸ˜‰)\n",
        "\n",
        "Peki, bu matrisin **ÅŸekli (shape)** nasÄ±l olacak?"
      ],
      "metadata": {
        "id": "ZwnkWsC3h6Dt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Matrisin ÅŸeklini kontrol etme\n",
        "MATRIX.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6nXh8mgwh70U",
        "outputId": "caa3aa31-f292-4d31-aed8-63618eeab93e"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ğŸ”¢ TensÃ¶r (Tensor) OluÅŸturma\n",
        "\n",
        "Åimdi daha genel ve Ã§ok boyutlu bir **tensÃ¶r** oluÅŸturalÄ±m.  \n",
        "**TensÃ¶rler**, skaler, vektÃ¶r ve matrislerden daha fazla boyut iÃ§erebilir ve Ã§ok daha karmaÅŸÄ±k verileri temsil etmek iÃ§in kullanÄ±lÄ±r.\n",
        "\n",
        "Ã–rneÄŸin, **3 boyutlu (3D)** bir tensÃ¶r oluÅŸturalÄ±m."
      ],
      "metadata": {
        "id": "JmGN7euTiJqF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 3 boyutlu bir tensÃ¶r oluÅŸturma\n",
        "TENSOR = torch.tensor([[[1, 2, 3],\n",
        "                        [3, 6, 9],\n",
        "                        [2, 4, 5]]])\n",
        "\n",
        "# TensÃ¶rÃ¼ yazdÄ±rma\n",
        "print(TENSOR)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MADADlgfiVIh",
        "outputId": "1bb8c29a-209c-460c-af91-c6343ee9a549"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[1, 2, 3],\n",
            "         [3, 6, 9],\n",
            "         [2, 4, 5]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ğŸ” TensÃ¶rler Neredeyse Her Åeyi Temsil Edebilir!\n",
        "\n",
        "GerÃ§ekten etkileyici bir tensÃ¶r oluÅŸturduk! ğŸ‰\n",
        "\n",
        "**TensÃ¶rler**, hemen hemen her tÃ¼rlÃ¼ veriyi temsil edebilir.  \n",
        "Az Ã¶nce oluÅŸturduÄŸumuz tensÃ¶r, Ã¶rneÄŸin bir **steak ve badem ezmesi** dÃ¼kkanÄ±nÄ±n satÄ±ÅŸ verilerini gÃ¶sterebilir! ğŸ–ğŸ¥œ\n",
        "\n",
        "ğŸ“Š **GÃ¶rsel Temsil:**  \n",
        "![Steak ve Badem Ezmesi SatÄ±ÅŸlarÄ±](https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/images/00_simple_tensor.png)  \n",
        "\n",
        "Bu tensÃ¶r, haftanÄ±n gÃ¼nlerine gÃ¶re **steak** ve **badem ezmesi** satÄ±ÅŸlarÄ±nÄ± temsil ediyor olabilir.\n",
        "\n",
        "\n",
        "### â“ **KaÃ§ Boyutlu Bir TensÃ¶r?**\n",
        "\n",
        "Åimdi bu tensÃ¶rÃ¼n kaÃ§ boyutlu olduÄŸunu bulalÄ±m!  \n",
        "ğŸ“Œ **Ä°pucu:** DÄ±ÅŸtaki kÃ¶ÅŸeli parantezleri (`[ ]`) sayÄ±n!"
      ],
      "metadata": {
        "id": "GN6nU9nBiio5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TENSOR deÄŸiÅŸkeninin boyut sayÄ±sÄ±nÄ± kontrol etme\n",
        "TENSOR.ndim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DiJqLXQFijoL",
        "outputId": "565437b5-c406-4887-bfce-8e8cf8a6fc09"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TENSOR deÄŸiÅŸkeninin ÅŸeklini (boyutlarÄ±nÄ±n dÃ¼zenini) kontrol etme\n",
        "TENSOR.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WjkmKhCbhl-s",
        "outputId": "bda8e873-7b2d-4f19-c867-2b71bb2b2672"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 3, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ğŸ” TensÃ¶r BoyutlarÄ± ve Ä°simlendirme\n",
        "\n",
        "**`torch.Size([1, 3, 3])`** Ã§Ä±ktÄ±sÄ± bize ÅŸunu sÃ¶ylÃ¼yor:  \n",
        "- DÄ±ÅŸtan iÃ§e doÄŸru gidildiÄŸinde, **1 adet 3x3 matris** olduÄŸunu anlÄ±yoruz.  \n",
        "- Yani bu tensÃ¶r, **3 boyutlu (3D)** bir yapÄ±ya sahip.\n",
        "\n",
        "ğŸ“Š **GÃ¶rsel Temsil:**  \n",
        "![FarklÄ± TensÃ¶r BoyutlarÄ±](https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/images/00-pytorch-different-tensor-dimensions.png)\n",
        "\n",
        "---\n",
        "\n",
        "### âœï¸ **Ä°simlendirme KurallarÄ±**\n",
        "\n",
        "Dikkat ettiyseniz, kÃ¼Ã§Ã¼k harfleri **`scalar`** ve **`vector`** iÃ§in, bÃ¼yÃ¼k harfleri ise **`MATRIX`** ve **`TENSOR`** iÃ§in kullandÄ±m.  \n",
        "Bu kasÄ±tlÄ± bir tercihti ve pratikte yaygÄ±n bir uygulamadÄ±r.  \n",
        "\n",
        "ğŸ“Œ **Genel Ä°simlendirme:**  \n",
        "- **Skaler (scalar)** ve **vektÃ¶r (vector)** â†’ Genellikle **kÃ¼Ã§Ã¼k harf** kullanÄ±lÄ±r (**`a`, `y`**)  \n",
        "- **Matris (matrix)** ve **tensÃ¶r (tensor)** â†’ Genellikle **bÃ¼yÃ¼k harf** kullanÄ±lÄ±r (**`X`, `W`**)  \n",
        "\n",
        "âš ï¸ **Not:** PyTorch'ta genellikle tÃ¼m veriler **`torch.Tensor`** olarak tanÄ±mlanÄ±r. Ancak iÃ§eriÄŸin boyutu ve ÅŸekli, verinin **skaler**, **vektÃ¶r**, **matris** veya daha yÃ¼ksek boyutlu bir tensÃ¶r olup olmadÄ±ÄŸÄ±nÄ± belirler.\n",
        "\n",
        "---\n",
        "\n",
        "### ğŸ“Š **Ã–zet Tablo**\n",
        "\n",
        "| **Ä°sim**   | **Nedir?**                                      | **Boyut SayÄ±sÄ±**  | **Genel Ä°simlendirme** |\n",
        "|------------|--------------------------------------------------|-------------------|------------------------|\n",
        "| **scalar** | Tek bir sayÄ±                                     | **0**             | KÃ¼Ã§Ã¼k harf (`a`)      |\n",
        "| **vector** | YÃ¶nÃ¼ olan sayÄ± dizisi (Ã¶rneÄŸin rÃ¼zgar hÄ±zÄ±)      | **1**             | KÃ¼Ã§Ã¼k harf (`y`)      |\n",
        "| **matrix** | 2 boyutlu sayÄ± dizisi                           | **2**             | BÃ¼yÃ¼k harf (`Q`)      |\n",
        "| **tensor** | **n** boyutlu sayÄ± dizisi                       | **0 ve Ã¼zeri**    | BÃ¼yÃ¼k harf (`X`)      |\n",
        "\n",
        "ğŸ“Œ **Ek Bilgi:**  \n",
        "- **0D** â†’ **Skaler**  \n",
        "- **1D** â†’ **VektÃ¶r**  \n",
        "- **2D** â†’ **Matris**  \n",
        "- **3D ve Ã¼zeri** â†’ **TensÃ¶r**  \n",
        "\n",
        "---\n",
        "\n",
        "### ğŸ¨ **GÃ¶rsel Temsil**\n",
        "\n",
        "![Skaler, VektÃ¶r, Matris ve TensÃ¶r GÃ¶rseli](https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/images/00-scalar-vector-matrix-tensor.png)\n",
        "\n",
        "Bu gÃ¶rselde farklÄ± boyutlardaki tensÃ¶rler arasÄ±ndaki farklarÄ± aÃ§Ä±kÃ§a gÃ¶rebilirsiniz.\n",
        "\n",
        "> ğŸ’¡ **UnutmayÄ±n:** PyTorchâ€™ta tÃ¼m veriler tensÃ¶r olarak iÅŸlenir. Ancak bu tensÃ¶rlerin boyutu ve ÅŸekli, onlarÄ± nasÄ±l yorumladÄ±ÄŸÄ±mÄ±zÄ± belirler!\n"
      ],
      "metadata": {
        "id": "5UBaoJHsjCDB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ğŸ² Rastgele TensÃ¶rler (Random Tensors)\n",
        "\n",
        "Daha Ã¶nce tensÃ¶rlerin verileri temsil ettiÄŸini Ã¶ÄŸrendik.  \n",
        "Makine Ã¶ÄŸrenimi modelleri (Ã¶zellikle **sinir aÄŸlarÄ±**) bu tensÃ¶rleri iÅŸleyerek iÃ§indeki kalÄ±plarÄ± ve iliÅŸkileri keÅŸfeder.\n",
        "\n",
        "Ancak, PyTorch ile makine Ã¶ÄŸrenimi modeli geliÅŸtirirken, tensÃ¶rleri elle oluÅŸturmak (ÅŸu ana kadar yaptÄ±ÄŸÄ±mÄ±z gibi) oldukÃ§a nadir bir durumdur.\n",
        "\n",
        "---\n",
        "\n",
        "### ğŸ”„ **Makine Ã–ÄŸreniminde Rastgele TensÃ¶rlerin Ã–nemi**\n",
        "\n",
        "Makine Ã¶ÄŸrenimi modelleri genellikle baÅŸlangÄ±Ã§ta rastgele sayÄ±larla doldurulmuÅŸ bÃ¼yÃ¼k tensÃ¶rlerle baÅŸlar.  \n",
        "Model, bu rastgele sayÄ±larÄ± veriyi iÅŸlerken gÃ¼nceller ve daha iyi tahminler yapmayÄ± Ã¶ÄŸrenir.\n",
        "\n",
        "Bu sÃ¼reci ÅŸu ÅŸekilde Ã¶zetleyebiliriz:\n",
        "\n",
        "`Rastgele sayÄ±larla baÅŸla â†’ Veriye bak â†’ SayÄ±larÄ± gÃ¼ncelle â†’ Veriye tekrar bak â†’ SayÄ±larÄ± gÃ¼ncelle...`\n",
        "\n",
        "ğŸ“Œ **Veri bilimcisi** olarak, modelin:  \n",
        "- **BaÅŸlangÄ±Ã§ deÄŸerlerini (initialization)** nasÄ±l belirleyeceÄŸini,  \n",
        "- **Veriyi (representation)** nasÄ±l iÅŸleyeceÄŸini ve  \n",
        "- **SayÄ±larÄ± (optimization)** nasÄ±l gÃ¼ncelleyeceÄŸini kontrol edebilirsiniz.\n",
        "\n",
        "Bu adÄ±mlarÄ± ilerleyen bÃ¶lÃ¼mlerde uygulamalÄ± olarak inceleyeceÄŸiz.  \n",
        "Åimdilik, rastgele sayÄ± iÃ§eren tensÃ¶rleri nasÄ±l oluÅŸturacaÄŸÄ±mÄ±za bakalÄ±m.\n",
        "\n",
        "---\n",
        "\n",
        "### ğŸ“ **Rastgele TensÃ¶r OluÅŸturma**\n",
        "\n",
        "Rastgele sayÄ± iÃ§eren tensÃ¶rleri oluÅŸturmak iÃ§in [`torch.rand()`](https://pytorch.org/docs/stable/generated/torch.rand.html) fonksiyonunu kullanabiliriz.  \n",
        "Bu fonksiyon, **0 ile 1** arasÄ±nda rastgele sayÄ± Ã¼reten bir tensÃ¶r oluÅŸturur.\n",
        "\n"
      ],
      "metadata": {
        "id": "IPXQkS5PjYTX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# (3, 4) boyutunda rastgele sayÄ± iÃ§eren bir tensÃ¶r oluÅŸturma\n",
        "random_tensor = torch.rand(size=(3, 4))\n",
        "\n",
        "# TensÃ¶rÃ¼ ve veri tipini yazdÄ±rma\n",
        "random_tensor, random_tensor.dtype"
      ],
      "metadata": {
        "id": "QnGv0yrIi0uY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "540d1dce-fa39-4478-de67-f2bc8016f117"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[0.4131, 0.4675, 0.0333, 0.9974],\n",
              "         [0.1534, 0.5545, 0.2321, 0.3569],\n",
              "         [0.6491, 0.9851, 0.5991, 0.1810]]),\n",
              " torch.float32)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ğŸ¨ GÃ¶rsel Verilere Uygun Rastgele TensÃ¶r OluÅŸturma\n",
        "\n",
        "**`torch.rand()`** fonksiyonunun en bÃ¼yÃ¼k avantajlarÄ±ndan biri, **`size`** parametresini istediÄŸimiz gibi ayarlayabilmemizdir.  \n",
        "Bu sayede, farklÄ± veri tÃ¼rleri ve boyutlarÄ±na uygun tensÃ¶rler oluÅŸturabiliriz.\n",
        "\n",
        "Ã–rneÄŸin, gÃ¶rseller genellikle ÅŸu boyutlarda temsil edilir:  \n",
        "**`[224, 224, 3]`** â†’ **[yÃ¼kseklik, geniÅŸlik, renk kanallarÄ±]**  \n",
        "- **224** piksel yÃ¼kseklik  \n",
        "- **224** piksel geniÅŸlik  \n",
        "- **3** renk kanalÄ± (**RGB**: KÄ±rmÄ±zÄ±, YeÅŸil, Mavi)\n",
        "\n",
        "Bu tÃ¼r bir tensÃ¶r, gÃ¶rÃ¼ntÃ¼ iÅŸleme projelerinde yaygÄ±n olarak kullanÄ±lÄ±r.\n"
      ],
      "metadata": {
        "id": "RCiwWXtRjwZ4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# (224, 224, 3) boyutunda rastgele sayÄ± iÃ§eren bir tensÃ¶r oluÅŸturma\n",
        "random_image_size_tensor = torch.rand(size=(224, 224, 3))\n",
        "\n",
        "# TensÃ¶rÃ¼n ÅŸeklini (shape) ve boyut sayÄ±sÄ±nÄ± (ndim) kontrol etme\n",
        "random_image_size_tensor.shape, random_image_size_tensor.ndim\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fDLLZ_lQjydO",
        "outputId": "7be435d7-143b-4abc-df09-de6cd0594535"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([224, 224, 3]), 3)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ğŸŸ¢ **SÄ±fÄ±r ve Birlerle Dolu TensÃ¶rler (Zeros and Ones)**\n",
        "\n",
        "Bazen tensÃ¶rleri sadece **0** veya **1** deÄŸerleriyle doldurmak isteyebilirsiniz.  \n",
        "Bu Ã¶zellikle **maskelere** ihtiyaÃ§ duyulan durumlarda kullanÄ±lÄ±r.  \n",
        "\n",
        "ğŸ“Œ **Maskeleme (Masking):**  \n",
        "Belirli verileri modelden gizlemek veya dikkate almamasÄ±nÄ± saÄŸlamak iÃ§in tensÃ¶rlerin bazÄ± kÄ±sÄ±mlarÄ±nÄ± **0** ile doldururuz.  \n",
        "Bu yÃ¶ntem, modelin Ã¶ÄŸrenmesini kontrol etmek iÃ§in sÄ±kÃ§a kullanÄ±lÄ±r.\n",
        "\n",
        "---\n",
        "\n",
        "### ğŸ“ **SÄ±fÄ±rlarla Dolu TensÃ¶r OluÅŸturma**\n",
        "\n",
        "**`torch.zeros()`** fonksiyonunu kullanarak tamamen sÄ±fÄ±rlarla dolu bir tensÃ¶r oluÅŸturabiliriz.\n"
      ],
      "metadata": {
        "id": "Z_sIJAdpkGPy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# (3, 4) boyutunda sÄ±fÄ±rlardan oluÅŸan bir tensÃ¶r oluÅŸturma\n",
        "zeros = torch.zeros(size=(3, 4))\n",
        "\n",
        "# TensÃ¶rÃ¼ ve veri tipini yazdÄ±rma\n",
        "zeros, zeros.dtype"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SFL-sPjhjppl",
        "outputId": "a720d913-427e-4b10-eb09-3eaee4ff57f8"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0.]]),\n",
              " torch.float32)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ğŸ”¢ Birlerle Dolu TensÃ¶r OluÅŸturma\n",
        "\n",
        "TÄ±pkÄ± sÄ±fÄ±rlarla dolu bir tensÃ¶r oluÅŸturduÄŸumuz gibi, **`torch.ones()`** fonksiyonunu kullanarak tÃ¼m elemanlarÄ± **1** olan bir tensÃ¶r oluÅŸturabiliriz.  \n",
        "Bu fonksiyon, belirli boyutlarda ve tÃ¼m deÄŸerleri **1** olan bir tensÃ¶r oluÅŸturur.\n"
      ],
      "metadata": {
        "id": "v_AaxC8WkUEm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# (3, 4) boyutunda birlerden oluÅŸan bir tensÃ¶r oluÅŸturma\n",
        "ones = torch.ones(size=(3, 4))\n",
        "\n",
        "# TensÃ¶rÃ¼ ve veri tipini yazdÄ±rma\n",
        "ones, ones.dtype"
      ],
      "metadata": {
        "id": "lTdN5pTckYFs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "04b6427d-35b2-403d-81cc-8f0c9cf4b664"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[1., 1., 1., 1.],\n",
              "         [1., 1., 1., 1.],\n",
              "         [1., 1., 1., 1.]]),\n",
              " torch.float32)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ğŸ”¢ **Belirli Bir AralÄ±kta TensÃ¶r OluÅŸturma (Range ve Benzersiz TensÃ¶rler)**\n",
        "\n",
        "Bazen belirli bir sayÄ± aralÄ±ÄŸÄ±nda bir tensÃ¶r oluÅŸturmak isteyebilirsiniz.  \n",
        "Ã–rneÄŸin, **1'den 10'a** veya **0'dan 100'e** kadar olan sayÄ±lar.\n",
        "\n",
        "Bunu **`torch.arange(start, end, step)`** fonksiyonunu kullanarak yapabiliriz.\n",
        "\n",
        "---\n",
        "\n",
        "### âš™ï¸ **Parametreler:**\n",
        "\n",
        "- **`start`** â†’ AralÄ±ÄŸÄ±n baÅŸlangÄ±Ã§ deÄŸeri (Ã¶rn. **0**)  \n",
        "- **`end`** â†’ AralÄ±ÄŸÄ±n bitiÅŸ deÄŸeri (Ã¶rn. **10**) *(bitiÅŸ deÄŸeri dahil deÄŸildir)*  \n",
        "- **`step`** â†’ SayÄ±lar arasÄ±ndaki artÄ±ÅŸ miktarÄ± (Ã¶rn. **1**)\n",
        "\n",
        "ğŸ“Œ **Not:**  \n",
        "- Python'da **`range()`** fonksiyonunu kullanarak da sayÄ± aralÄ±klarÄ± oluÅŸturabilirsiniz.  \n",
        "- Ancak PyTorch'ta **`torch.range()`** fonksiyonu artÄ±k **kullanÄ±mdan kaldÄ±rÄ±lmÄ±ÅŸtÄ±r** ve ileride hata verebilir.  \n",
        "  Bunun yerine **`torch.arange()`** kullanÄ±lmalÄ±dÄ±r.\n"
      ],
      "metadata": {
        "id": "26pj-1amknbf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# âš ï¸ Dikkat: torch.range() kullanÄ±mdan kaldÄ±rÄ±lmÄ±ÅŸtÄ±r (deprecated)\n",
        "zero_to_ten_deprecated = torch.range(0, 10)  # Bu kullanÄ±m gelecekte hata verebilir!\n",
        "\n",
        "# âœ… DoÄŸru kullanÄ±m: torch.arange() ile 0'dan 10'a kadar bir tensÃ¶r oluÅŸturma\n",
        "zero_to_ten = torch.arange(start=0, end=10, step=1)\n",
        "\n",
        "# TensÃ¶rÃ¼ yazdÄ±rma\n",
        "zero_to_ten"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AjNX3QXlkf7Z",
        "outputId": "e62edb9a-13af-44d1-95f6-9938c5a86c44"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-16-4ec072aa6a03>:2: UserWarning: torch.range is deprecated and will be removed in a future release because its behavior is inconsistent with Python's range builtin. Instead, use torch.arange, which produces values in [start, end).\n",
            "  zero_to_ten_deprecated = torch.range(0, 10)  # Bu kullanÄ±m gelecekte hata verebilir!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ğŸ” **BaÅŸka Bir TensÃ¶rle AynÄ± Åekilde TensÃ¶r OluÅŸturma**\n",
        "\n",
        "Bazen mevcut bir tensÃ¶rle **aynÄ± boyutta** ancak farklÄ± deÄŸerlerle (sÄ±fÄ±r veya bir) doldurulmuÅŸ yeni bir tensÃ¶r oluÅŸturmak isteyebilirsiniz.  \n",
        "\n",
        "Bu durumda, **`torch.zeros_like()`** ve **`torch.ones_like()`** fonksiyonlarÄ±nÄ± kullanabilirsiniz.  \n",
        "\n",
        "- **`torch.zeros_like(input)`** â†’ Verilen tensÃ¶rle aynÄ± boyutta, **sÄ±fÄ±rlardan** oluÅŸan bir tensÃ¶r oluÅŸturur.  \n",
        "- **`torch.ones_like(input)`** â†’ Verilen tensÃ¶rle aynÄ± boyutta, **birlerden** oluÅŸan bir tensÃ¶r oluÅŸturur.  \n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "aAe8jjsPlEOR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mevcut bir tensÃ¶rle aynÄ± boyutta sÄ±fÄ±rlardan oluÅŸan bir tensÃ¶r oluÅŸturma\n",
        "ten_zeros = torch.zeros_like(input=zero_to_ten)  # zero_to_ten ile aynÄ± boyutta\n",
        "\n",
        "# OluÅŸturulan tensÃ¶rÃ¼ yazdÄ±rma\n",
        "ten_zeros"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bc9jS0O2lE-_",
        "outputId": "4c8bf102-e8bf-44c8-a8c1-5fb9dd55bc23"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ğŸ§© **TensÃ¶r Veri Tipleri (Tensor Datatypes)**\n",
        "\n",
        "PyTorch'ta birÃ§ok farklÄ± **tensÃ¶r veri tipi (datatype)** bulunmaktadÄ±r.  \n",
        "Bu veri tiplerinin bazÄ±larÄ± **CPU**, bazÄ±larÄ± ise **GPU** iÃ§in daha uygundur.\n",
        "\n",
        "ğŸ” **Genel Bilgiler:**  \n",
        "- **`torch.cuda`** kullanÄ±mÄ±, tensÃ¶rÃ¼n **GPU**'da Ã§alÄ±ÅŸtÄ±rÄ±ldÄ±ÄŸÄ±nÄ± gÃ¶sterir.  \n",
        "- En yaygÄ±n (ve varsayÄ±lan) veri tipi **`torch.float32`** veya **`torch.float`**â€™tir.  \n",
        "- Bu tÃ¼r, **32-bit kayan noktalÄ± sayÄ± (floating point)** olarak bilinir.\n",
        "\n",
        "---\n",
        "\n",
        "### ğŸ“Š **FarklÄ± Veri Tipleri**\n",
        "\n",
        "| **Veri Tipi**             | **AÃ§Ä±klama**                       | **KÄ±saltma**  |\n",
        "|---------------------------|------------------------------------|---------------|\n",
        "| **32-bit Float**          | Kayan noktalÄ± sayÄ± (varsayÄ±lan)    | `torch.float32` veya `torch.float` |\n",
        "| **16-bit Float**          | Daha dÃ¼ÅŸÃ¼k hassasiyetli float      | `torch.float16` veya `torch.half`  |\n",
        "| **64-bit Float**          | Daha yÃ¼ksek hassasiyetli float     | `torch.float64` veya `torch.double` |\n",
        "| **8, 16, 32, 64-bit Int** | Tam sayÄ±lar                       | `torch.int8`, `torch.int16`, `torch.int32`, `torch.int64` |\n",
        "\n",
        "> **Not:**  \n",
        "> - **Tam sayÄ±lar (integer):** Kesirli olmayan sayÄ±lar (Ã¶rn. **7**)  \n",
        "> - **Kayan noktalÄ± sayÄ±lar (float):** OndalÄ±klÄ± sayÄ±lar (Ã¶rn. **7.0**)  \n",
        "\n",
        "ğŸ” **Hassasiyet (Precision):**  \n",
        "- **DÃ¼ÅŸÃ¼k hassasiyet (8, 16-bit):** Daha hÄ±zlÄ± iÅŸlem yapÄ±lÄ±r ancak doÄŸruluk biraz dÃ¼ÅŸebilir.  \n",
        "- **YÃ¼ksek hassasiyet (32, 64-bit):** Daha fazla detay iÃ§erir ancak hesaplama sÃ¼resi uzar.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "urBksgNaljOv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Belirli Veri Tipleriyle TensÃ¶r OluÅŸturma\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# 32-bit float tensÃ¶r (varsayÄ±lan)\n",
        "float32_tensor = torch.tensor([1.0, 2.0, 3.0], dtype=torch.float32)\n",
        "\n",
        "# 16-bit float tensÃ¶r\n",
        "float16_tensor = torch.tensor([1.0, 2.0, 3.0], dtype=torch.float16)\n",
        "\n",
        "# 64-bit float tensÃ¶r\n",
        "float64_tensor = torch.tensor([1.0, 2.0, 3.0], dtype=torch.float64)\n",
        "\n",
        "# 32-bit integer tensÃ¶r\n",
        "int32_tensor = torch.tensor([1, 2, 3], dtype=torch.int32)\n",
        "\n",
        "# TensÃ¶rleri yazdÄ±rma\n",
        "print(\"32-bit Float Tensor:\", float32_tensor)\n",
        "print(\"16-bit Float Tensor:\", float16_tensor)\n",
        "print(\"64-bit Float Tensor:\", float64_tensor)\n",
        "print(\"32-bit Integer Tensor:\", int32_tensor)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NNilqe53liTg",
        "outputId": "b4c2c88d-3670-441d-e83a-7447f1b515c9"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "32-bit Float Tensor: tensor([1., 2., 3.])\n",
            "16-bit Float Tensor: tensor([1., 2., 3.], dtype=torch.float16)\n",
            "64-bit Float Tensor: tensor([1., 2., 3.], dtype=torch.float64)\n",
            "32-bit Integer Tensor: tensor([1, 2, 3], dtype=torch.int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# VarsayÄ±lan olarak float32 tipinde bir tensÃ¶r oluÅŸturma\n",
        "float_32_tensor = torch.tensor([3.0, 6.0, 9.0],\n",
        "                               dtype=None,         # Belirtilmezse varsayÄ±lan olarak torch.float32 olur\n",
        "                               device=None,        # Belirtilmezse CPU kullanÄ±lÄ±r\n",
        "                               requires_grad=False)  # False olduÄŸu iÃ§in gradyan hesaplanmaz\n",
        "\n",
        "# TensÃ¶rÃ¼n ÅŸekli, veri tipi ve cihaz bilgisi\n",
        "float_32_tensor.shape, float_32_tensor.dtype, float_32_tensor.device\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dJ117geslupG",
        "outputId": "87b4e1ea-7ba3-4725-fa45-ebed7861d407"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([3]), torch.float32, device(type='cpu'))"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### âš ï¸ **PyTorch'ta YaygÄ±n Hatalar: Veri Tipi ve Cihaz UyumsuzluklarÄ±**\n",
        "\n",
        "PyTorch'ta karÅŸÄ±laÅŸÄ±lan en yaygÄ±n hatalardan biri, **tensÃ¶r ÅŸekli (shape)** uyuÅŸmazlÄ±klarÄ±dÄ±r.  \n",
        "Ancak bunun dÄ±ÅŸÄ±nda iki Ã¶nemli hata tÃ¼rÃ¼ daha vardÄ±r:\n",
        "\n",
        "1. **Veri Tipi (Datatype) UyumsuzluklarÄ±:**  \n",
        "   - Bir tensÃ¶r **`torch.float32`**, diÄŸeri **`torch.float16`** olduÄŸunda uyumsuzluk oluÅŸabilir.  \n",
        "   - PyTorch, genellikle tensÃ¶rlerin aynÄ± veri tipinde olmasÄ±nÄ± ister.\n",
        "\n",
        "2. **Cihaz (Device) UyumsuzluklarÄ±:**  \n",
        "   - Bir tensÃ¶r **CPU** Ã¼zerinde, diÄŸeri **GPU** Ã¼zerinde olduÄŸunda hata verebilir.  \n",
        "   - PyTorch, iÅŸlemlerin aynÄ± cihazda yÃ¼rÃ¼tÃ¼lmesini bekler.\n",
        "\n",
        "ğŸ“Œ **Not:**  \n",
        "- TensÃ¶rler arasÄ± hesaplamalarda **aynÄ± veri tipi** ve **aynÄ± cihazda** olmalarÄ± Ã¶nemlidir.  \n",
        "- Ä°lerleyen konularda bu cihaz yÃ¶netimini daha detaylÄ± inceleyeceÄŸiz.\n",
        "\n",
        "---\n",
        "\n",
        "### ğŸ“ **torch.float16 Veri Tipinde TensÃ¶r OluÅŸturma**\n",
        "\n",
        "Åimdi, **`torch.float16`** veri tipinde bir tensÃ¶r oluÅŸturalÄ±m.  \n",
        "**`torch.float16`**, daha dÃ¼ÅŸÃ¼k hassasiyetli ve daha hÄ±zlÄ± hesaplamalar iÃ§in kullanÄ±lÄ±r.\n"
      ],
      "metadata": {
        "id": "X1Izbba5mEM6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 16-bit kayan noktalÄ± (float16) tensÃ¶r oluÅŸturma\n",
        "float_16_tensor = torch.tensor([3.0, 6.0, 9.0],\n",
        "                               dtype=torch.float16)  # torch.half da kullanÄ±labilir\n",
        "\n",
        "# TensÃ¶rÃ¼n veri tipini kontrol etme\n",
        "float_16_tensor.dtype"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0S8-IvdbmEBX",
        "outputId": "9f261e68-ede0-4a78-ab56-8085c4aa2ff0"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.float16"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## â„¹ï¸ TensÃ¶rlerden Bilgi Alma\n",
        "\n",
        "TensÃ¶rler oluÅŸturduktan sonra (ister kendiniz, ister bir PyTorch modÃ¼lÃ¼ tarafÄ±ndan oluÅŸturulmuÅŸ olsun), onlarla ilgili bazÄ± bilgilere ihtiyaÃ§ duyabilirsiniz.\n",
        "\n",
        "Daha Ã¶nce de gÃ¶rdÃ¼ÄŸÃ¼mÃ¼z gibi, tensÃ¶rlerle ilgili en yaygÄ±n kullanÄ±lan Ã¼Ã§ Ã¶zellik ÅŸunlardÄ±r:\n",
        "\n",
        "- **`shape`** â†’ TensÃ¶rÃ¼n ÅŸekli nedir?  \n",
        "  (*BazÄ± iÅŸlemler belirli ÅŸekil kurallarÄ±nÄ± gerektirir.*)  \n",
        "- **`dtype`** â†’ TensÃ¶rdeki elemanlar hangi veri tÃ¼rÃ¼nde saklanÄ±yor?  \n",
        "- **`device`** â†’ TensÃ¶r hangi cihazda saklanÄ±yor? (**CPU** veya **GPU**)\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "bbyrWAvamR_W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ğŸ”¢ 3x4 boyutunda rastgele bir tensÃ¶r oluÅŸturma\n",
        "some_tensor = torch.rand(3, 4)\n",
        "\n",
        "# â„¹ï¸ TensÃ¶rÃ¼n detaylarÄ±nÄ± yazdÄ±rma\n",
        "print(\"TensÃ¶r:\\n\", some_tensor)\n",
        "print(f\"TensÃ¶rÃ¼n Åekli (Shape): {some_tensor.shape}\")\n",
        "print(f\"TensÃ¶rÃ¼n Veri Tipi (Datatype): {some_tensor.dtype}\")\n",
        "print(f\"TensÃ¶rÃ¼n CihazÄ± (Device): {some_tensor.device}\")  # VarsayÄ±lan olarak CPU'da tutulur\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZW0lYl99mSrm",
        "outputId": "4a4f273a-df91-4a2d-a359-f536f2501a96"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensÃ¶r:\n",
            " tensor([[0.5015, 0.4369, 0.7028, 0.7865],\n",
            "        [0.5677, 0.8335, 0.6876, 0.7213],\n",
            "        [0.3433, 0.5446, 0.4910, 0.2284]])\n",
            "TensÃ¶rÃ¼n Åekli (Shape): torch.Size([3, 4])\n",
            "TensÃ¶rÃ¼n Veri Tipi (Datatype): torch.float32\n",
            "TensÃ¶rÃ¼n CihazÄ± (Device): cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> **ğŸ“Œ Not:**  \n",
        "> PyTorch'ta karÅŸÄ±laÅŸtÄ±ÄŸÄ±nÄ±z hatalarÄ±n Ã§oÄŸu genellikle yukarÄ±da bahsedilen **Ã¼Ã§ temel Ã¶zellikten** biriyle ilgilidir:  \n",
        "> - **Åekil (Shape)**  \n",
        "> - **Veri Tipi (Datatype)**  \n",
        "> - **Cihaz (Device)**  \n",
        ">\n",
        "> â— Hata mesajlarÄ± aldÄ±ÄŸÄ±nÄ±zda, kendinize ÅŸu kÃ¼Ã§Ã¼k ÅŸarkÄ±yÄ± sÃ¶yleyin:  \n",
        ">\n",
        "> ğŸµ *\"TensÃ¶rlerimin ÅŸekli ne? Veri tipi ne ve nerede saklanÄ±yorlar?  \n",
        "> Åekil ne, veri tipi ne, nerede nerede nerede?\"* ğŸµ  \n",
        ">\n",
        "> Bu Ã¼Ã§ soruyu kendinize sorarak sorunun kaynaÄŸÄ±nÄ± hÄ±zlÄ±ca bulabilirsiniz! ğŸ”\n"
      ],
      "metadata": {
        "id": "zTfOogXHmptT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ğŸ”„ TensÃ¶rleri ManipÃ¼le Etme (TensÃ¶r OperasyonlarÄ±)\n",
        "\n",
        "Derin Ã¶ÄŸrenmede; **gÃ¶rseller**, **metinler**, **videolar**, **sesler**, hatta **protein yapÄ±larÄ±** gibi veriler tensÃ¶rler aracÄ±lÄ±ÄŸÄ±yla temsil edilir.\n",
        "\n",
        "ğŸ“š **Model nasÄ±l Ã¶ÄŸrenir?**  \n",
        "Bir model, bu tensÃ¶rler Ã¼zerinde milyonlarca iÅŸlem yaparak verilerdeki kalÄ±plarÄ± ve iliÅŸkileri Ã¶ÄŸrenir.  \n",
        "Bu iÅŸlemler, modelin girdileri daha iyi temsil etmesine yardÄ±mcÄ± olur.\n",
        "\n",
        "---\n",
        "\n",
        "### ğŸ¯ **Temel TensÃ¶r Ä°ÅŸlemleri**\n",
        "\n",
        "Derin Ã¶ÄŸrenmede kullanÄ±lan iÅŸlemler genellikle ÅŸu temel matematiksel iÅŸlemler etrafÄ±nda dÃ¶ner:\n",
        "\n",
        "- â• **Toplama (Addition)**  \n",
        "- â– **Ã‡Ä±karma (Subtraction)**  \n",
        "- âœ–ï¸ **Ã‡arpma (Element-wise Multiplication)**  \n",
        "- â— **BÃ¶lme (Division)**  \n",
        "- ğŸŸ° **Matris Ã‡arpÄ±mÄ± (Matrix Multiplication)**\n",
        "\n",
        "ğŸ”‘ **Not:**  \n",
        "Bu iÅŸlemler sinir aÄŸlarÄ±nÄ±n temel yapÄ± taÅŸlarÄ±nÄ± oluÅŸturur.  \n",
        "Bu yapÄ± taÅŸlarÄ±nÄ± doÄŸru ÅŸekilde birleÅŸtirerek, **lego parÃ§alarÄ± gibi** en karmaÅŸÄ±k sinir aÄŸlarÄ±nÄ± oluÅŸturabilirsiniz! ğŸ§©\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "GmgthCbYnkYO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### â• â– âœ–ï¸ **Temel TensÃ¶r Ä°ÅŸlemleri (Basic Operations)**\n",
        "\n",
        "Åimdi, en temel matematiksel iÅŸlemler olan **toplama (`+`)**, **Ã§Ä±karma (`-`)** ve **Ã§arpma (`*`)** iÅŸlemlerine bakalÄ±m.  \n",
        "Bu iÅŸlemler, PyTorch'ta da tÄ±pkÄ± matematikte olduÄŸu gibi Ã§alÄ±ÅŸÄ±r.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "YOjjRU3unvPJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ğŸ”¢ TensÃ¶r oluÅŸturma\n",
        "tensor = torch.tensor([1, 2, 3])\n",
        "\n",
        "# â• TensÃ¶re 10 ekleme (eleman bazlÄ±)\n",
        "tensor + 10"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zY5hHpqEnz4T",
        "outputId": "233052a2-3e90-49f4-963e-3e832ae920a1"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([11, 12, 13])"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# âœ–ï¸ TensÃ¶rÃ¼ 10 ile Ã§arpma (eleman bazlÄ±)\n",
        "tensor * 10"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F-1Kgg4rnv7S",
        "outputId": "7df6fa78-f21f-456f-d554-a3c8cd5222b4"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([10, 20, 30])"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ğŸ“Œ **Dikkat:**  \n",
        "YukarÄ±daki tensÃ¶r deÄŸerlerinin **`tensor([110, 120, 130])`** olmadÄ±ÄŸÄ±nÄ± fark ettiniz mi?  \n",
        "Bunun nedeni, tensÃ¶rÃ¼n iÃ§indeki deÄŸerlerin **yeniden atanmadÄ±kÃ§a deÄŸiÅŸmemesidir**.\n"
      ],
      "metadata": {
        "id": "bViynErXoj7W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TensÃ¶rler yeniden atanmadÄ±kÃ§a deÄŸiÅŸmez\n",
        "tensor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aner-aWwnnKV",
        "outputId": "b244233a-7667-4eb7-8949-51c3b0f124a0"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 2, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### â– Bir SayÄ± Ã‡Ä±karalÄ±m ve Bu Sefer `tensor` DeÄŸiÅŸkenini Yeniden AtayalÄ±m.\n"
      ],
      "metadata": {
        "id": "kNs1MShwo48c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ã‡Ä±karma iÅŸlemi ve yeniden atama\n",
        "tensor = tensor - 10\n",
        "\n",
        "# GÃ¼ncellenmiÅŸ tensÃ¶rÃ¼ yazdÄ±rma\n",
        "print(tensor)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JWFcoNPno6KK",
        "outputId": "bb54b7cc-6721-4646-8535-32c6be27e6c1"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([-9, -8, -7])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Toplama iÅŸlemi ve yeniden atama\n",
        "tensor = tensor + 10\n",
        "\n",
        "# GÃ¼ncellenmiÅŸ tensÃ¶rÃ¼ yazdÄ±rma\n",
        "print(tensor)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BuIVGv9_mE7u",
        "outputId": "5a5a3ece-6817-4a39-eb4c-584b8842a02e"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1, 2, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "markdown\n",
        "Kodu kopyala\n",
        "### ğŸ› ï¸ **PyTorch'un YerleÅŸik FonksiyonlarÄ±**\n",
        "\n",
        "PyTorch, temel iÅŸlemleri gerÃ§ekleÅŸtirmek iÃ§in birÃ§ok **yerleÅŸik (built-in)** fonksiyon sunar.  \n",
        "Bu fonksiyonlar, tensÃ¶rler Ã¼zerinde hÄ±zlÄ± ve etkili bir ÅŸekilde iÅŸlem yapmayÄ± saÄŸlar.\n",
        "\n",
        "---\n",
        "\n",
        "### ğŸ”¢ **Temel YerleÅŸik Fonksiyonlar**\n",
        "\n",
        "- **`torch.add()`** â†’ **Toplama** iÅŸlemi yapar.  \n",
        "- **`torch.sub()`** â†’ **Ã‡Ä±karma** iÅŸlemi yapar.  \n",
        "- **`torch.mul()`** â†’ **Ã‡arpma** iÅŸlemi yapar.  \n",
        "- **`torch.div()`** â†’ **BÃ¶lme** iÅŸlemi yapar.  \n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "KvuSDE7TprLl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# PyTorch fonksiyonlarÄ±nÄ± da kullanabilirsiniz\n",
        "torch.multiply(tensor, 10)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dD1q0G25pq00",
        "outputId": "0acbfb58-a049-4370-f81e-0834e157c7f3"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([10, 20, 30])"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Orijinal tensÃ¶r hÃ¢lÃ¢ deÄŸiÅŸmedi\n",
        "tensor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tOtVT5j4p-7p",
        "outputId": "ca42a6bf-7762-4963-cc7a-69ae67c74099"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 2, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ancak, `torch.mul()` yerine `*` gibi operatÃ¶r sembollerini kullanmak daha yaygÄ±ndÄ±r.\n"
      ],
      "metadata": {
        "id": "YHVL2nAJqQE0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ğŸ”¢ Eleman BazlÄ± Ã‡arpma (Her eleman aynÄ± indeksdeki elemanla Ã§arpÄ±lÄ±r: 0->0, 1->1, 2->2)\n",
        "print(tensor, \"*\", tensor)\n",
        "print(\"SonuÃ§:\", tensor * tensor)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LchV9GuxqQ18",
        "outputId": "7df2f52b-34b0-46ae-fa68-c0190b8e6bab"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1, 2, 3]) * tensor([1, 2, 3])\n",
            "SonuÃ§: tensor([1, 4, 9])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ğŸŸ° **Matris Ã‡arpÄ±mÄ± (Matrix Multiplication)**\n",
        "\n",
        "Makine Ã¶ÄŸrenimi ve derin Ã¶ÄŸrenme algoritmalarÄ±nda (Ã¶zellikle **sinir aÄŸlarÄ±nda**) en yaygÄ±n kullanÄ±lan iÅŸlemlerden biri **matris Ã§arpÄ±mÄ±dÄ±r**.  \n",
        "PyTorch, matris Ã§arpÄ±mÄ± iÅŸlemini **[`torch.matmul()`](https://pytorch.org/docs/stable/generated/torch.matmul.html)** fonksiyonuyla gerÃ§ekleÅŸtirir.\n",
        "\n",
        "---\n",
        "\n",
        "### ğŸ“ **Matris Ã‡arpÄ±mÄ± iÃ§in Temel Kurallar**\n",
        "\n",
        "1. **Ä°Ã§ Boyutlar UyuÅŸmalÄ± (Inner Dimensions Must Match):**  \n",
        "   - `(3, 2) @ (3, 2)` âŒ **Uyumsuz**  \n",
        "   - `(2, 3) @ (3, 2)` âœ… **Uyumlu**  \n",
        "   - `(3, 2) @ (2, 3)` âœ… **Uyumlu**\n",
        "\n",
        "2. **Ã‡Ä±ktÄ±nÄ±n Boyutu DÄ±ÅŸ Boyutlardan Gelir (Resulting Shape = Outer Dimensions):**  \n",
        "   - `(2, 3) @ (3, 2)` â†’ **`(2, 2)`**  \n",
        "   - `(3, 2) @ (2, 3)` â†’ **`(3, 3)`**\n",
        "\n",
        "> **ğŸ“Œ Not:**  \n",
        "> Python'da **`@`** operatÃ¶rÃ¼, **matris Ã§arpÄ±mÄ±** iÃ§in kullanÄ±lÄ±r.\n",
        "\n",
        "> **ğŸ“š Kaynak:**  \n",
        "> TÃ¼m matris Ã§arpÄ±mÄ± kurallarÄ±nÄ± gÃ¶rmek iÃ§in [PyTorch dokÃ¼mantasyonuna](https://pytorch.org/docs/stable/generated/torch.matmul.html) gÃ¶z atabilirsiniz.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "EPFpO80bqiDl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "tensor = torch.tensor([1, 2, 3])\n",
        "tensor.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qtl3wk1jqjfr",
        "outputId": "43a17123-f7e5-4707-b87e-f083d03e0df6"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3])"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ğŸ” **Eleman BazlÄ± Ã‡arpma ile Matris Ã‡arpÄ±mÄ± ArasÄ±ndaki Fark**\n",
        "\n",
        "**Eleman bazlÄ± Ã§arpma (element-wise multiplication)** ve **matris Ã§arpÄ±mÄ± (matrix multiplication)** arasÄ±ndaki temel fark, **toplama iÅŸleminin** varlÄ±ÄŸÄ±dÄ±r.\n",
        "\n",
        "**`tensor`** deÄŸiÅŸkenimiz **`[1, 2, 3]`** deÄŸerlerine sahiptir.\n",
        "\n",
        "| **Ä°ÅŸlem**                       | **Hesaplama**                   | **Kod**                    |\n",
        "|---------------------------------|--------------------------------|---------------------------|\n",
        "| **â— Eleman BazlÄ± Ã‡arpma**      | `[1*1, 2*2, 3*3]` â†’ `[1, 4, 9]` | `tensor * tensor`         |\n",
        "| **ğŸŸ° Matris Ã‡arpÄ±mÄ±**           | `1*1 + 2*2 + 3*3` â†’ `[14]`      | `tensor.matmul(tensor)`   |\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "IkVJdXydqwUc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# â— Eleman BazlÄ± Ã‡arpma (Element-wise Multiplication)\n",
        "tensor * tensor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GW85IddGqxS1",
        "outputId": "e8142024-dfe9-44bb-b1e9-64d6ca65b72a"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 4, 9])"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#matris Ã§arpÄ±mÄ± (matrix multiplication)\n",
        "torch.matmul(tensor, tensor)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "32l6g82qq7I8",
        "outputId": "c42d7071-43c0-44a7-d02c-23ec2506875e"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(14)"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Matris Ã§arpÄ±mÄ± iÃ§in \"@\" sembolÃ¼ de kullanÄ±labilir, ancak Ã¶nerilmez.\n",
        "tensor @ tensor\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7_3rWam8rGvj",
        "outputId": "45ec6d4e-5be1-4acc-c7e1-f954241ee503"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(14)"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Elle matris Ã§arpÄ±mÄ± yapabilirsiniz ancak bu Ã¶nerilmez.\n",
        "\n",
        "YerleÅŸik **`torch.matmul()`** yÃ¶ntemi Ã§ok daha hÄ±zlÄ±dÄ±r.\n"
      ],
      "metadata": {
        "id": "EADDMNLXrK6H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "# ğŸŸ° Elle Matris Ã‡arpÄ±mÄ± (Manuel Hesaplama)\n",
        "# â— For dÃ¶ngÃ¼leriyle iÅŸlem yapmaktan kaÃ§Ä±nÄ±n, Ã§Ã¼nkÃ¼ hesaplama maliyeti yÃ¼ksektir!\n",
        "\n",
        "value = 0\n",
        "for i in range(len(tensor)):\n",
        "    value += tensor[i] * tensor[i]\n",
        "\n",
        "# Sonucu yazdÄ±rma\n",
        "value"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4udTBTTLrLxk",
        "outputId": "bd5a63f5-6eb9-443f-f59d-f62a99624cec"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 3.22 ms, sys: 1.74 ms, total: 4.96 ms\n",
            "Wall time: 15.7 ms\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(14)"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "# ğŸŸ° Matris Ã‡arpÄ±mÄ± - PyTorch YerleÅŸik Fonksiyonu ile\n",
        "torch.matmul(tensor, tensor)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vt0gZJWwrZZR",
        "outputId": "e5a7d75c-9aa8-4011-ae2c-fe4d8da572b5"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 100 Âµs, sys: 0 ns, total: 100 Âµs\n",
            "Wall time: 105 Âµs\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(14)"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Derin Ã–ÄŸrenmede En YaygÄ±n Hatalardan Biri (Åekil HatalarÄ±)\n",
        "\n",
        "Derin Ã¶ÄŸrenmede yapÄ±lan iÅŸlemlerin Ã§oÄŸu matrislerin Ã§arpÄ±lmasÄ± ve Ã¼zerinde Ã§eÅŸitli iÅŸlemler yapÄ±lmasÄ±dÄ±r.  \n",
        "Matrisler, hangi ÅŸekil ve boyutlarda birleÅŸtirilebileceÄŸi konusunda katÄ± kurallara sahiptir.  \n",
        "Bu nedenle, derin Ã¶ÄŸrenmede en sÄ±k karÅŸÄ±laÅŸÄ±lan hatalardan biri **ÅŸekil uyumsuzluklarÄ±dÄ±r (shape mismatches)**.\n",
        "### ğŸ“ **Matris Ã‡arpÄ±mÄ± KurallarÄ±**\n",
        "\n",
        "1. **Ä°Ã§ BoyutlarÄ±n UyuÅŸmasÄ± Gerekir (Inner Dimensions Must Match):**  \n",
        "   - `(3, 2) @ (3, 2)` âŒ **Uyumsuz**  \n",
        "   - `(2, 3) @ (3, 2)` âœ… **Uyumlu**\n",
        "\n",
        "2. **Ã‡Ä±ktÄ± Matrisinin Åekli DÄ±ÅŸ Boyutlardan Gelir:**  \n",
        "   - `(2, 3) @ (3, 2)` â†’ **`(2, 2)`**  \n",
        "   - `(3, 2) @ (2, 3)` â†’ **`(3, 3)`**\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "m-miMQuorZIx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ğŸ”¢ Ä°ki tensÃ¶r oluÅŸturuluyor\n",
        "tensor_A = torch.tensor([[1, 2],\n",
        "                         [3, 4],\n",
        "                         [5, 6]], dtype=torch.float32)\n",
        "\n",
        "tensor_B = torch.tensor([[7, 10],\n",
        "                         [8, 11],\n",
        "                         [9, 12]], dtype=torch.float32)\n",
        "\n",
        "# ğŸŸ° Matris Ã§arpÄ±mÄ± (Bu iÅŸlem hata verecek!)\n",
        "torch.matmul(tensor_A, tensor_B)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "id": "4TpXvTlCr5OC",
        "outputId": "03990849-e12b-44cf-a700-e97d3aa9f8c0"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "mat1 and mat2 shapes cannot be multiplied (3x2 and 3x2)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-37-6839c54cdfcb>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# ğŸŸ° Matris Ã§arpÄ±mÄ± (Bu iÅŸlem hata verecek!)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor_A\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_B\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (3x2 and 3x2)"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ğŸŸ° **Matris Ã‡arpÄ±mÄ±nÄ± Uyumlu Hale Getirme (Transpose ile)**\n",
        "\n",
        "**`tensor_A`** ve **`tensor_B`** arasÄ±nda matris Ã§arpÄ±mÄ±nÄ± gerÃ§ekleÅŸtirebilmek iÃ§in, **iÃ§ boyutlarÄ±n (inner dimensions)** uyumlu olmasÄ± gerekir.\n",
        "\n",
        "### ğŸ”„ **Bu Uyumu SaÄŸlamanÄ±n YollarÄ±ndan Biri: Transpoz (Transpose)**\n",
        "\n",
        "**Transpoz**, bir tensÃ¶rÃ¼n **satÄ±r ve sÃ¼tunlarÄ±nÄ±** yer deÄŸiÅŸtirerek boyutlarÄ±nÄ± Ã§evirir.\n",
        "\n",
        "### ğŸ”§ **PyTorch'ta Transpoz NasÄ±l YapÄ±lÄ±r?**\n",
        "\n",
        "1. **`torch.transpose(input, dim0, dim1)`**  \n",
        "   - `input`: Transpoz yapÄ±lacak tensÃ¶r.  \n",
        "   - `dim0` ve `dim1`: Yer deÄŸiÅŸtirecek boyutlar.\n",
        "\n",
        "2. **`tensor.T`**  \n",
        "   - Daha kÄ±sa ve pratik bir yÃ¶ntemdir.  \n",
        "   - TensÃ¶rÃ¼n boyutlarÄ±nÄ± otomatik olarak yer deÄŸiÅŸtirir.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "HLvuJjqRrS_c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# tensor_A ve tensor_B'yi gÃ¶rÃ¼ntÃ¼le\n",
        "print(tensor_A)\n",
        "print(tensor_B)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WoTIHTeQsXMp",
        "outputId": "1c2a59a9-194f-4c44-faba-f4bcbda54643"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 2.],\n",
            "        [3., 4.],\n",
            "        [5., 6.]])\n",
            "tensor([[ 7., 10.],\n",
            "        [ 8., 11.],\n",
            "        [ 9., 12.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# tensor_A ve tensor_B.T'yi gÃ¶rÃ¼ntÃ¼le\n",
        "print(tensor_A)\n",
        "print(tensor_B.T)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a3tbwyIKsb8T",
        "outputId": "77f0e817-bb09-4bd7-ca45-3e62831aeb4e"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 2.],\n",
            "        [3., 4.],\n",
            "        [5., 6.]])\n",
            "tensor([[ 7.,  8.,  9.],\n",
            "        [10., 11., 12.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# tensor_B transpozu alÄ±ndÄ±ÄŸÄ±nda iÅŸlem Ã§alÄ±ÅŸÄ±r\n",
        "print(f\"Original shapes: tensor_A = {tensor_A.shape}, tensor_B = {tensor_B.shape}\\n\")\n",
        "print(f\"New shapes: tensor_A = {tensor_A.shape} (same as above), tensor_B.T = {tensor_B.T.shape}\\n\")\n",
        "print(f\"Multiplying: {tensor_A.shape} * {tensor_B.T.shape} <- inner dimensions match\\n\")\n",
        "print(\"Output:\\n\")\n",
        "\n",
        "# Matris Ã§arpÄ±mÄ±nÄ± yap\n",
        "output = torch.matmul(tensor_A, tensor_B.T)\n",
        "print(output)\n",
        "print(f\"\\nOutput shape: {output.shape}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "upDoZfRrsirc",
        "outputId": "7065b11a-6f6a-46fa-816b-63a15dc7f80f"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original shapes: tensor_A = torch.Size([3, 2]), tensor_B = torch.Size([3, 2])\n",
            "\n",
            "New shapes: tensor_A = torch.Size([3, 2]) (same as above), tensor_B.T = torch.Size([2, 3])\n",
            "\n",
            "Multiplying: torch.Size([3, 2]) * torch.Size([2, 3]) <- inner dimensions match\n",
            "\n",
            "Output:\n",
            "\n",
            "tensor([[ 27.,  30.,  33.],\n",
            "        [ 61.,  68.,  75.],\n",
            "        [ 95., 106., 117.]])\n",
            "\n",
            "Output shape: torch.Size([3, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ğŸ› ï¸ **`torch.mm()` KullanÄ±mÄ±**\n",
        "\n",
        "**`torch.mm()`** fonksiyonu, **`torch.matmul()`** fonksiyonunun kÄ±saltmasÄ±dÄ±r.  \n",
        "Her ikisi de **matris Ã§arpÄ±mÄ±** iÃ§in kullanÄ±lÄ±r ve aynÄ± iÅŸlevi yerine getirir.\n"
      ],
      "metadata": {
        "id": "5TGWnw0IsqM2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# torch.mm, matmul iÃ§in bir kÄ±saltmadÄ±r\n",
        "torch.mm(tensor_A, tensor_B.T)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "57DvtpxNsrlw",
        "outputId": "6cb3f238-ea76-4479-a21e-a35307a50f84"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 27.,  30.,  33.],\n",
              "        [ 61.,  68.,  75.],\n",
              "        [ 95., 106., 117.]])"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Åekil transpozunu almadan matris Ã§arpÄ±mÄ± yapmaya Ã§alÄ±ÅŸtÄ±ÄŸÄ±mÄ±zda, matris Ã§arpÄ±mÄ±nÄ±n kurallarÄ± yerine getirilmez ve yukarÄ±daki gibi bir hata alÄ±rÄ±z.\n",
        "\n",
        "Peki ya gÃ¶rsel bir Ã¶rnek?\n",
        "\n",
        "![Matris Ã‡arpÄ±mÄ±nÄ±n GÃ¶rsel GÃ¶sterimi](https://github.com/mrdbourke/pytorch-deep-learning/raw/main/images/00-matrix-multiply-crop.gif)\n",
        "\n",
        "Bu tÃ¼r matris Ã§arpÄ±mÄ± gÃ¶rsellerini **[matrixmultiplication.xyz](http://matrixmultiplication.xyz/)** adresinde kendiniz oluÅŸturabilirsiniz.\n",
        "\n",
        "> **Not:**  \n",
        "> BÃ¶yle bir matris Ã§arpÄ±mÄ±, aynÄ± zamanda [**dot product** (nokta Ã§arpÄ±mÄ±)](https://www.mathsisfun.com/algebra/vectors-dot-product.html) olarak da adlandÄ±rÄ±lÄ±r.\n"
      ],
      "metadata": {
        "id": "VfaQf7fSsbrn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sinir aÄŸlarÄ±, matris Ã§arpÄ±mlarÄ± ve nokta Ã§arpÄ±mlarÄ±yla doludur.\n",
        "\n",
        "**`torch.nn.Linear()`** modÃ¼lÃ¼ (bunu ilerleyen bÃ¶lÃ¼mlerde gÃ¶receÄŸiz), aynÄ± zamanda **feed-forward layer** veya **tam baÄŸlantÄ±lÄ± katman** olarak bilinir, bir giriÅŸ **`x`** ve aÄŸÄ±rlÄ±klar matris **`A`** arasÄ±nda matris Ã§arpÄ±mÄ± gerÃ§ekleÅŸtirir.\n",
        "\n",
        "$$\n",
        "y = x\\cdot{A^T} + b\n",
        "$$\n",
        "\n",
        "### Nerede:\n",
        "- **`x`** katmana verilen giriÅŸtir (derin Ã¶ÄŸrenme, `torch.nn.Linear()` gibi katmanlarÄ±n Ã¼st Ã¼ste konmasÄ±yla oluÅŸur).\n",
        "- **`A`** katman tarafÄ±ndan oluÅŸturulan aÄŸÄ±rlÄ±klar matrisidir, bu baÅŸlangÄ±Ã§ta rastgele sayÄ±larla baÅŸlar ve sinir aÄŸÄ±, verilerdeki kalÄ±plarÄ± daha iyi temsil etmeyi Ã¶ÄŸrenirken bu sayÄ±lar ayarlanÄ±r (not edin, \"`T`\" burada aÄŸÄ±rlÄ±klar matrisinin transpoz edildiÄŸini gÃ¶sterir).\n",
        "  - **Not:** AÄŸÄ±rlÄ±klar matrisini **`W`** veya **`X`** gibi baÅŸka harflerle de gÃ¶rebilirsiniz.\n",
        "- **`b`** aÄŸÄ±rlÄ±klar ve giriÅŸler arasÄ±nda kÃ¼Ã§Ã¼k bir kayma yaratmak iÃ§in kullanÄ±lan bias terimidir.\n",
        "- **`y`** Ã§Ä±kÄ±ÅŸtÄ±r (giriÅŸin bir manipÃ¼lasyonu, amacÄ± iÃ§erisindeki kalÄ±plarÄ± keÅŸfetmektir).\n",
        "\n",
        "Bu bir doÄŸrusal fonksiyondur (belki lise veya baÅŸka bir yerde **`y = mx+b`** gibi bir ÅŸey gÃ¶rmÃ¼ÅŸsÃ¼nÃ¼zdÃ¼r) ve doÄŸrusal bir Ã§izgi Ã§izmeyi saÄŸlar!\n",
        "\n",
        "Åimdi bir doÄŸrusal katmanla oynayalÄ±m.\n",
        "\n",
        "AÅŸaÄŸÄ±daki **`in_features`** ve **`out_features`** deÄŸerlerini deÄŸiÅŸtirin ve ne olduÄŸunu gÃ¶rÃ¼n.\n",
        "\n",
        "**Åekillerle** ilgili bir ÅŸey fark ediyor musunuz?\n"
      ],
      "metadata": {
        "id": "zCPC4Kf1tCGL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ğŸ”¢ Rasgele aÄŸÄ±rlÄ±klar matrisinin tekrarlanabilir olmasÄ±nÄ± saÄŸlamak iÃ§in manuel tohum belirleme\n",
        "torch.manual_seed(42)\n",
        "\n",
        "# ğŸŸ° DoÄŸrusal katmanÄ± oluÅŸturma\n",
        "linear = torch.nn.Linear(in_features=2,  # in_features = giriÅŸin iÃ§ boyutuyla uyumlu\n",
        "                         out_features=6)  # out_features = dÄ±ÅŸ boyutunu tanÄ±mlar\n",
        "\n",
        "# ğŸ§‘â€ğŸ’» GiriÅŸ tensÃ¶rÃ¼nÃ¼ tanÄ±mlama\n",
        "x = tensor_A\n",
        "\n",
        "# ğŸ”„ Ã‡Ä±kÄ±ÅŸÄ± hesaplama\n",
        "output = linear(x)\n",
        "\n",
        "# SonuÃ§larÄ± yazdÄ±rma\n",
        "print(f\"GiriÅŸ ÅŸekli: {x.shape}\\n\")\n",
        "print(f\"Ã‡Ä±ktÄ±:\\n{output}\\n\\nÃ‡Ä±ktÄ± ÅŸekli: {output.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Q3ZnTQRs_rm",
        "outputId": "e7edff87-abaa-4d52-cd5a-53766412b7c5"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GiriÅŸ ÅŸekli: torch.Size([3, 2])\n",
            "\n",
            "Ã‡Ä±ktÄ±:\n",
            "tensor([[2.2368, 1.2292, 0.4714, 0.3864, 0.1309, 0.9838],\n",
            "        [4.4919, 2.1970, 0.4469, 0.5285, 0.3401, 2.4777],\n",
            "        [6.7469, 3.1648, 0.4224, 0.6705, 0.5493, 3.9716]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "\n",
            "Ã‡Ä±ktÄ± ÅŸekli: torch.Size([3, 6])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> **Soru:**  \n",
        "> YukarÄ±daki Ã¶rnekte **`in_features`** deÄŸerini **2**'den **3**'e deÄŸiÅŸtirirseniz ne olur? Hata alÄ±r mÄ±sÄ±nÄ±z? GiriÅŸin (**`x`**) ÅŸeklinin hatayÄ± karÅŸÄ±layabilmesi iÃ§in nasÄ±l deÄŸiÅŸtirilebilir? Ä°pucu: Daha Ã¶nce **`tensor_B`**'yi ne yapmak zorunda kaldÄ±k?\n"
      ],
      "metadata": {
        "id": "-eSn9Pj9ti3x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "EÄŸer daha Ã¶nce yapmadÄ±ysanÄ±z, matris Ã§arpÄ±mÄ± baÅŸlangÄ±Ã§ta kafa karÄ±ÅŸtÄ±rÄ±cÄ± bir konu olabilir.\n",
        "\n",
        "Ancak bir kaÃ§ kez denedikten ve birkaÃ§ sinir aÄŸÄ±na gÃ¶z attÄ±ktan sonra, her yerde olduÄŸunu fark edeceksiniz.\n",
        "\n",
        "UnutmayÄ±n, matris Ã§arpÄ±mÄ± **hemen her ÅŸey** iÃ§in gereklidir.\n",
        "\n",
        "![matrix multiplication is all you need](https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/images/00_matrix_multiplication_is_all_you_need.jpeg)\n",
        "\n",
        "*Sinir aÄŸÄ± katmanlarÄ±na girmeye ve kendi katmanlarÄ±nÄ±zÄ± inÅŸa etmeye baÅŸladÄ±ÄŸÄ±nÄ±zda, matris Ã§arpÄ±mlarÄ±nÄ±n her yerde olduÄŸunu gÃ¶receksiniz. **Kaynak:** https://marksaroufim.substack.com/p/working-class-deep-learner*\n"
      ],
      "metadata": {
        "id": "c3SB56yPtkfx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Min, max, mean, sum gibi iÅŸlemlerle toplama (aggregation)\n",
        "\n",
        "Åimdi tensÃ¶rleri nasÄ±l manipÃ¼le edebileceÄŸimizi gÃ¶rdÃ¼k, ÅŸimdi de bunlarÄ± **toplayarak** (daha fazla deÄŸerden daha az deÄŸere) nasÄ±l iÅŸlem yapabileceÄŸimizi gÃ¶relim.\n",
        "\n",
        "Ã–nce bir tensÃ¶r oluÅŸturacaÄŸÄ±z ve ardÄ±ndan bu tensÃ¶rÃ¼n **max**, **min**, **mean** ve **sum** gibi deÄŸerlerini bulacaÄŸÄ±z.\n",
        "\n"
      ],
      "metadata": {
        "id": "zb7i2MHxtwt4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ğŸ”¢ Bir tensÃ¶r oluÅŸturma\n",
        "x = torch.arange(0, 100, 10)\n",
        "print(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lSE8auantx2q",
        "outputId": "26a6b919-6302-4b8b-9e0b-466458c71ec1"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 0, 10, 20, 30, 40, 50, 60, 70, 80, 90])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's perform some aggregation."
      ],
      "metadata": {
        "id": "P4zW97oSt8ct"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Minimum deÄŸeri yazdÄ±rma\n",
        "print(f\"Minimum: {x.min()}\")\n",
        "\n",
        "# Maksimum deÄŸeri yazdÄ±rma\n",
        "print(f\"Maximum: {x.max()}\")\n",
        "\n",
        "# OrtalamayÄ± yazdÄ±rma (Hata alÄ±r Ã§Ã¼nkÃ¼ integer tensÃ¶rde mean kullanÄ±lamaz)\n",
        "# print(f\"Mean: {x.mean()}\") # Bu hata verir\n",
        "\n",
        "# OrtalamayÄ± doÄŸru ÅŸekilde yazdÄ±rma (float32 veri tipi ile)\n",
        "print(f\"Mean: {x.type(torch.float32).mean()}\") # float32 veri tipi ile Ã§alÄ±ÅŸÄ±r\n",
        "\n",
        "# Toplam deÄŸeri yazdÄ±rma\n",
        "print(f\"Sum: {x.sum()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i3EmMTbst9C1",
        "outputId": "74988e27-c82f-48db-f52c-1f0660e4ad14"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Minimum: 0\n",
            "Maximum: 90\n",
            "Mean: 45.0\n",
            "Sum: 450\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> **Not:**  \n",
        "> BazÄ± yÃ¶ntemlerin, Ã¶rneÄŸin **`torch.mean()`**, tensÃ¶rlerin **`torch.float32`** (en yaygÄ±n) veya baÅŸka bir Ã¶zel veri tipinde olmasÄ±nÄ± gerektirdiÄŸini gÃ¶rebilirsiniz, aksi takdirde iÅŸlem baÅŸarÄ±sÄ±z olur.\n",
        "\n",
        "AÅŸaÄŸÄ±da yapmÄ±ÅŸ olduÄŸumuz iÅŸlemi **`torch`** yÃ¶ntemleriyle de gerÃ§ekleÅŸtirebilirsiniz.\n"
      ],
      "metadata": {
        "id": "TzqcSufIujOw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.max(x), torch.min(x), torch.mean(x.type(torch.float32)), torch.sum(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZBdB3deKuj4K",
        "outputId": "73881ce9-d592-48b5-ff6f-e0e0e93f6d1e"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(90), tensor(0), tensor(45.), tensor(450))"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Pozisyonel Min/Max**\n",
        "\n",
        "Bir tensÃ¶rde maksimum veya minimum deÄŸerin bulunduÄŸu **indeksi** bulmak iÃ§in sÄ±rasÄ±yla **`torch.argmax()`** ve **`torch.argmin()`** fonksiyonlarÄ±nÄ± kullanabilirsiniz.\n",
        "\n",
        "Bu, **en yÃ¼ksek (veya en dÃ¼ÅŸÃ¼k) deÄŸerin** pozisyonunu bilmek istediÄŸinizde faydalÄ±dÄ±r, ancak **deÄŸerin kendisini** deÄŸil. (Bunu, [softmax aktivasyon fonksiyonunu](https://pytorch.org/docs/stable/generated/torch.nn.Softmax.html) kullandÄ±ÄŸÄ±mÄ±z ilerleyen bÃ¶lÃ¼mlerde gÃ¶receÄŸiz).\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "hUYhsUrCuvn3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ğŸ”¢ TensÃ¶r oluÅŸturma\n",
        "tensor = torch.arange(10, 100, 10)\n",
        "print(f\"TensÃ¶r: {tensor}\")\n",
        "\n",
        "# Maksimum ve minimum deÄŸerlerin indekslerini dÃ¶ndÃ¼rme\n",
        "print(f\"Max deÄŸerin bulunduÄŸu indeks: {tensor.argmax()}\")\n",
        "print(f\"Min deÄŸerin bulunduÄŸu indeks: {tensor.argmin()}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aEcJ39qlu0V3",
        "outputId": "a7c8c498-9aca-4a2c-fdcd-277466a2454c"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensÃ¶r: tensor([10, 20, 30, 40, 50, 60, 70, 80, 90])\n",
            "Max deÄŸerin bulunduÄŸu indeks: 8\n",
            "Min deÄŸerin bulunduÄŸu indeks: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### TensÃ¶r Veri Tipini DeÄŸiÅŸtirme\n",
        "\n",
        "Daha Ã¶nce de belirtildiÄŸi gibi, derin Ã¶ÄŸrenme iÅŸlemlerinde karÅŸÄ±laÅŸÄ±lan yaygÄ±n sorunlardan biri, tensÃ¶rlerin farklÄ± veri tiplerinde olmasÄ±dÄ±r.\n",
        "\n",
        "EÄŸer bir tensÃ¶r **`torch.float64`** tipindeyse ve diÄŸer tensÃ¶r **`torch.float32`** tipindeyse, bazÄ± hatalarla karÅŸÄ±laÅŸabilirsiniz.\n",
        "\n",
        "Ama bunun bir Ã§Ã¶zÃ¼mÃ¼ var.\n",
        "\n",
        "TensÃ¶rlerin veri tiplerini **[`torch.Tensor.type(dtype=None)`](https://pytorch.org/docs/stable/generated/torch.Tensor.type.html)** fonksiyonunu kullanarak deÄŸiÅŸtirebilirsiniz. Burada **`dtype`** parametresi, kullanmak istediÄŸiniz veri tipini belirtir.\n",
        "\n",
        "Ã–nce bir tensÃ¶r oluÅŸturacaÄŸÄ±z ve veri tipini kontrol edeceÄŸiz (varsayÄ±lan olarak **`torch.float32`** olacaktÄ±r).\n"
      ],
      "metadata": {
        "id": "kuxaVo3yvC5x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ğŸ”¢ TensÃ¶r oluÅŸturma ve veri tipini kontrol etme\n",
        "tensor = torch.arange(10., 100., 10.)\n",
        "print(tensor.dtype)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ii-GL0u4vChl",
        "outputId": "a2e4c0a0-34d9-466b-929f-1fb321d3b621"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.float32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Åimdi, Ã¶nceki tensÃ¶rle aynÄ± olan bir tensÃ¶r oluÅŸturacaÄŸÄ±z ancak veri tipini **`torch.float16`** olarak deÄŸiÅŸtireceÄŸiz.\n"
      ],
      "metadata": {
        "id": "gvH5fe_vvOPM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ğŸ”¢ float16 veri tipiyle bir tensÃ¶r oluÅŸturma\n",
        "tensor_float16 = tensor.type(torch.float16)\n",
        "print(tensor_float16)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nTTsfJB4vOv1",
        "outputId": "75c43ba6-3024-4b16-f382-026da9799b05"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([10., 20., 30., 40., 50., 60., 70., 80., 90.], dtype=torch.float16)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ve benzer ÅŸekilde, bir **`torch.int8`** tensÃ¶rÃ¼ oluÅŸturmak iÃ§in aynÄ± iÅŸlemi yapabiliriz.\n"
      ],
      "metadata": {
        "id": "A2xPbEG0vY5j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ğŸ”¢ int8 veri tipiyle bir tensÃ¶r oluÅŸturma\n",
        "tensor_int8 = tensor.type(torch.int8)\n",
        "print(tensor_int8)\n"
      ],
      "metadata": {
        "id": "FhdgZJJwvZvi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "330f4962-0437-4528-f3f5-ff75a1b716a8"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([10, 20, 30, 40, 50, 60, 70, 80, 90], dtype=torch.int8)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> **Not:**  \n",
        "> FarklÄ± veri tipleri baÅŸlangÄ±Ã§ta kafa karÄ±ÅŸtÄ±rÄ±cÄ± olabilir. Ama bunu ÅŸÃ¶yle dÃ¼ÅŸÃ¼nÃ¼n, sayÄ± ne kadar kÃ¼Ã§Ã¼kse (Ã¶rneÄŸin **32**, **16**, **8**), bilgisayar deÄŸeri o kadar az hassasiyetle depolar. Ve daha az depolama ile, bu genellikle daha hÄ±zlÄ± hesaplama ve daha kÃ¼Ã§Ã¼k bir modelle sonuÃ§lanÄ±r. Mobil tabanlÄ± sinir aÄŸlarÄ± genellikle **8-bit tamsayÄ±larla** Ã§alÄ±ÅŸÄ±r; bunlar daha kÃ¼Ã§Ã¼k ve hÄ±zlÄ± Ã§alÄ±ÅŸÄ±r, ancak **float32** karÅŸÄ±lÄ±klarÄ±na gÃ¶re daha az doÄŸruluk saÄŸlar. Bu konuda daha fazla bilgi iÃ§in **[hesaplamadaki hassasiyet](https://en.wikipedia.org/wiki/Precision_(computer_science))** hakkÄ±nda okumayÄ± Ã¶neririm.\n",
        "\n",
        "> **AlÄ±ÅŸtÄ±rma:**  \n",
        "> Åimdiye kadar pek Ã§ok tensÃ¶r metodunu inceledik, ancak [`torch.Tensor` dokÃ¼mantasyonunda](https://pytorch.org/docs/stable/tensors.html) daha pek Ã§ok metod var. 10 dakika ayÄ±rÄ±p bu dokÃ¼mantasyonu gÃ¶zden geÃ§irmenizi Ã¶neririm. Ä°lginizi Ã§ekenleri tÄ±klayÄ±p, ardÄ±ndan kendi kodunuzla yazÄ±p neler olduÄŸunu gÃ¶rmek faydalÄ± olacaktÄ±r.\n"
      ],
      "metadata": {
        "id": "PhcIxnQZvimz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Yeniden Åekillendirme, YÄ±ÄŸÄ±t OluÅŸturma, SÄ±kÄ±ÅŸtÄ±rma ve Unsqueeze\n",
        "\n",
        "Ã‡oÄŸu zaman, tensÃ¶rlerinizin iÃ§indeki deÄŸerleri deÄŸiÅŸtirmeden boyutlarÄ±nÄ± yeniden ÅŸekillendirmek isteyeceksiniz.\n",
        "\n",
        "Bunu yapmak iÃ§in popÃ¼ler yÃ¶ntemler ÅŸunlardÄ±r:\n",
        "\n",
        "| YÃ¶ntem | KÄ±sa aÃ§Ä±klama |\n",
        "| ----- | ----- |\n",
        "| [`torch.reshape(input, shape)`](https://pytorch.org/docs/stable/generated/torch.reshape.html#torch.reshape) | `input`'Ä± `shape`'e yeniden ÅŸekillendirir (uyumluysa), ayrÄ±ca `torch.Tensor.reshape()` de kullanÄ±labilir. |\n",
        "| [`Tensor.view(shape)`](https://pytorch.org/docs/stable/generated/torch.Tensor.view.html) | Orijinal tensÃ¶rÃ¼n aynÄ± verileri paylaÅŸarak farklÄ± bir `shape`'teki gÃ¶rÃ¼nÃ¼mÃ¼nÃ¼ dÃ¶ndÃ¼rÃ¼r. |\n",
        "| [`torch.stack(tensors, dim=0)`](https://pytorch.org/docs/1.9.1/generated/torch.stack.html) | Bir dizi `tensÃ¶r`Ã¼ yeni bir boyut (`dim`) boyunca birleÅŸtirir, tÃ¼m `tensÃ¶rler` aynÄ± boyutta olmalÄ±dÄ±r. |\n",
        "| [`torch.squeeze(input)`](https://pytorch.org/docs/stable/generated/torch.squeeze.html) | `input`'Ä±, deÄŸeri `1` olan tÃ¼m boyutlarÄ± Ã§Ä±kararak sÄ±kÄ±ÅŸtÄ±rÄ±r. |\n",
        "| [`torch.unsqueeze(input, dim)`](https://pytorch.org/docs/1.9.1/generated/torch.unsqueeze.html) | `input`'Ä±, belirtilen `dim` boyutunda `1` deÄŸeri ekleyerek dÃ¶ndÃ¼rÃ¼r. |\n",
        "| [`torch.permute(input, dims)`](https://pytorch.org/docs/stable/generated/torch.permute.html) | Orijinal `input`'Ä±n boyutlarÄ±nÄ± `dims`'e gÃ¶re sÄ±ralayarak dÃ¶ndÃ¼ren *gÃ¶rÃ¼nÃ¼m* saÄŸlar. |\n",
        "\n",
        "### Neden bunlarÄ± yapmalÄ±sÄ±nÄ±z?\n",
        "\n",
        "Ã‡Ã¼nkÃ¼ derin Ã¶ÄŸrenme modelleri (sinir aÄŸlarÄ±), bir ÅŸekilde tensÃ¶rleri manipÃ¼le etmekle ilgilidir. Ve matris Ã§arpÄ±mÄ± kurallarÄ± nedeniyle, ÅŸekil uyuÅŸmazlÄ±klarÄ±nÄ±z varsa, hatalarla karÅŸÄ±laÅŸÄ±rsÄ±nÄ±z. Bu yÃ¶ntemler, tensÃ¶rlerinizin doÄŸru elemanlarÄ±nÄ±n diÄŸer tensÃ¶rlerin doÄŸru elemanlarÄ±yla karÄ±ÅŸmasÄ±nÄ± saÄŸlamaya yardÄ±mcÄ± olur.\n",
        "\n",
        "Åimdi bunlarÄ± deneyelim.\n",
        "\n",
        "Ã–nce bir tensÃ¶r oluÅŸturacaÄŸÄ±z.\n"
      ],
      "metadata": {
        "id": "T6K8WWVmvwBU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TensÃ¶r OluÅŸturma\n",
        "import torch\n",
        "x = torch.arange(1., 8.)\n",
        "x, x.shape\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZBhQT02gvjpf",
        "outputId": "9bf682c7-8ab1-45ac-9e5f-6697f94c6125"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([1., 2., 3., 4., 5., 6., 7.]), torch.Size([7]))"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Åimdi **`torch.reshape()`** ile ekstra bir boyut ekleyelim.\n"
      ],
      "metadata": {
        "id": "BNyV67IOwAaD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ekstra bir boyut ekleme\n",
        "x_reshaped = x.reshape(1, 7)\n",
        "x_reshaped, x_reshaped.shape\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tbBhfHfYwBZ_",
        "outputId": "b8e73e51-ce3c-4a81-f968-ec3ba429e3a0"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[1., 2., 3., 4., 5., 6., 7.]]), torch.Size([1, 7]))"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "AyrÄ±ca gÃ¶rÃ¼nÃ¼mÃ¼ **`torch.view()`** ile deÄŸiÅŸtirebiliriz.\n"
      ],
      "metadata": {
        "id": "ocWzkKMpwSsQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# GÃ¶rÃ¼nÃ¼mÃ¼ deÄŸiÅŸtir (aynÄ± veriyi korur ancak gÃ¶rÃ¼nÃ¼mÃ¼ deÄŸiÅŸtirir)\n",
        "# Daha fazla bilgi: https://stackoverflow.com/a/54507446/7900723\n",
        "z = x.view(1, 7)\n",
        "z, z.shape\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m6PUtz_bwTnv",
        "outputId": "cbeea3d6-4121-4227-b684-046de49fc68f"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[1., 2., 3., 4., 5., 6., 7.]]), torch.Size([1, 7]))"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ancak unutmayÄ±n, **`torch.view()`** ile bir tensÃ¶rÃ¼n gÃ¶rÃ¼nÃ¼mÃ¼nÃ¼ deÄŸiÅŸtirmek, aslÄ±nda **aynÄ±** tensÃ¶rÃ¼n yeni bir gÃ¶rÃ¼nÃ¼mÃ¼nÃ¼ oluÅŸturur.\n",
        "\n",
        "Yani gÃ¶rÃ¼nÃ¼mÃ¼ deÄŸiÅŸtirmek, orijinal tensÃ¶rÃ¼ de deÄŸiÅŸtirir.\n"
      ],
      "metadata": {
        "id": "w2SiGS8rwYlU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# z'yi deÄŸiÅŸtirmek x'i de deÄŸiÅŸtirir\n",
        "z[:, 0] = 5\n",
        "z, x\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vO3W1BmowdrG",
        "outputId": "59387671-8dd9-4a02-cf01-460ca13bae5b"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[5., 2., 3., 4., 5., 6., 7.]]), tensor([5., 2., 3., 4., 5., 6., 7.]))"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "EÄŸer yeni tensÃ¶rÃ¼mÃ¼zÃ¼ kendisinin Ã¼zerine beÅŸ kez yÄ±ÄŸmak istersek, bunu **`torch.stack()`** ile yapabiliriz.\n"
      ],
      "metadata": {
        "id": "Hz8iFuB7wtQn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TensÃ¶rleri Ã¼st Ã¼ste yÄ±ÄŸma\n",
        "x_stacked = torch.stack([x, x, x, x], dim=0) # dim'i dim=1 olarak deÄŸiÅŸtirip ne olduÄŸunu gÃ¶rÃ¼n\n",
        "x_stacked\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k1MQI6Wvwt6E",
        "outputId": "ee3a6957-9e3d-496e-80d2-0674c1f1b796"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[5., 2., 3., 4., 5., 6., 7.],\n",
              "        [5., 2., 3., 4., 5., 6., 7.],\n",
              "        [5., 2., 3., 4., 5., 6., 7.],\n",
              "        [5., 2., 3., 4., 5., 6., 7.]])"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ya bir tensÃ¶rden tÃ¼m tek boyutlarÄ± (single dimensions) kaldÄ±rmak istersek?\n",
        "\n",
        "Bunu yapmak iÃ§in **`torch.squeeze()`** kullanabilirsiniz (ben bunu, tensÃ¶rÃ¼ sadece 1'den bÃ¼yÃ¼k boyutlara sahip olacak ÅŸekilde **sÄ±kÄ±ÅŸtÄ±rmak** olarak hatÄ±rlÄ±yorum).\n"
      ],
      "metadata": {
        "id": "-d41TZh1w9w1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Ã–nceki tensÃ¶r: {x_reshaped}\")\n",
        "print(f\"Ã–nceki ÅŸekil: {x_reshaped.shape}\")\n",
        "\n",
        "# x_reshaped'ten ekstra boyutu kaldÄ±rma\n",
        "x_squeezed = x_reshaped.squeeze()\n",
        "print(f\"\\nYeni tensÃ¶r: {x_squeezed}\")\n",
        "print(f\"Yeni ÅŸekil: {x_squeezed.shape}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OfKb1E75w-Xk",
        "outputId": "a3cceeff-6363-4e46-9265-f2de5c6f735a"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ã–nceki tensÃ¶r: tensor([[5., 2., 3., 4., 5., 6., 7.]])\n",
            "Ã–nceki ÅŸekil: torch.Size([1, 7])\n",
            "\n",
            "Yeni tensÃ¶r: tensor([5., 2., 3., 4., 5., 6., 7.])\n",
            "Yeni ÅŸekil: torch.Size([7])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ve **`torch.squeeze()`**'in tersini yapmak iÃ§in, belirli bir indekste **1** deÄŸeri eklemek iÃ§in **`torch.unsqueeze()`** kullanabilirsiniz.\n"
      ],
      "metadata": {
        "id": "1ZJ25JS2xG-p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Ã–nceki tensÃ¶r: {x_squeezed}\")\n",
        "print(f\"Ã–nceki ÅŸekil: {x_squeezed.shape}\")\n",
        "\n",
        "## unsqueeze ile ekstra bir boyut ekleyin\n",
        "x_unsqueezed = x_squeezed.unsqueeze(dim=0)\n",
        "print(f\"\\nYeni tensÃ¶r: {x_unsqueezed}\")\n",
        "print(f\"Yeni ÅŸekil: {x_unsqueezed.shape}\")\n"
      ],
      "metadata": {
        "id": "qq3LbsW4xHk5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "831315cc-39c9-41f3-c3a7-b4a41f9f8af0"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ã–nceki tensÃ¶r: tensor([5., 2., 3., 4., 5., 6., 7.])\n",
            "Ã–nceki ÅŸekil: torch.Size([7])\n",
            "\n",
            "Yeni tensÃ¶r: tensor([[5., 2., 3., 4., 5., 6., 7.]])\n",
            "Yeni ÅŸekil: torch.Size([1, 7])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "AyrÄ±ca **`torch.permute(input, dims)`** ile eksen deÄŸerlerinin sÄ±rasÄ±nÄ± yeniden dÃ¼zenleyebilirsiniz; burada **`input`**, yeni **`dims`** ile bir *gÃ¶rÃ¼nÃ¼m* haline gelir.\n"
      ],
      "metadata": {
        "id": "IMBoef0axRTk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Belirli bir ÅŸekle sahip tensÃ¶r oluÅŸturma\n",
        "x_original = torch.rand(size=(224, 224, 3))\n",
        "\n",
        "# Orijinal tensÃ¶rÃ¼ eksen sÄ±rasÄ±nÄ± yeniden dÃ¼zenlemek iÃ§in permute etme\n",
        "x_permuted = x_original.permute(2, 0, 1) # eksenleri 0->1, 1->2, 2->0 ÅŸeklinde kaydÄ±rÄ±r\n",
        "\n",
        "print(f\"Ã–nceki ÅŸekil: {x_original.shape}\")\n",
        "print(f\"Yeni ÅŸekil: {x_permuted.shape}\")\n"
      ],
      "metadata": {
        "id": "Zk9WYjFtxSCy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "32c0e549-d4f3-4213-cda7-1df2cd83273e"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ã–nceki ÅŸekil: torch.Size([224, 224, 3])\n",
            "Yeni ÅŸekil: torch.Size([3, 224, 224])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> **Not:**  \n",
        "> Ã‡Ã¼nkÃ¼ **`permute()`** bir *gÃ¶rÃ¼nÃ¼m* dÃ¶ndÃ¼rÃ¼r (orijinal ile aynÄ± veriyi paylaÅŸÄ±r), permÃ¼telenmiÅŸ tensÃ¶rdeki deÄŸerler, orijinal tensÃ¶rle aynÄ± olacaktÄ±r ve eÄŸer gÃ¶rÃ¼nÃ¼mdeki deÄŸerleri deÄŸiÅŸtirirseniz, bu orijinal tensÃ¶rÃ¼n deÄŸerlerini de deÄŸiÅŸtirir.\n"
      ],
      "metadata": {
        "id": "33UNUvajxaOb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ä°ndeksleme (TensÃ¶rlerden veri seÃ§me)\n",
        "\n",
        "Bazen tensÃ¶rlerden belirli verileri seÃ§mek isteyebilirsiniz (Ã¶rneÄŸin, sadece ilk sÃ¼tun veya ikinci satÄ±r gibi).\n",
        "\n",
        "Bunu yapmak iÃ§in indeksleme kullanabilirsiniz.\n",
        "\n",
        "EÄŸer Python listelerinde veya NumPy dizilerinde indeksleme yaptÄ±ysanÄ±z, PyTorch'ta tensÃ¶rlerle indeksleme yapmak oldukÃ§a benzer.\n"
      ],
      "metadata": {
        "id": "4pquuNWDxe_2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TensÃ¶r oluÅŸturma\n",
        "import torch\n",
        "x = torch.arange(1, 10).reshape(1, 3, 3)\n",
        "x, x.shape\n"
      ],
      "metadata": {
        "id": "LJN2guVyxf96",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a7cfea40-fc9c-418e-dea3-d912bc2b0a90"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[[1, 2, 3],\n",
              "          [4, 5, 6],\n",
              "          [7, 8, 9]]]),\n",
              " torch.Size([1, 3, 3]))"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ä°ndeksleme iÅŸlemi dÄ±ÅŸ boyuttan iÃ§ boyuta doÄŸru yapÄ±lÄ±r (kare parantezlere gÃ¶z atÄ±n).\n"
      ],
      "metadata": {
        "id": "_tDKNCaExxrE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Hadi, parantez parantez indeksleyelim\n",
        "print(f\"Ä°lk kare parantez:\\n{x[0]}\")\n",
        "print(f\"Ä°kinci kare parantez: {x[0][0]}\")\n",
        "print(f\"ÃœÃ§Ã¼ncÃ¼ kare parantez: {x[0][0][0]}\")\n"
      ],
      "metadata": {
        "id": "WUDQjSA9xydt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "99d06ab1-d70e-4cda-9e1e-2cef691ba535"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ä°lk kare parantez:\n",
            "tensor([[1, 2, 3],\n",
            "        [4, 5, 6],\n",
            "        [7, 8, 9]])\n",
            "Ä°kinci kare parantez: tensor([1, 2, 3])\n",
            "ÃœÃ§Ã¼ncÃ¼ kare parantez: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "AyrÄ±ca **`:`** kullanarak \"bu boyuttaki tÃ¼m deÄŸerleri\" belirtebilir ve ardÄ±ndan bir virgÃ¼l (**`,`**) kullanarak baÅŸka bir boyut ekleyebilirsiniz.\n"
      ],
      "metadata": {
        "id": "HHSGjMY5x7zO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 0. boyuttaki tÃ¼m deÄŸerleri ve 1. boyuttaki 0. indeksi almak\n",
        "x[:, 0]\n"
      ],
      "metadata": {
        "id": "etjqcRH7yAjx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "19ac4d09-26a2-4e3b-e246-f2d1f79b286e"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1, 2, 3]])"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 0. ve 1. boyuttaki tÃ¼m deÄŸerleri, ancak yalnÄ±zca 2. boyuttaki 1. indeksi almak\n",
        "x[:, :, 1]\n"
      ],
      "metadata": {
        "id": "E5OVlfwFyE0b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50a1d5b7-af55-4253-ffb0-9cf081c75980"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[2, 5, 8]])"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 0. ve 1. boyutlarÄ±n 0. indeksini almak ve 2. boyuttaki tÃ¼m deÄŸerleri almak\n",
        "x[0, 0, :] # x[0][0] ile aynÄ±\n"
      ],
      "metadata": {
        "id": "MjaOVh54yJ3d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0146023e-7cff-45cc-c853-03a90a5d00f1"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 2, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ä°ndeksleme baÅŸta oldukÃ§a kafa karÄ±ÅŸtÄ±rÄ±cÄ± olabilir, Ã¶zellikle daha bÃ¼yÃ¼k tensÃ¶rlerle Ã§alÄ±ÅŸÄ±rken (ben hÃ¢lÃ¢ doÄŸru yapmak iÃ§in birkaÃ§ kez indeksleme yapmam gerekiyor). Ama biraz pratik yaparak ve veri kaÅŸiflerinin mottosunu takip ederek (***gÃ¶rselleÅŸtir, gÃ¶rselleÅŸtir, gÃ¶rselleÅŸtir***), zamanla alÄ±ÅŸmaya baÅŸlayacaksÄ±nÄ±z.\n"
      ],
      "metadata": {
        "id": "jjPT0sl1yNzu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PyTorch TensÃ¶rleri ve NumPy\n",
        "\n",
        "NumPy, popÃ¼ler bir Python sayÄ±sal hesaplama kÃ¼tÃ¼phanesi olduÄŸundan, PyTorch'un NumPy ile dÃ¼zgÃ¼n bir ÅŸekilde etkileÅŸim kurma iÅŸlevselliÄŸi vardÄ±r.\n",
        "\n",
        "NumPy ile PyTorch arasÄ±nda (ve geriye) kullanmak isteyeceÄŸiniz iki ana yÃ¶ntem ÅŸunlardÄ±r:\n",
        "* [`torch.from_numpy(ndarray)`](https://pytorch.org/docs/stable/generated/torch.from_numpy.html) - NumPy dizisi -> PyTorch tensÃ¶rÃ¼.\n",
        "* [`torch.Tensor.numpy()`](https://pytorch.org/docs/stable/generated/torch.Tensor.numpy.html) - PyTorch tensÃ¶rÃ¼ -> NumPy dizisi.\n",
        "\n",
        "Åimdi bunlarÄ± deneyelim.\n"
      ],
      "metadata": {
        "id": "o20M5CwhyUir"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# NumPy dizisini tensÃ¶re Ã§evirme\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "array = np.arange(1.0, 8.0)\n",
        "tensor = torch.from_numpy(array)\n",
        "array, tensor\n"
      ],
      "metadata": {
        "id": "sDB_iIqHyXTG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "38ec93f3-f816-4d79-ce48-5c0eea155cf3"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([1., 2., 3., 4., 5., 6., 7.]),\n",
              " tensor([1., 2., 3., 4., 5., 6., 7.], dtype=torch.float64))"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> **Not:**  \n",
        "> VarsayÄ±lan olarak, NumPy dizileri **`float64`** veri tipiyle oluÅŸturulur ve PyTorch tensÃ¶rÃ¼ne dÃ¶nÃ¼ÅŸtÃ¼rdÃ¼ÄŸÃ¼nÃ¼zde aynÄ± veri tipi korunur (yukarÄ±daki gibi).  \n",
        ">  \n",
        "> Ancak, birÃ§ok PyTorch hesaplamasÄ± varsayÄ±lan olarak **`float32`** kullanÄ±r.  \n",
        ">  \n",
        "> Yani, NumPy dizinizi (**`float64`**) -> PyTorch tensÃ¶rÃ¼ (**`float64`**) -> PyTorch tensÃ¶rÃ¼ (**`float32`**) olarak dÃ¶nÃ¼ÅŸtÃ¼rmek istiyorsanÄ±z, **`tensor = torch.from_numpy(array).type(torch.float32)`** kullanabilirsiniz.  \n",
        ">  \n",
        "> YukarÄ±da **`tensor`**'u yeniden atadÄ±ÄŸÄ±mÄ±z iÃ§in, tensÃ¶rÃ¼ deÄŸiÅŸtirdiÄŸinizde dizi aynÄ± kalÄ±r.\n"
      ],
      "metadata": {
        "id": "-1c4THo2ydr1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Diziyi deÄŸiÅŸtir, tensÃ¶rÃ¼ aynÄ± tut\n",
        "array = array + 1\n",
        "array, tensor\n"
      ],
      "metadata": {
        "id": "H3bOiO4myOg6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f86a82f-fd47-4bec-c847-20e05dca69b3"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([2., 3., 4., 5., 6., 7., 8.]),\n",
              " tensor([1., 2., 3., 4., 5., 6., 7.], dtype=torch.float64))"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ve eÄŸer PyTorch tensÃ¶rÃ¼nden NumPy dizisine geÃ§mek isterseniz, **`tensor.numpy()`** fonksiyonunu Ã§aÄŸÄ±rabilirsiniz.\n"
      ],
      "metadata": {
        "id": "5e2K5bPNymkm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TensÃ¶rden NumPy dizisine\n",
        "tensor = torch.ones(7) # float32 veri tipiyle bir tensÃ¶r oluÅŸturma\n",
        "numpy_tensor = tensor.numpy() # dtype=float32 olacak, eÄŸer deÄŸiÅŸtirilmezse\n",
        "tensor, numpy_tensor\n"
      ],
      "metadata": {
        "id": "N9aI-6JEynRs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "44f23c96-dd0c-4cfb-850a-58e4b85acceb"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([1., 1., 1., 1., 1., 1., 1.]),\n",
              " array([1., 1., 1., 1., 1., 1., 1.], dtype=float32))"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ve yukarÄ±daki kural aynen geÃ§erlidir; eÄŸer orijinal **`tensor`**'Ä± deÄŸiÅŸtirirseniz, yeni **`numpy_tensor`** aynÄ± kalÄ±r.\n"
      ],
      "metadata": {
        "id": "TvLFP0jtyru4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TensÃ¶rÃ¼ deÄŸiÅŸtir, diziyi aynÄ± tut\n",
        "tensor = tensor + 1\n",
        "tensor, numpy_tensor\n"
      ],
      "metadata": {
        "id": "fq7yUezxyz_5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "12529339-d205-4649-e8cc-ce120ebdefa5"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([2., 2., 2., 2., 2., 2., 2.]),\n",
              " array([1., 1., 1., 1., 1., 1., 1.], dtype=float32))"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tekrarlanabilirlik (RastgeleliÄŸi Rastgelelikten Ã‡Ä±karmaya Ã‡alÄ±ÅŸmak)\n",
        "\n",
        "Sinir aÄŸlarÄ± ve makine Ã¶ÄŸrenimi hakkÄ±nda daha fazla ÅŸey Ã¶ÄŸrendikÃ§e, rastgeleliÄŸin ne kadar Ã¶nemli bir rol oynadÄ±ÄŸÄ±nÄ± keÅŸfedeceksiniz.\n",
        "\n",
        "AslÄ±nda bu, **sahte rastgelelik**. Ã‡Ã¼nkÃ¼ sonuÃ§ta, tasarlandÄ±klarÄ± gibi bir bilgisayar temelde **deterministiktir** (her adÄ±m tahmin edilebilir), bu yÃ¼zden yarattÄ±klarÄ± rastgelelikler, simÃ¼le edilmiÅŸ rastgeleliklerdir (bununla ilgili de tartÄ±ÅŸmalar olsa da, ben bir bilgisayar bilimci olmadÄ±ÄŸÄ±m iÃ§in bunu kendiniz keÅŸfetmenize bÄ±rakÄ±yorum).\n",
        "\n",
        "Peki bu, sinir aÄŸlarÄ± ve derin Ã¶ÄŸrenme ile nasÄ±l iliÅŸkilidir?\n",
        "\n",
        "Sinir aÄŸlarÄ±nÄ±n, verilerdeki kalÄ±plarÄ± tanÄ±mlamak iÃ§in rastgele sayÄ±larla baÅŸladÄ±ÄŸÄ±nÄ± ve bu sayÄ±larÄ± tensÃ¶r iÅŸlemleri (ve henÃ¼z tartÄ±ÅŸmadÄ±ÄŸÄ±mÄ±z birkaÃ§ baÅŸka ÅŸey) kullanarak iyileÅŸtirmeye Ã§alÄ±ÅŸtÄ±ÄŸÄ±nÄ± konuÅŸtuk. Bu sayÄ±lar baÅŸlangÄ±Ã§ta kÃ¶tÃ¼ tanÄ±mlamalardÄ±r ve verilerdeki kalÄ±plarÄ± daha iyi tanÄ±mlamak iÃ§in bu rastgele sayÄ±lar iyileÅŸtirilmeye Ã§alÄ±ÅŸÄ±lÄ±r.\n",
        "\n",
        "KÄ±sacasÄ±:\n",
        "\n",
        "``rastgele sayÄ±larla baÅŸla -> tensÃ¶r iÅŸlemleri -> daha iyi hale getirmeye Ã§alÄ±ÅŸ (defalarca ve tekrar)``\n",
        "\n",
        "Rastgelelik gÃ¼zel ve gÃ¼Ã§lÃ¼ olsa da, bazen biraz daha az rastgelelik istersiniz.\n",
        "\n",
        "Neden?\n",
        "\n",
        "Ã‡Ã¼nkÃ¼ tekrarlanabilir deneyler yapabilmek istersiniz.\n",
        "\n",
        "Ã–rneÄŸin, X performansÄ±nÄ± elde edebilen bir algoritma oluÅŸturursunuz.\n",
        "\n",
        "Ve sonra arkadaÅŸÄ±nÄ±z bunu deneyerek sizin deli olmadÄ±ÄŸÄ±nÄ±zÄ± doÄŸrulamak ister.\n",
        "\n",
        "Bunu nasÄ±l yapabilirler?\n",
        "\n",
        "Ä°ÅŸte burada **tekrarlanabilirlik** devreye giriyor.\n",
        "\n",
        "BaÅŸka bir deyiÅŸle, aynÄ± kodu Ã§alÄ±ÅŸtÄ±ran bilgisayarÄ±mda aldÄ±ÄŸÄ±m aynÄ± (veya Ã§ok benzer) sonuÃ§larÄ±, sizin bilgisayarÄ±nÄ±zda alabilir misiniz?\n",
        "\n",
        "Hadi PyTorch'ta tekrarlanabilirliÄŸe kÄ±sa bir Ã¶rnek bakalÄ±m.\n",
        "\n",
        "Ä°ki rastgele tensÃ¶r oluÅŸturacaÄŸÄ±z. Ã‡Ã¼nkÃ¼ rastgele olduklarÄ±ndan, farklÄ± olmalarÄ±nÄ± beklersiniz, deÄŸil mi?\n"
      ],
      "metadata": {
        "id": "sa47pSZny3V_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Ä°ki rastgele tensÃ¶r oluÅŸturma\n",
        "random_tensor_A = torch.rand(3, 4)\n",
        "random_tensor_B = torch.rand(3, 4)\n",
        "\n",
        "print(f\"TensÃ¶r A:\\n{random_tensor_A}\\n\")\n",
        "print(f\"TensÃ¶r B:\\n{random_tensor_B}\\n\")\n",
        "print(f\"TensÃ¶r A, TensÃ¶r B'ye eÅŸit mi? (herhangi bir yerde)\")\n",
        "random_tensor_A == random_tensor_B\n"
      ],
      "metadata": {
        "id": "FVX4eoFUy86n",
        "outputId": "bf4ac29d-7441-441d-b6b0-fab53c33ea46",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensÃ¶r A:\n",
            "tensor([[0.8016, 0.3649, 0.6286, 0.9663],\n",
            "        [0.7687, 0.4566, 0.5745, 0.9200],\n",
            "        [0.3230, 0.8613, 0.0919, 0.3102]])\n",
            "\n",
            "TensÃ¶r B:\n",
            "tensor([[0.9536, 0.6002, 0.0351, 0.6826],\n",
            "        [0.3743, 0.5220, 0.1336, 0.9666],\n",
            "        [0.9754, 0.8474, 0.8988, 0.1105]])\n",
            "\n",
            "TensÃ¶r A, TensÃ¶r B'ye eÅŸit mi? (herhangi bir yerde)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[False, False, False, False],\n",
              "        [False, False, False, False],\n",
              "        [False, False, False, False]])"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "BeklediÄŸiniz gibi, tensÃ¶rler farklÄ± deÄŸerlerle Ã§Ä±ktÄ±.\n",
        "\n",
        "Ama ya iki rastgele tensÃ¶rÃ¼n *aynÄ±* deÄŸerlere sahip olmasÄ±nÄ± isteseydiniz?\n",
        "\n",
        "Yani tensÃ¶rler hala rastgele deÄŸerlere sahip olacak ama aynÄ± \"lezzette\" olacaklardÄ±.\n",
        "\n",
        "Ä°ÅŸte burada **`torch.manual_seed(seed)`** devreye giriyor; burada **`seed`** bir tam sayÄ±dÄ±r (mesela **`42`** olabilir ama baÅŸka bir ÅŸey de olabilir) ve rastgeleliÄŸi **lezzetlendiren** bir deÄŸerdir.\n",
        "\n",
        "Hadi bunu deneyelim ve daha fazla *lezzetlendirilmiÅŸ* rastgele tensÃ¶rler oluÅŸturalÄ±m.\n"
      ],
      "metadata": {
        "id": "uIjm-ILtzLhB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import random\n",
        "\n",
        "# Rastgele tohum deÄŸerini ayarla\n",
        "RANDOM_SEED = 42 # Bunu farklÄ± deÄŸerlere deÄŸiÅŸtirerek aÅŸaÄŸÄ±daki sayÄ±larda ne olduÄŸunu gÃ¶rebilirsiniz\n",
        "torch.manual_seed(seed=RANDOM_SEED)\n",
        "random_tensor_C = torch.rand(3, 4)\n",
        "\n",
        "# Her yeni rand() Ã§aÄŸrÄ±ldÄ±ÄŸÄ±nda tohumun sÄ±fÄ±rlanmasÄ± gerekir\n",
        "# Bunu yapmazsanÄ±z, tensor_D, tensor_C'ye farklÄ± olurdu\n",
        "torch.random.manual_seed(seed=RANDOM_SEED) # Bu satÄ±rÄ± yorum satÄ±rÄ±na almayÄ± deneyin ve ne olacaÄŸÄ±nÄ± gÃ¶rÃ¼n\n",
        "random_tensor_D = torch.rand(3, 4)\n",
        "\n",
        "print(f\"TensÃ¶r C:\\n{random_tensor_C}\\n\")\n",
        "print(f\"TensÃ¶r D:\\n{random_tensor_D}\\n\")\n",
        "print(f\"TensÃ¶r C, TensÃ¶r D'ye eÅŸit mi? (herhangi bir yerde)\")\n",
        "random_tensor_C == random_tensor_D\n"
      ],
      "metadata": {
        "id": "QhdIoDPGzOan",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b1faa9c-6b9d-4a18-c58e-73bb2e7c8486"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensÃ¶r C:\n",
            "tensor([[0.8823, 0.9150, 0.3829, 0.9593],\n",
            "        [0.3904, 0.6009, 0.2566, 0.7936],\n",
            "        [0.9408, 0.1332, 0.9346, 0.5936]])\n",
            "\n",
            "TensÃ¶r D:\n",
            "tensor([[0.8823, 0.9150, 0.3829, 0.9593],\n",
            "        [0.3904, 0.6009, 0.2566, 0.7936],\n",
            "        [0.9408, 0.1332, 0.9346, 0.5936]])\n",
            "\n",
            "TensÃ¶r C, TensÃ¶r D'ye eÅŸit mi? (herhangi bir yerde)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[True, True, True, True],\n",
              "        [True, True, True, True],\n",
              "        [True, True, True, True]])"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Harika!\n",
        "\n",
        "GÃ¶rÃ¼nÃ¼ÅŸe gÃ¶re tohum ayarlamak iÅŸe yaramÄ±ÅŸ.\n",
        "\n",
        "> **Kaynak:** Åu ana kadar ele aldÄ±klarÄ±mÄ±z, PyTorch'ta tekrarlanabilirlik konusunda yalnÄ±zca yÃ¼zeyi Ã§iziyor. Genel olarak tekrarlanabilirlik ve rastgele tohumlar hakkÄ±nda daha fazla bilgi iÃ§in ÅŸunlarÄ± incelemenizi Ã¶neririm:\n",
        "> * [PyTorch tekrarlanabilirlik dokÃ¼mantasyonu](https://pytorch.org/docs/stable/notes/randomness.html) (iyi bir alÄ±ÅŸtÄ±rma, bunu 10 dakika boyunca okuyup anlamasanÄ±z da, buna aÅŸina olmak Ã¶nemlidir).\n",
        "> * [Wikipedia rastgele tohum sayfasÄ±](https://en.wikipedia.org/wiki/Random_seed) (bu, rastgele tohumlar ve genel olarak sahte rastgelelik hakkÄ±nda iyi bir genel bakÄ±ÅŸ saÄŸlar).\n"
      ],
      "metadata": {
        "id": "xgKOtuWpzVAE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## TensÃ¶rleri GPU'larda Ã‡alÄ±ÅŸtÄ±rma (ve Daha HÄ±zlÄ± Hesaplamalar Yapma)\n",
        "\n",
        "Derin Ã¶ÄŸrenme algoritmalarÄ± Ã§ok fazla sayÄ±sal iÅŸlem gerektirir.\n",
        "\n",
        "Ve varsayÄ±lan olarak bu iÅŸlemler Ã§oÄŸunlukla bir CPU'da (iÅŸlemci) yapÄ±lÄ±r.\n",
        "\n",
        "Ancak, bir GPU (grafik iÅŸleme birimi) adÄ±nda baÅŸka bir yaygÄ±n donanÄ±m tÃ¼rÃ¼ vardÄ±r, bu donanÄ±m genellikle sinir aÄŸlarÄ±nÄ±n ihtiyaÃ§ duyduÄŸu belirli tÃ¼rdeki iÅŸlemleri (matris Ã§arpÄ±mlarÄ±) CPU'lardan Ã§ok daha hÄ±zlÄ± bir ÅŸekilde gerÃ§ekleÅŸtirebilir.\n",
        "\n",
        "BilgisayarÄ±nÄ±zda bir tane olabilir.\n",
        "\n",
        "EÄŸer Ã¶yleyse, sinir aÄŸlarÄ±nÄ± eÄŸitmek iÃ§in her fÄ±rsatta kullanmaya Ã§alÄ±ÅŸmalÄ±sÄ±nÄ±z Ã§Ã¼nkÃ¼ bÃ¼yÃ¼k ihtimalle eÄŸitim sÃ¼resini dramatik ÅŸekilde hÄ±zlandÄ±racaktÄ±r.\n",
        "\n",
        "GPU'ya eriÅŸmenin ve PyTorch'u GPU kullanacak ÅŸekilde yapÄ±landÄ±rmanÄ±n birkaÃ§ yolu vardÄ±r.\n",
        "\n",
        "> **Not:** Bu kurs boyunca \"GPU\"dan bahsederken, [CUDA etkinleÅŸtirilmiÅŸ bir Nvidia GPU'yu](https://developer.nvidia.com/cuda-gpus) kast ediyorum (CUDA, GPU'larÄ±n yalnÄ±zca grafik deÄŸil, genel amaÃ§lÄ± hesaplama iÃ§in de kullanÄ±lmasÄ±nÄ± saÄŸlayan bir hesaplama platformu ve API'sidir) aksi belirtilmedikÃ§e.\n"
      ],
      "metadata": {
        "id": "D4xB2AVnzgEp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. GPU'ya EriÅŸim\n",
        "\n",
        "GPU dediÄŸimde ne olduÄŸunu zaten biliyor olabilirsiniz. Ancak bilmiyorsanÄ±z, birine eriÅŸim saÄŸlamak iÃ§in birkaÃ§ yol vardÄ±r.\n",
        "\n",
        "| **YÃ¶ntem** | **Kurulum ZorluÄŸu** | **Avantajlar** | **Dezavantajlar** | **NasÄ±l Kurulur** |\n",
        "| ----- | ----- | ----- | ----- | ----- |\n",
        "| Google Colab | Kolay | Ãœcretsiz, neredeyse sÄ±fÄ±r kurulum gerektirir, Ã§alÄ±ÅŸmalarÄ± baÅŸkalarÄ±yla bir baÄŸlantÄ± kadar kolay paylaÅŸabilirsiniz | Verilerinizi kaydetmez, sÄ±nÄ±rlÄ± hesaplama gÃ¼cÃ¼, zaman aÅŸÄ±mÄ±na uÄŸrayabilir | [Google Colab KÄ±lavuzunu Takip Edin](https://colab.research.google.com/notebooks/gpu.ipynb) |\n",
        "| Kendi bilgisayarÄ±nÄ±zÄ± kullanma | Orta | Her ÅŸeyi yerel olarak kendi bilgisayarÄ±nÄ±zda Ã§alÄ±ÅŸtÄ±rabilirsiniz | GPU'lar Ã¼cretsiz deÄŸil, Ã¶nceden maliyet gerektirir | [PyTorch kurulum yÃ¶nergelerini takip edin](https://pytorch.org/get-started/locally/) |\n",
        "| Bulut biliÅŸim (AWS, GCP, Azure) | Orta-Zor | KÃ¼Ã§Ã¼k Ã¶n maliyet, neredeyse sonsuz hesaplama eriÅŸimi | SÃ¼rekli Ã§alÄ±ÅŸtÄ±rÄ±rsanÄ±z pahalÄ± olabilir, doÄŸru ÅŸekilde kurmak zaman alabilir | [PyTorch bulut kurulum kÄ±lavuzunu takip edin](https://pytorch.org/get-started/cloud-partners/) |\n",
        "\n",
        "GPU'larÄ± kullanmak iÃ§in daha fazla seÃ§enek vardÄ±r ancak yukarÄ±daki Ã¼Ã§ seÃ§enek ÅŸimdilik yeterli olacaktÄ±r.\n",
        "\n",
        "KiÅŸisel olarak, kÃ¼Ã§Ã¼k Ã¶lÃ§ekli deneyler (ve bu kursu oluÅŸturma) iÃ§in Google Colab ve kendi bilgisayarÄ±mÄ±n bir kombinasyonunu kullanÄ±yorum ve daha fazla hesaplama gÃ¼cÃ¼ne ihtiyaÃ§ duyduÄŸumda bulut kaynaklarÄ±na baÅŸvuruyorum.\n",
        "\n",
        "> **Kaynak:** Kendi GPU'nuzu satÄ±n almayÄ± dÃ¼ÅŸÃ¼nÃ¼yorsanÄ±z ancak ne alacaÄŸÄ±nÄ±zÄ± bilmiyorsanÄ±z, [Tim Dettmers'Ä±n harika bir kÄ±lavuzu var](https://timdettmers.com/2020/09/07/which-gpu-for-deep-learning/).\n",
        "\n",
        "Bir Nvidia GPU'nuzun olup olmadÄ±ÄŸÄ±nÄ± kontrol etmek iÃ§in, `!nvidia-smi` komutunu Ã§alÄ±ÅŸtÄ±rabilirsiniz, burada `!` (aynÄ± zamanda bang olarak da bilinir) \"bunu komut satÄ±rÄ±nda Ã§alÄ±ÅŸtÄ±r\" anlamÄ±na gelir.\n"
      ],
      "metadata": {
        "id": "rwemFJIkzq2c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "DgB0QZWrzjEp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5abd51b1-a5cb-4bab-e34f-cba00e6908ec"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: nvidia-smi: command not found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "EÄŸer eriÅŸebileceÄŸiniz bir Nvidia GPU'nuz yoksa, yukarÄ±daki Ã§Ä±ktÄ± ÅŸu ÅŸekilde gÃ¶rÃ¼necektir:\n",
        "\n"
      ],
      "metadata": {
        "id": "wJglSGizz6GB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. PyTorch'u GPU Ã¼zerinde Ã§alÄ±ÅŸtÄ±rma\n",
        "\n",
        "Bir GPU'ya eriÅŸim saÄŸladÄ±ktan sonra, bir sonraki adÄ±m, PyTorch'u verileri (tensÃ¶rleri) depolamak ve veriler Ã¼zerinde hesaplamalar yapmak (tensÃ¶rler Ã¼zerinde iÅŸlemler gerÃ§ekleÅŸtirmek) iÃ§in kullanmaktÄ±r.\n",
        "\n",
        "Bunu yapmak iÃ§in **`torch.cuda`** paketini kullanabilirsiniz.\n",
        "\n",
        "Bundan bahsetmek yerine, bunu deneyelim.\n",
        "\n",
        "PyTorch'un bir GPU'ya eriÅŸimi olup olmadÄ±ÄŸÄ±nÄ±, **[`torch.cuda.is_available()`](https://pytorch.org/docs/stable/generated/torch.cuda.is_available.html#torch.cuda.is_available)** fonksiyonunu kullanarak test edebilirsiniz.\n"
      ],
      "metadata": {
        "id": "Khx-VYnoz_SE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# GPU'yu kontrol etme\n",
        "import torch\n",
        "torch.cuda.is_available()\n"
      ],
      "metadata": {
        "id": "iMwPP5g8z_59",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d7421290-d6d2-4b8e-eff9-46ed3109914d"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "EÄŸer yukarÄ±daki Ã§Ä±ktÄ± **`True`** ise, PyTorch GPU'yu gÃ¶rebilir ve kullanabilir, eÄŸer **`False`** Ã§Ä±karsa, GPU'yu gÃ¶remez ve bu durumda kurulum adÄ±mlarÄ±nÄ± tekrar gÃ¶zden geÃ§irmeniz gerekecek.\n",
        "\n",
        "Åimdi, kodunuzu CPU *veya* mevcutsa GPU Ã¼zerinde Ã§alÄ±ÅŸacak ÅŸekilde ayarlamak istediÄŸinizi varsayalÄ±m.\n",
        "\n",
        "Bu ÅŸekilde, siz veya birisi kodunuzu Ã§alÄ±ÅŸtÄ±rmaya karar verdiÄŸinde, kullandÄ±klarÄ± hesaplama cihazÄ±na bakÄ±lmaksÄ±zÄ±n Ã§alÄ±ÅŸacaktÄ±r.\n",
        "\n",
        "Bir `device` deÄŸiÅŸkeni oluÅŸturalÄ±m ve hangi tÃ¼r cihazÄ±n mevcut olduÄŸunu saklayalÄ±m.\n"
      ],
      "metadata": {
        "id": "Ipf9zbYY0K-w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cihaz tÃ¼rÃ¼nÃ¼ ayarlama\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "device\n"
      ],
      "metadata": {
        "id": "nqgwd7fe0M6M",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "72c43e40-c99c-4fc0-ef8b-8b527f8dc82c"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cpu'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "YukarÄ±daki Ã§Ä±ktÄ± **`\"cuda\"`** ise, tÃ¼m PyTorch kodumuzu mevcut CUDA cihazÄ±nÄ± (GPU) kullanacak ÅŸekilde ayarlayabileceÄŸimiz anlamÄ±na gelir ve eÄŸer **`\"cpu\"`** Ã§Ä±karsa, PyTorch kodumuz CPU Ã¼zerinde Ã§alÄ±ÅŸacaktÄ±r.\n",
        "\n",
        "> **Not:** PyTorch'ta, [**cihazdan baÄŸÄ±msÄ±z kod**](https://pytorch.org/docs/master/notes/cuda.html#device-agnostic-code) yazmak en iyi uygulamadÄ±r. Bu, CPU'da (her zaman mevcut) veya GPU'da (mevcutsa) Ã§alÄ±ÅŸacak kod anlamÄ±na gelir.\n",
        "\n",
        "Daha hÄ±zlÄ± hesaplamalar yapmak istiyorsanÄ±z, bir GPU kullanabilirsiniz, ancak *Ã§ok* daha hÄ±zlÄ± hesaplamalar yapmak istiyorsanÄ±z, birden fazla GPU kullanabilirsiniz.\n",
        "\n",
        "PyTorch'un eriÅŸebileceÄŸi GPU sayÄ±sÄ±nÄ±, **[`torch.cuda.device_count()`](https://pytorch.org/docs/stable/generated/torch.cuda.device_count.html#torch.cuda.device_count)** fonksiyonunu kullanarak Ã¶ÄŸrenebilirsiniz.\n"
      ],
      "metadata": {
        "id": "XA1sKRPg0URk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cihaz sayÄ±sÄ±nÄ± sayma\n",
        "torch.cuda.device_count()\n"
      ],
      "metadata": {
        "id": "dQMUzFRB0YPm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6850b677-c7a6-4eb0-de24-56e30b6e4004"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "PyTorch'un eriÅŸebileceÄŸi GPU sayÄ±sÄ±nÄ± bilmek, bir iÅŸlemi bir GPU'da ve baÅŸka bir iÅŸlemi diÄŸer GPU'da Ã§alÄ±ÅŸtÄ±rmak isterseniz faydalÄ±dÄ±r (PyTorch ayrÄ±ca bir iÅŸlemi *tÃ¼m* GPU'lar Ã¼zerinde Ã§alÄ±ÅŸtÄ±rmanÄ±za olanak tanÄ±yan Ã¶zelliklere sahiptir).\n"
      ],
      "metadata": {
        "id": "TpIixDo-0d2l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.1 PyTorch'u Apple Silicon'da Ã‡alÄ±ÅŸtÄ±rma\n",
        "\n",
        "Apple'Ä±n M1/M2/M3 GPU'larÄ±nda PyTorch Ã§alÄ±ÅŸtÄ±rmak iÃ§in **[`torch.backends.mps`](https://pytorch.org/docs/stable/notes/mps.html)** modÃ¼lÃ¼nÃ¼ kullanabilirsiniz.\n",
        "\n",
        "macOS ve PyTorch sÃ¼rÃ¼mlerinin gÃ¼ncel olduÄŸundan emin olun.\n",
        "\n",
        "PyTorch'un bir GPU'ya eriÅŸimi olup olmadÄ±ÄŸÄ±nÄ± **`torch.backends.mps.is_available()`** ile test edebilirsiniz.\n"
      ],
      "metadata": {
        "id": "uIB79nEG0jU9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Apple Silicon GPU'yu kontrol etme\n",
        "import torch\n",
        "torch.backends.mps.is_available() # Not: Bu, bir Mac'te Ã§alÄ±ÅŸmÄ±yorsanÄ±z false dÃ¶ndÃ¼recektir\n"
      ],
      "metadata": {
        "id": "HqCas6Gs0kH-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "78ad6086-2d37-43e7-8b2d-f16af49b9f68"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cihaz tÃ¼rÃ¼nÃ¼ ayarlama\n",
        "device = \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
        "device\n"
      ],
      "metadata": {
        "id": "mwA66ygc0oP3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "6fdbcf70-3369-41fd-9ef0-a67bbe0b5417"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cpu'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "YukarÄ±daki Ã§Ä±ktÄ± **`\"mps\"`** ise, tÃ¼m PyTorch kodumuzu mevcut Apple Silicon GPU'sunu kullanacak ÅŸekilde ayarlayabileceÄŸimiz anlamÄ±na gelir.\n"
      ],
      "metadata": {
        "id": "vEgOhEOt0s-E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if torch.cuda.is_available():\n",
        "    device = \"cuda\"  # NVIDIA GPU'yu kullan (eÄŸer mevcutsa)\n",
        "elif torch.backends.mps.is_available():\n",
        "    device = \"mps\"  # Apple Silicon GPU'yu kullan (eÄŸer mevcutsa)\n",
        "else:\n",
        "    device = \"cpu\"  # GPU yoksa varsayÄ±lan olarak CPU kullan\n"
      ],
      "metadata": {
        "id": "R7-M6VxR0x1t"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. TensÃ¶rleri (ve modelleri) GPU'ya koyma\n",
        "\n",
        "TensÃ¶rleri (ve modelleri, bunu daha sonra gÃ¶receÄŸiz) belirli bir cihaza koymak iÃ§in onlara **`to(device)`** fonksiyonunu Ã§aÄŸÄ±rabilirsiniz. Burada **`device`**, tensÃ¶rÃ¼n (veya modelin) gitmesini istediÄŸiniz hedef cihazdÄ±r.\n",
        "\n",
        "Bunu neden yapmalÄ±sÄ±nÄ±z?\n",
        "\n",
        "GPU'lar, CPU'lardan Ã§ok daha hÄ±zlÄ± sayÄ±sal hesaplamalar yapar ve eÄŸer bir GPU mevcut deÄŸilse, **cihazdan baÄŸÄ±msÄ±z kodumuz** (yukarÄ±ya bakÄ±n) sayesinde kod CPU Ã¼zerinde Ã§alÄ±ÅŸacaktÄ±r.\n",
        "\n",
        "> **Not:** **`to(device)`** kullanarak bir tensÃ¶rÃ¼ GPU'ya koymak (Ã¶rneÄŸin **`some_tensor.to(device)`**) o tensÃ¶rÃ¼n bir kopyasÄ±nÄ± dÃ¶ndÃ¼rÃ¼r; Ã¶rneÄŸin, aynÄ± tensÃ¶r hem CPU'da hem de GPU'da olacaktÄ±r. TensÃ¶rleri Ã¼zerine yazmak iÃ§in onlarÄ± yeniden atayÄ±n:\n",
        ">\n",
        "> `some_tensor = some_tensor.to(device)`\n",
        "\n",
        "Hadi, bir tensÃ¶r oluÅŸturalÄ±m ve onu GPU'ya koyalÄ±m (eÄŸer mevcutsa).\n"
      ],
      "metadata": {
        "id": "lUppzg1l06wL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TensÃ¶r oluÅŸturma (varsayÄ±lan olarak CPU Ã¼zerinde)\n",
        "tensor = torch.tensor([1, 2, 3])\n",
        "\n",
        "# TensÃ¶r GPU'da deÄŸil\n",
        "print(tensor, tensor.device)\n",
        "\n",
        "# TensÃ¶rÃ¼ GPU'ya taÅŸÄ±ma (eÄŸer mevcutsa)\n",
        "tensor_on_gpu = tensor.to(device)\n",
        "tensor_on_gpu\n"
      ],
      "metadata": {
        "id": "JevoqGA-08kQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "010c8a98-cb8d-4c5b-b33c-684ce01c5daf"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1, 2, 3]) cpu\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 2, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "EÄŸer bir GPU'nuz mevcutsa, yukarÄ±daki kod ÅŸu ÅŸekilde bir Ã§Ä±ktÄ± verecektir:\n",
        "\n",
        "```\n",
        "tensor([1, 2, 3]) cpu\n",
        "tensor([1, 2, 3], device='cuda:0')\n",
        "```\n",
        "\n",
        "Ä°kinci tensÃ¶rÃ¼n **`device='cuda:0'`** olduÄŸunu fark edin, bu, tensÃ¶rÃ¼n mevcut 0. GPU'da depolandÄ±ÄŸÄ±nÄ± gÃ¶sterir (GPU'lar 0'dan baÅŸlar, eÄŸer iki GPU mevcutsa, sÄ±rasÄ±yla `'cuda:0'` ve `'cuda:1'` olur, bu ÅŸekilde `'cuda:n'`'e kadar devam eder).\n"
      ],
      "metadata": {
        "id": "OuJIlGiN1HcU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. TensÃ¶rleri CPU'ya geri taÅŸÄ±ma\n",
        "\n",
        "Ya tensÃ¶rÃ¼ geri CPU'ya taÅŸÄ±mak istersek?\n",
        "\n",
        "Ã–rneÄŸin, tensÃ¶rlerinizle NumPy ile etkileÅŸimde bulunmak isterseniz bunu yapmak isteyebilirsiniz (NumPy, GPU'yu kullanmaz).\n",
        "\n",
        "Hadi, **`torch.Tensor.numpy()`** metodunu **`tensor_on_gpu`** Ã¼zerinde deneyelim.\n"
      ],
      "metadata": {
        "id": "YbKaIdQ81K8n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# EÄŸer tensÃ¶r GPU'daysa, NumPy'ye dÃ¶nÃ¼ÅŸtÃ¼rÃ¼lemez (bu hata verecektir)\n",
        "tensor_on_gpu.numpy()\n"
      ],
      "metadata": {
        "id": "dh6y1zUr1RTw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf0b7baa-daec-446e-a305-15e947c483a9"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 2, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bunun yerine, bir tensÃ¶rÃ¼ CPU'ya geri almak ve NumPy ile kullanÄ±labilir hale getirmek iÃ§in **[`Tensor.cpu()`](https://pytorch.org/docs/stable/generated/torch.Tensor.cpu.html)** kullanabiliriz.\n",
        "\n",
        "Bu, tensÃ¶rÃ¼ CPU belleÄŸine kopyalar, bÃ¶ylece CPU'lar ile kullanÄ±labilir hale gelir.\n"
      ],
      "metadata": {
        "id": "re4L2_YZ1adh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Bunun yerine, tensÃ¶rÃ¼ geri CPU'ya kopyala\n",
        "tensor_back_on_cpu = tensor_on_gpu.cpu().numpy()\n",
        "tensor_back_on_cpu\n"
      ],
      "metadata": {
        "id": "LPIKXGxN1fdT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ca13c6b-c777-4a1b-c243-0892bc501eda"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 2, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "YukarÄ±daki iÅŸlem, GPU tensÃ¶rÃ¼nÃ¼n bir kopyasÄ±nÄ± CPU belleÄŸine dÃ¶ndÃ¼rÃ¼r, bÃ¶ylece orijinal tensÃ¶r hala GPU Ã¼zerinde kalÄ±r.\n"
      ],
      "metadata": {
        "id": "bc36Ve3J1jp0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tensor_on_gpu"
      ],
      "metadata": {
        "id": "JRHDFVEy1m7u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9e33e278-7e2a-4865-cc3d-6e0060d6aade"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 2, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    }
  ]
}